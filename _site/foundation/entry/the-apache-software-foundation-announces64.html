<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Apache Software Foundation Announces Apache® Hudi™ as a Top-Level Project | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="The Apache Software Foundation Announces Apache® Hudi™ as a Top-Level Project" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Open Source data lake technology for stream processing on top of Apache Hadoop in use at Alibaba, Tencent, Uber, and more. Wakefield, MA &mdash;4 June 2020&mdash; The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of more than 350 Open Source projects and initiatives, announced today Apache&reg; Hudi&trade; as a Top-Level Project (TLP). Apache Hudi (Hadoop Upserts Deletes and Incrementals) data lake technology enables stream processing on top of Apache Hadoop compatible cloud stores &amp; distributed file systems. The project was originally developed at Uber in 2016 (code-named and pronounced &quot;Hoodie&quot;), open-sourced in 2017, and submitted to the Apache Incubator in January 2019. &quot;Learning and growing the Apache way in the incubator was a rewarding experience,&quot; said Vinoth Chandar, Vice President of Apache Hudi. &quot;As a community, we are humbled by how far we have advanced the project together, while at the same time, excited about the challenges ahead.&quot; Apache Hudi is used to manage petabyte-scale data lakes using stream processing primitives like upserts and incremental change streams on Apache Hadoop Distributed File System (HDFS) or cloud stores. Hudi data lakes provide fresh data while being an order of magnitude efficient over traditional batch processing. Features include: Upsert/Delete support with fast, pluggable indexing Transactionally commit/rollback data Change capture from Hudi tables for stream processing Support for Apache Hive, Apache Spark, Apache Impala and Presto query engines Built-in data ingestion tool supporting Apache Kafka, Apache Sqoop and other common data sources Optimize query performance by managing file sizes, storage layout Fast row based ingestion format with async compaction into columnar format Timeline metadata for audit tracking Apache Hudi is in use at organizations such as Alibaba Group, EMIS Health, Linknovate, Tathastu.AI, Tencent, and Uber, and is supported as part of Amazon EMR by Amazon Web Services. A partial list of those deploying Hudi is available at https://hudi.apache.org/docs/powered_by.html &quot;We are very pleased to see Apache Hudi graduate to an Apache Top-Level Project. Apache Hudi is supported in Amazon EMR release 5.28 and higher, and enables customers with data in Amazon S3 data lakes to perform record-level inserts, updates, and deletes for privacy regulations, change data capture (CDC), and simplified data pipeline development,&quot; said Rahul Pathak, General Manager, Analytics, AWS. &ldquo;We look forward to working with our customers and the Apache Hudi community to help advance the project.&quot; &quot;At Uber, Hudi powers one of the largest transactional data lakes on the planet in near real time to provide meaningful experiences to users worldwide,&quot; said Nishith Agarwal, member of the Apache Hudi Project Management Committee. &quot;With over 150 petabytes of data and more than 500 billion records ingested per day, Uber&rsquo;s use cases range from business critical workflows to analytics and machine learning.&quot; &quot;Using Apache Hudi, end-users can handle either read-heavy or write-heavy use cases, and Hudi will manage the underlying data stored on HDFS/COS/CHDFS using Apache Parquet and Apache Avro,&quot; said Felix Zheng, Lead of Cloud Real-Time Computing Service Technology at Tencent. &quot;As cloud infrastructure becomes more sophisticated, data analysis and computing solutions gradually begin to build data lake platforms based on cloud object storage and computing resources,&quot; said Li Wei, Technical Lead on Data Lake Analytics, at Alibaba Cloud. &quot;Apache Hudi is a very good incremental storage engine that helps users manage the data in the data lake in an open way and accelerate users&#39; computing and analysis.&quot; &quot;Apache Hudi is a key building block for the Hopsworks Feature Store, providing versioned features, incremental and atomic updates to features, and indexed time-travel queries for features,&quot; said Jim Dowling, CEO/Co-Founder at Logical Clocks. &quot;The graduation of Hudi to a top-level Apache project is also the graduation of the open-source data lake from its earlier data swamp incarnation to a modern ACID-enabled, enterprise-ready data platform.&quot; &quot;Hudi&#39;s graduation to a top-level Apache project is a result of the efforts of many dedicated contributors in the Hudi community,&quot; said Jennifer Anderson, Senior Director of Platform Engineering at Uber. &quot;Hudi is critical to the performance and scalability of Uber&#39;s big data infrastructure. We&#39;re excited to see it gain traction and achieve this major milestone.&quot; &quot;Thus far, Hudi has started a meaningful discussion in the industry about the wide gaps between data warehouses and data lakes. We have also taken strides to bridge some of them, with the help of the Apache community,&quot; added Chandar. &quot;But, we are only getting started with our deeply technical roadmap. We certainly look forward to a lot more contributions and collaborations from the community to get there. Everyone&rsquo;s invited!&quot; Catch Apache Hudi in action at Virtual Berlin Buzzwords 7-12 June 2020, as well as at MeetUps, and other events. Availability and OversightApache Hudi software is released under the Apache License v2.0 and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. For downloads, documentation, and ways to become involved with Apache Hudi, visit http://hudi.apache.org/&nbsp;and https://twitter.com/apachehudi&nbsp; About the Apache IncubatorThe Apache Incubator is the primary entry path for projects and codebases wishing to become part of the efforts at The Apache Software Foundation. All code donations from external organizations and existing external projects enter the ASF through the Incubator to: 1) ensure all donations are in accordance with the ASF legal standards; and 2) develop new communities that adhere to our guiding principles. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF. For more information, visit http://incubator.apache.org/&nbsp; About The Apache Software Foundation (ASF)Established in 1999, The Apache Software Foundation (ASF) is the world&rsquo;s largest Open Source foundation, stewarding 200M+ lines of code and providing more than $20B+ worth of software to the public at 100% no cost. The ASF&rsquo;s all-volunteer community grew from 21 original founders overseeing the Apache HTTP Server to 765 individual Members and 206 Project Management Committees who successfully lead 350+ Apache projects and initiatives in collaboration with 7,600 Committers through the ASF&rsquo;s meritocratic process known as &quot;The Apache Way&quot;. Apache software is integral to nearly every end user computing device, from laptops to tablets to mobile devices across enterprises and mission-critical applications. Apache projects power most of the Internet, manage exabytes of data, execute teraflops of operations, and store billions of objects in virtually every industry. The commercially-friendly and permissive Apache License v2 is an Open Source industry standard, helping launch billion dollar corporations and benefiting countless users worldwide. The ASF is a US 501(c)(3) not-for-profit charitable organization funded by individual donations and corporate sponsors including Aetna, Alibaba Cloud Computing, Amazon Web Services, Anonymous, Baidu, Bloomberg, Budget Direct, Capital One, CarGurus, Cerner, Cloudera, Comcast, Facebook, Google, Handshake, Huawei, IBM, Indeed, Inspur, Leaseweb, Microsoft, Pineapple Fund, Red Hat, Target, Tencent, Union Investment, Verizon Media, and Workday. For more information, visit http://apache.org/&nbsp;and https://twitter.com/TheASF&nbsp; &copy; The Apache Software Foundation. &quot;Apache&quot;, &quot;Hudi&quot;, &quot;Apache Hudi&quot;, &quot;Hadoop&quot;, &quot;Apache Hadoop&quot;, and &quot;ApacheCon&quot; are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. All other brands and trademarks are the property of their respective owners. # # #" />
<meta property="og:description" content="Open Source data lake technology for stream processing on top of Apache Hadoop in use at Alibaba, Tencent, Uber, and more. Wakefield, MA &mdash;4 June 2020&mdash; The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of more than 350 Open Source projects and initiatives, announced today Apache&reg; Hudi&trade; as a Top-Level Project (TLP). Apache Hudi (Hadoop Upserts Deletes and Incrementals) data lake technology enables stream processing on top of Apache Hadoop compatible cloud stores &amp; distributed file systems. The project was originally developed at Uber in 2016 (code-named and pronounced &quot;Hoodie&quot;), open-sourced in 2017, and submitted to the Apache Incubator in January 2019. &quot;Learning and growing the Apache way in the incubator was a rewarding experience,&quot; said Vinoth Chandar, Vice President of Apache Hudi. &quot;As a community, we are humbled by how far we have advanced the project together, while at the same time, excited about the challenges ahead.&quot; Apache Hudi is used to manage petabyte-scale data lakes using stream processing primitives like upserts and incremental change streams on Apache Hadoop Distributed File System (HDFS) or cloud stores. Hudi data lakes provide fresh data while being an order of magnitude efficient over traditional batch processing. Features include: Upsert/Delete support with fast, pluggable indexing Transactionally commit/rollback data Change capture from Hudi tables for stream processing Support for Apache Hive, Apache Spark, Apache Impala and Presto query engines Built-in data ingestion tool supporting Apache Kafka, Apache Sqoop and other common data sources Optimize query performance by managing file sizes, storage layout Fast row based ingestion format with async compaction into columnar format Timeline metadata for audit tracking Apache Hudi is in use at organizations such as Alibaba Group, EMIS Health, Linknovate, Tathastu.AI, Tencent, and Uber, and is supported as part of Amazon EMR by Amazon Web Services. A partial list of those deploying Hudi is available at https://hudi.apache.org/docs/powered_by.html &quot;We are very pleased to see Apache Hudi graduate to an Apache Top-Level Project. Apache Hudi is supported in Amazon EMR release 5.28 and higher, and enables customers with data in Amazon S3 data lakes to perform record-level inserts, updates, and deletes for privacy regulations, change data capture (CDC), and simplified data pipeline development,&quot; said Rahul Pathak, General Manager, Analytics, AWS. &ldquo;We look forward to working with our customers and the Apache Hudi community to help advance the project.&quot; &quot;At Uber, Hudi powers one of the largest transactional data lakes on the planet in near real time to provide meaningful experiences to users worldwide,&quot; said Nishith Agarwal, member of the Apache Hudi Project Management Committee. &quot;With over 150 petabytes of data and more than 500 billion records ingested per day, Uber&rsquo;s use cases range from business critical workflows to analytics and machine learning.&quot; &quot;Using Apache Hudi, end-users can handle either read-heavy or write-heavy use cases, and Hudi will manage the underlying data stored on HDFS/COS/CHDFS using Apache Parquet and Apache Avro,&quot; said Felix Zheng, Lead of Cloud Real-Time Computing Service Technology at Tencent. &quot;As cloud infrastructure becomes more sophisticated, data analysis and computing solutions gradually begin to build data lake platforms based on cloud object storage and computing resources,&quot; said Li Wei, Technical Lead on Data Lake Analytics, at Alibaba Cloud. &quot;Apache Hudi is a very good incremental storage engine that helps users manage the data in the data lake in an open way and accelerate users&#39; computing and analysis.&quot; &quot;Apache Hudi is a key building block for the Hopsworks Feature Store, providing versioned features, incremental and atomic updates to features, and indexed time-travel queries for features,&quot; said Jim Dowling, CEO/Co-Founder at Logical Clocks. &quot;The graduation of Hudi to a top-level Apache project is also the graduation of the open-source data lake from its earlier data swamp incarnation to a modern ACID-enabled, enterprise-ready data platform.&quot; &quot;Hudi&#39;s graduation to a top-level Apache project is a result of the efforts of many dedicated contributors in the Hudi community,&quot; said Jennifer Anderson, Senior Director of Platform Engineering at Uber. &quot;Hudi is critical to the performance and scalability of Uber&#39;s big data infrastructure. We&#39;re excited to see it gain traction and achieve this major milestone.&quot; &quot;Thus far, Hudi has started a meaningful discussion in the industry about the wide gaps between data warehouses and data lakes. We have also taken strides to bridge some of them, with the help of the Apache community,&quot; added Chandar. &quot;But, we are only getting started with our deeply technical roadmap. We certainly look forward to a lot more contributions and collaborations from the community to get there. Everyone&rsquo;s invited!&quot; Catch Apache Hudi in action at Virtual Berlin Buzzwords 7-12 June 2020, as well as at MeetUps, and other events. Availability and OversightApache Hudi software is released under the Apache License v2.0 and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. For downloads, documentation, and ways to become involved with Apache Hudi, visit http://hudi.apache.org/&nbsp;and https://twitter.com/apachehudi&nbsp; About the Apache IncubatorThe Apache Incubator is the primary entry path for projects and codebases wishing to become part of the efforts at The Apache Software Foundation. All code donations from external organizations and existing external projects enter the ASF through the Incubator to: 1) ensure all donations are in accordance with the ASF legal standards; and 2) develop new communities that adhere to our guiding principles. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF. For more information, visit http://incubator.apache.org/&nbsp; About The Apache Software Foundation (ASF)Established in 1999, The Apache Software Foundation (ASF) is the world&rsquo;s largest Open Source foundation, stewarding 200M+ lines of code and providing more than $20B+ worth of software to the public at 100% no cost. The ASF&rsquo;s all-volunteer community grew from 21 original founders overseeing the Apache HTTP Server to 765 individual Members and 206 Project Management Committees who successfully lead 350+ Apache projects and initiatives in collaboration with 7,600 Committers through the ASF&rsquo;s meritocratic process known as &quot;The Apache Way&quot;. Apache software is integral to nearly every end user computing device, from laptops to tablets to mobile devices across enterprises and mission-critical applications. Apache projects power most of the Internet, manage exabytes of data, execute teraflops of operations, and store billions of objects in virtually every industry. The commercially-friendly and permissive Apache License v2 is an Open Source industry standard, helping launch billion dollar corporations and benefiting countless users worldwide. The ASF is a US 501(c)(3) not-for-profit charitable organization funded by individual donations and corporate sponsors including Aetna, Alibaba Cloud Computing, Amazon Web Services, Anonymous, Baidu, Bloomberg, Budget Direct, Capital One, CarGurus, Cerner, Cloudera, Comcast, Facebook, Google, Handshake, Huawei, IBM, Indeed, Inspur, Leaseweb, Microsoft, Pineapple Fund, Red Hat, Target, Tencent, Union Investment, Verizon Media, and Workday. For more information, visit http://apache.org/&nbsp;and https://twitter.com/TheASF&nbsp; &copy; The Apache Software Foundation. &quot;Apache&quot;, &quot;Hudi&quot;, &quot;Apache Hudi&quot;, &quot;Hadoop&quot;, &quot;Apache Hadoop&quot;, and &quot;ApacheCon&quot; are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. All other brands and trademarks are the property of their respective owners. # # #" />
<link rel="canonical" href="http://localhost:4000/foundation/entry/the-apache-software-foundation-announces64" />
<meta property="og:url" content="http://localhost:4000/foundation/entry/the-apache-software-foundation-announces64" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-06T17:41:26-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Apache Software Foundation Announces Apache® Hudi™ as a Top-Level Project" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-07-06T17:41:26-04:00","datePublished":"2020-07-06T17:41:26-04:00","description":"Open Source data lake technology for stream processing on top of Apache Hadoop in use at Alibaba, Tencent, Uber, and more. Wakefield, MA &mdash;4 June 2020&mdash; The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of more than 350 Open Source projects and initiatives, announced today Apache&reg; Hudi&trade; as a Top-Level Project (TLP). Apache Hudi (Hadoop Upserts Deletes and Incrementals) data lake technology enables stream processing on top of Apache Hadoop compatible cloud stores &amp; distributed file systems. The project was originally developed at Uber in 2016 (code-named and pronounced &quot;Hoodie&quot;), open-sourced in 2017, and submitted to the Apache Incubator in January 2019. &quot;Learning and growing the Apache way in the incubator was a rewarding experience,&quot; said Vinoth Chandar, Vice President of Apache Hudi. &quot;As a community, we are humbled by how far we have advanced the project together, while at the same time, excited about the challenges ahead.&quot; Apache Hudi is used to manage petabyte-scale data lakes using stream processing primitives like upserts and incremental change streams on Apache Hadoop Distributed File System (HDFS) or cloud stores. Hudi data lakes provide fresh data while being an order of magnitude efficient over traditional batch processing. Features include: Upsert/Delete support with fast, pluggable indexing Transactionally commit/rollback data Change capture from Hudi tables for stream processing Support for Apache Hive, Apache Spark, Apache Impala and Presto query engines Built-in data ingestion tool supporting Apache Kafka, Apache Sqoop and other common data sources Optimize query performance by managing file sizes, storage layout Fast row based ingestion format with async compaction into columnar format Timeline metadata for audit tracking Apache Hudi is in use at organizations such as Alibaba Group, EMIS Health, Linknovate, Tathastu.AI, Tencent, and Uber, and is supported as part of Amazon EMR by Amazon Web Services. A partial list of those deploying Hudi is available at https://hudi.apache.org/docs/powered_by.html &quot;We are very pleased to see Apache Hudi graduate to an Apache Top-Level Project. Apache Hudi is supported in Amazon EMR release 5.28 and higher, and enables customers with data in Amazon S3 data lakes to perform record-level inserts, updates, and deletes for privacy regulations, change data capture (CDC), and simplified data pipeline development,&quot; said Rahul Pathak, General Manager, Analytics, AWS. &ldquo;We look forward to working with our customers and the Apache Hudi community to help advance the project.&quot; &quot;At Uber, Hudi powers one of the largest transactional data lakes on the planet in near real time to provide meaningful experiences to users worldwide,&quot; said Nishith Agarwal, member of the Apache Hudi Project Management Committee. &quot;With over 150 petabytes of data and more than 500 billion records ingested per day, Uber&rsquo;s use cases range from business critical workflows to analytics and machine learning.&quot; &quot;Using Apache Hudi, end-users can handle either read-heavy or write-heavy use cases, and Hudi will manage the underlying data stored on HDFS/COS/CHDFS using Apache Parquet and Apache Avro,&quot; said Felix Zheng, Lead of Cloud Real-Time Computing Service Technology at Tencent. &quot;As cloud infrastructure becomes more sophisticated, data analysis and computing solutions gradually begin to build data lake platforms based on cloud object storage and computing resources,&quot; said Li Wei, Technical Lead on Data Lake Analytics, at Alibaba Cloud. &quot;Apache Hudi is a very good incremental storage engine that helps users manage the data in the data lake in an open way and accelerate users&#39; computing and analysis.&quot; &quot;Apache Hudi is a key building block for the Hopsworks Feature Store, providing versioned features, incremental and atomic updates to features, and indexed time-travel queries for features,&quot; said Jim Dowling, CEO/Co-Founder at Logical Clocks. &quot;The graduation of Hudi to a top-level Apache project is also the graduation of the open-source data lake from its earlier data swamp incarnation to a modern ACID-enabled, enterprise-ready data platform.&quot; &quot;Hudi&#39;s graduation to a top-level Apache project is a result of the efforts of many dedicated contributors in the Hudi community,&quot; said Jennifer Anderson, Senior Director of Platform Engineering at Uber. &quot;Hudi is critical to the performance and scalability of Uber&#39;s big data infrastructure. We&#39;re excited to see it gain traction and achieve this major milestone.&quot; &quot;Thus far, Hudi has started a meaningful discussion in the industry about the wide gaps between data warehouses and data lakes. We have also taken strides to bridge some of them, with the help of the Apache community,&quot; added Chandar. &quot;But, we are only getting started with our deeply technical roadmap. We certainly look forward to a lot more contributions and collaborations from the community to get there. Everyone&rsquo;s invited!&quot; Catch Apache Hudi in action at Virtual Berlin Buzzwords 7-12 June 2020, as well as at MeetUps, and other events. Availability and OversightApache Hudi software is released under the Apache License v2.0 and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. For downloads, documentation, and ways to become involved with Apache Hudi, visit http://hudi.apache.org/&nbsp;and https://twitter.com/apachehudi&nbsp; About the Apache IncubatorThe Apache Incubator is the primary entry path for projects and codebases wishing to become part of the efforts at The Apache Software Foundation. All code donations from external organizations and existing external projects enter the ASF through the Incubator to: 1) ensure all donations are in accordance with the ASF legal standards; and 2) develop new communities that adhere to our guiding principles. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF. For more information, visit http://incubator.apache.org/&nbsp; About The Apache Software Foundation (ASF)Established in 1999, The Apache Software Foundation (ASF) is the world&rsquo;s largest Open Source foundation, stewarding 200M+ lines of code and providing more than $20B+ worth of software to the public at 100% no cost. The ASF&rsquo;s all-volunteer community grew from 21 original founders overseeing the Apache HTTP Server to 765 individual Members and 206 Project Management Committees who successfully lead 350+ Apache projects and initiatives in collaboration with 7,600 Committers through the ASF&rsquo;s meritocratic process known as &quot;The Apache Way&quot;. Apache software is integral to nearly every end user computing device, from laptops to tablets to mobile devices across enterprises and mission-critical applications. Apache projects power most of the Internet, manage exabytes of data, execute teraflops of operations, and store billions of objects in virtually every industry. The commercially-friendly and permissive Apache License v2 is an Open Source industry standard, helping launch billion dollar corporations and benefiting countless users worldwide. The ASF is a US 501(c)(3) not-for-profit charitable organization funded by individual donations and corporate sponsors including Aetna, Alibaba Cloud Computing, Amazon Web Services, Anonymous, Baidu, Bloomberg, Budget Direct, Capital One, CarGurus, Cerner, Cloudera, Comcast, Facebook, Google, Handshake, Huawei, IBM, Indeed, Inspur, Leaseweb, Microsoft, Pineapple Fund, Red Hat, Target, Tencent, Union Investment, Verizon Media, and Workday. For more information, visit http://apache.org/&nbsp;and https://twitter.com/TheASF&nbsp; &copy; The Apache Software Foundation. &quot;Apache&quot;, &quot;Hudi&quot;, &quot;Apache Hudi&quot;, &quot;Hadoop&quot;, &quot;Apache Hadoop&quot;, and &quot;ApacheCon&quot; are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. All other brands and trademarks are the property of their respective owners. # # #","headline":"The Apache Software Foundation Announces Apache® Hudi™ as a Top-Level Project","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/foundation/entry/the-apache-software-foundation-announces64"},"url":"http://localhost:4000/foundation/entry/the-apache-software-foundation-announces64"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Apache Software Foundation Announces Apache&amp;reg; Hudi&amp;trade; as a Top-Level Project</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-07-06T17:41:26-04:00" itemprop="datePublished">Jul 6, 2020
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Sally Khudairi", "login"=>"sk", "email"=>"sk@haloworldwide.com"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><span style="font-size: 14px;"><b>Open Source data lake technology for stream processing on top of Apache Hadoop in use at Alibaba, Tencent, Uber, and more.</b></span></p>
<p><span style="font-size: 14px;"><b>Wakefield, MA &mdash;4 June 2020&mdash;</b> T</span>he Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of more than 350 Open Source projects and initiatives, announced today Apache&reg; Hudi&trade; as a Top-Level Project (TLP).</p>
<p><span style="font-size: 14px;">Apache Hudi (Hadoop Upserts Deletes and Incrementals) data lake technology enables stream processing on top of Apache Hadoop compatible cloud stores &amp; distributed file systems. The project was originally developed at Uber in 2016 (code-named and pronounced "Hoodie"), open-sourced in 2017, and submitted to the Apache Incubator in January 2019.</span></p>
<p><span style="font-size: 14px;">"Learning and growing the Apache way in the incubator was a rewarding experience," said Vinoth Chandar, Vice President of Apache Hudi. "As a community, we are humbled by how far we have advanced the project together, while at the same time, excited about the challenges ahead."</span></p>
<p><span style="font-size: 14px;">Apache Hudi is used to manage petabyte-scale data lakes using stream processing primitives like upserts and incremental change streams on Apache Hadoop Distributed File System (HDFS) or cloud stores. Hudi data lakes provide fresh data while being an order of magnitude efficient over traditional batch processing. Features include:</span></p>
<ul>
<li><span style="font-size: 14px;">Upsert/Delete support with fast, pluggable indexing</span></li>
<li><span style="font-size: 14px;">Transactionally commit/rollback data</span></li>
<li><span style="font-size: 14px;">Change capture from Hudi tables for stream processing</span></li>
<li><span style="font-size: 14px;">Support for Apache Hive, Apache Spark, Apache Impala and Presto query engines</span></li>
<li><span style="font-size: 14px;">Built-in data ingestion tool supporting Apache Kafka, Apache Sqoop and other common data sources</span></li>
<li><span style="font-size: 14px;">Optimize query performance by managing file sizes, storage layout</span></li>
<li><span style="font-size: 14px;">Fast row based ingestion format with async compaction into columnar format</span></li>
<li><span style="font-size: 14px;">Timeline metadata for audit tracking</span></li>
</ul>
<p><span style="font-size: 14px;">Apache Hudi is in use at organizations such as Alibaba Group, EMIS Health, Linknovate, Tathastu.AI, Tencent, and Uber, and is supported as part of Amazon EMR by Amazon Web Services. A partial list of those deploying Hudi is available at https://hudi.apache.org/docs/powered_by.html</span></p>
<p><span style="font-size: 14px;">"We are very pleased to see Apache Hudi graduate to an Apache Top-Level Project. Apache Hudi is supported in Amazon EMR release 5.28 and higher, and enables customers with data in Amazon S3 data lakes to perform record-level inserts, updates, and deletes for privacy regulations, change data capture (CDC), and simplified data pipeline development," said Rahul Pathak, General Manager, Analytics, AWS. &ldquo;We look forward to working with our customers and the Apache Hudi community to help advance the project."</span></p>
<p><span style="font-size: 14px;">"At Uber, Hudi powers one of the largest transactional data lakes on the planet in near real time to provide meaningful experiences to users worldwide," said Nishith Agarwal, member of the Apache Hudi Project Management Committee. "With over 150 petabytes of data and more than 500 billion records ingested per day, Uber&rsquo;s use cases range from business critical workflows to analytics and machine learning."</span></p>
<p><span style="font-size: 14px;">"Using Apache Hudi, end-users can handle either read-heavy or write-heavy use cases, and Hudi will manage the underlying data stored on HDFS/COS/CHDFS using Apache Parquet and Apache Avro," said Felix Zheng, Lead of Cloud Real-Time Computing Service Technology at Tencent.</span></p>
<p><span style="font-size: 14px;">"As cloud infrastructure becomes more sophisticated, data analysis and computing solutions gradually begin to build data lake platforms based on cloud object storage and computing resources," said Li Wei, Technical Lead on Data Lake Analytics, at Alibaba Cloud. "Apache Hudi is a very good incremental storage engine that helps users manage the data in the data lake in an open way and accelerate users' computing and analysis."</span></p>
<p><span style="font-size: 14px;">"Apache Hudi is a key building block for the Hopsworks Feature Store, providing versioned features, incremental and atomic updates to features, and indexed time-travel queries for features," said Jim Dowling, CEO/Co-Founder at Logical Clocks. "The graduation of Hudi to a top-level Apache project is also the graduation of the open-source data lake from its earlier data swamp incarnation to a modern ACID-enabled, enterprise-ready data platform."</span></p>
<p><span style="font-size: 14px;">"Hudi's graduation to a top-level Apache project is a result of the efforts of many dedicated contributors in the Hudi community," said Jennifer Anderson, Senior Director of Platform Engineering at Uber. "Hudi is critical to the performance and scalability of Uber's big data infrastructure. We're excited to see it gain traction and achieve this major milestone."</span></p>
<p><span style="font-size: 14px;">"Thus far, Hudi has started a meaningful discussion in the industry about the wide gaps between data warehouses and data lakes. We have also taken strides to bridge some of them, with the help of the Apache community," added Chandar. "But, we are only getting started with our deeply technical roadmap. We certainly look forward to a lot more contributions and collaborations from the community to get there. Everyone&rsquo;s invited!"</span></p>
<p><span style="font-size: 14px;">Catch Apache Hudi in action at Virtual Berlin Buzzwords 7-12 June 2020, as well as at MeetUps, and other events.</span></p>
<p><span style="font-size: 14px;"><b>Availability and Oversight<br></b></span>Apache Hudi software is released under the Apache License v2.0 and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project's day-to-day operations, including community development and product releases. For downloads, documentation, and ways to become involved with Apache Hudi, visit <a href="http://hudi.apache.org/" target="_blank" style="background-color: rgb(255, 255, 255);">http://hudi.apache.org/</a>&nbsp;and <a href="https://twitter.com/apachehudi" target="_blank" style="background-color: rgb(255, 255, 255);">https://twitter.com/apachehudi</a>&nbsp;</p>
<p><span style="font-size: 14px;"><b>About the Apache Incubator<br></b></span>The Apache Incubator is the primary entry path for projects and codebases wishing to become part of the efforts at The Apache Software Foundation. All code donations from external organizations and existing external projects enter the ASF through the Incubator to: 1) ensure all donations are in accordance with the ASF legal standards; and 2) develop new communities that adhere to our guiding principles. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF. For more information, visit <a href="http://incubator.apache.org/" target="_blank" style="background-color: rgb(255, 255, 255);">http://incubator.apache.org/</a>&nbsp;</p>
<p><span style="font-size: 14px;"><b>About The Apache Software Foundation (ASF)<br></b></span>Established in 1999, The Apache Software Foundation (ASF) is the world&rsquo;s largest Open Source foundation, stewarding 200M+ lines of code and providing more than $20B+ worth of software to the public at 100% no cost. The ASF&rsquo;s all-volunteer community grew from 21 original founders overseeing the Apache HTTP Server to 765 individual Members and 206 Project Management Committees who successfully lead 350+ Apache projects and initiatives in collaboration with 7,600 Committers through the ASF&rsquo;s meritocratic process known as "The Apache Way". Apache software is integral to nearly every end user computing device, from laptops to tablets to mobile devices across enterprises and mission-critical applications. Apache projects power most of the Internet, manage exabytes of data, execute teraflops of operations, and store billions of objects in virtually every industry. The commercially-friendly and permissive Apache License v2 is an Open Source industry standard, helping launch billion dollar corporations and benefiting countless users worldwide. The ASF is a US 501(c)(3) not-for-profit charitable organization funded by individual donations and corporate sponsors including Aetna, Alibaba Cloud Computing, Amazon Web Services, Anonymous, Baidu, Bloomberg, Budget Direct, Capital One, CarGurus, Cerner, Cloudera, Comcast, Facebook, Google, Handshake, Huawei, IBM, Indeed, Inspur, Leaseweb, Microsoft, Pineapple Fund, Red Hat, Target, Tencent, Union Investment, Verizon Media, and Workday. For more information, visit <a href="http://apache.org/" target="_blank" style="background-color: rgb(255, 255, 255);">http://apache.org/</a>&nbsp;and <a href="https://twitter.com/TheASF" target="_blank" style="background-color: rgb(255, 255, 255);">https://twitter.com/TheASF</a>&nbsp;</p>
<p><span style="font-size: 14px;">&copy; The Apache Software Foundation. "Apache", "Hudi", "Apache Hudi", "Hadoop", "Apache Hadoop", and "ApacheCon" are registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries. All other brands and trademarks are the property of their respective owners.</span></p>
<p><span style="font-size: 14px;"># # #</span></p>

  </div><a class="u-url" href="/foundation/entry/the-apache-software-foundation-announces64" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
