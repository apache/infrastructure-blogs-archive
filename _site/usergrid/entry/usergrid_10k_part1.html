<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Scaling Usergrid to over 10,000 requests/second - Part 1 | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Scaling Usergrid to over 10,000 requests/second - Part 1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="By Michael Russo Based on recent testing at Apigee, the upcoming Apache Usergrid 2 release is set to be the most scalable open-source Backend as a Service available. We were able to drive Usergrid to 10,000 transactions per second and, more importantly, found that Usergrid can scale horizontally. Here&#39;s the story of how we got there. What is Usergrid? Apache Usergrid is a software stack that enables you to run a (Backend-as-a-Service) BaaS that can store, index, and query JSON objects. It also enables you to manage assets and provide authentication, push notifications, and a host of other features useful to developers&mdash;especially those working on mobile apps. The project recently graduated from the Apache Incubator and is now a top-level project of the Apache Software Foundation (ASF). Usergrid is new at Apache, but Apigee has been using it in production for three years now as the foundation for Apigee&#39;s API BaaS product. What&#39;s new in Usergrid 2? Usergrid 2 features the same REST API as Usergrid 1, but under the hood just about everything has changed. Usergrid 2 includes a completely new persistence engine backed by Apache Cassandra and a query/indexing service backed by ElasticSearch. We brought ElasticSearch into Usergrid because the query/index service in Usergrid 1 was not performing well and was complex and difficult to maintain. ElasticSearch does a much better job of query/index than we could have done ourselves. Additionally, separating key-value persistence from index/query allows us to scale each concern separately. As the architecture of Usergrid changed drastically, we needed to have a new baseline performance benchmark to make sure the system scaled as well as, if not better than, it did before. Let&#39;s talk about how we tested. Our testing framework and approach The Usergrid team has invested a lot of time building repeatable test cases using the Gatling load-testing framework. Performance is a high priority for us and we need a way to validate performance metrics for every release candidate. As Usergrid is open source, so are our Usergrid-specific Gatling scenarios, which you can find here: stack/loadtests (on Github). Usergrid application benchmark One of our goals was to prove that we had the ability to scale more requests per second with more hardware, so we started small and worked our way up. As the first in our series of new benchmarking for Usergrid, we wanted to start with a trivial use case to establish a solid baseline for the application. All testing scenarios use the HTTP API and test the concurrency and performance of the requests. We inserted a few million entities that we could later read from the system. The test case itself was simple. Each entity has a UUID (universally unique identifier) property. For all the entities we had inserted, we randomly read them out by their UUID: GET /organization/application/collection/:entityUUID First, we tried scaling the Usergrid application by its configuration. We configured a higher number of connections to use for Cassandra and a higher number of threads for Tomcat to use. This actually yielded higher latencies and system resource usage for marginally the same throughput. We saw better throughput when there was less concurrency allowed. This made sense, but we needed more, and immediately added more Usergrid servers to verify horizontal scalability. What will it take to get to 10,000 RPS? # Usergrid Servers # Cassandra Nodes Peak Requests Per Second 6 4 1420 6 6 2248 10 6 3324 20 6 3820 Switch to nine c3.2xlarge instances for Cassandra 20 9 6321 Switch to nine c3.4xlarge instances for Cassandra 20 9 7237 30 9 9120 35 9 10268 Cassandra Performance It was time to see if Cassandra was keeping up. As we scaled up the load we found Cassandra read operation latencies were also increasing. Shouldn&#39;t Cassandra handle more, though? We observed a single Usergrid read by UUID was translating to about 10 read operations to cassandra. Optimization #1: reduce the number of read operations from Cassandra on our most trivial use case. Given what we know, we still decided to test up to a peak 10,000 RPS in the current state. &lt;img src=&quot;https://blogs.apache.org/usergrid/mediaresource/3edc219b-82f4-44fa-9a36-5d4d1a6bdf06&quot; alt=&quot;RPS statistics screen shot/&gt; The cluster was scaled horizontally (more nodes) until we needed to vertically scale (bigger nodes) Cassandra due to high CPU usage. We stopped at 10,268 Requests Per Second with 35 c3.xlarge Usergrid servers and 9 c3.4xlarge Cassandra nodes. By this point numerous opportunities for improvement were identified in the codebase, and we had already executed on some. We fully expect to reach the same throughput with much less infrastructure in the coming weeks. In fact, we&#39;ve already reached ~7,800 RPS with only 15 Usergrid servers since our benchmarking. Deployment/Runtime Architecture Here are the components that we used in our Usergrid performance testing: Tomcat 7.0.62 where the Usergrid WAR file is deployed Cassandra 2.0.15 w/ Astyanax client Elasticsearch 1.4.4 (not utilized in these tests) As part of benchmarking, we wanted to ensure that all configurations and deployment scenarios exactly matched how we would run a production cluster. The main configurations that are recommended for production use of Usergrid are: Usergrid (Application) Tomcat (Container) Cassandra (Database) 1 LOCAL QUORUM read and write consistency set for Cassandra operations Blocking IO connector ( required in Usergrid) 6+ node cluster size 2 Configure separate Keyspace used for Locks vs. Main Usergrid application Use HTTP 1.1 and ensure keepAlive is configured 3 Configure max # of connections used per Cassandra node to be 15 Non-SSL connector (SSL typically handled by a load balancer) Replication Factor = 3 What&#39;s Next? As part of this testing, not only did we identify code optimizations that we can quickly fix for huge performance gains, we also learned more about tuning our infrastructure to handle high concurrency. Having this baseline gives us the motivation to continually improve performance of the Usergrid application, reducing the cost for operating a BaaS platform at huge scale. This post is just the start of our performance series. Stay tuned, as we&rsquo;ll be publishing more results in the future for the following Usergrid scenarios: Query performance - this includes complex graph and geo-location queries Write performance - performance of directly writing entities as well as completing indexing Push Notification performance - this is a combination of query and write performance See you next time!" />
<meta property="og:description" content="By Michael Russo Based on recent testing at Apigee, the upcoming Apache Usergrid 2 release is set to be the most scalable open-source Backend as a Service available. We were able to drive Usergrid to 10,000 transactions per second and, more importantly, found that Usergrid can scale horizontally. Here&#39;s the story of how we got there. What is Usergrid? Apache Usergrid is a software stack that enables you to run a (Backend-as-a-Service) BaaS that can store, index, and query JSON objects. It also enables you to manage assets and provide authentication, push notifications, and a host of other features useful to developers&mdash;especially those working on mobile apps. The project recently graduated from the Apache Incubator and is now a top-level project of the Apache Software Foundation (ASF). Usergrid is new at Apache, but Apigee has been using it in production for three years now as the foundation for Apigee&#39;s API BaaS product. What&#39;s new in Usergrid 2? Usergrid 2 features the same REST API as Usergrid 1, but under the hood just about everything has changed. Usergrid 2 includes a completely new persistence engine backed by Apache Cassandra and a query/indexing service backed by ElasticSearch. We brought ElasticSearch into Usergrid because the query/index service in Usergrid 1 was not performing well and was complex and difficult to maintain. ElasticSearch does a much better job of query/index than we could have done ourselves. Additionally, separating key-value persistence from index/query allows us to scale each concern separately. As the architecture of Usergrid changed drastically, we needed to have a new baseline performance benchmark to make sure the system scaled as well as, if not better than, it did before. Let&#39;s talk about how we tested. Our testing framework and approach The Usergrid team has invested a lot of time building repeatable test cases using the Gatling load-testing framework. Performance is a high priority for us and we need a way to validate performance metrics for every release candidate. As Usergrid is open source, so are our Usergrid-specific Gatling scenarios, which you can find here: stack/loadtests (on Github). Usergrid application benchmark One of our goals was to prove that we had the ability to scale more requests per second with more hardware, so we started small and worked our way up. As the first in our series of new benchmarking for Usergrid, we wanted to start with a trivial use case to establish a solid baseline for the application. All testing scenarios use the HTTP API and test the concurrency and performance of the requests. We inserted a few million entities that we could later read from the system. The test case itself was simple. Each entity has a UUID (universally unique identifier) property. For all the entities we had inserted, we randomly read them out by their UUID: GET /organization/application/collection/:entityUUID First, we tried scaling the Usergrid application by its configuration. We configured a higher number of connections to use for Cassandra and a higher number of threads for Tomcat to use. This actually yielded higher latencies and system resource usage for marginally the same throughput. We saw better throughput when there was less concurrency allowed. This made sense, but we needed more, and immediately added more Usergrid servers to verify horizontal scalability. What will it take to get to 10,000 RPS? # Usergrid Servers # Cassandra Nodes Peak Requests Per Second 6 4 1420 6 6 2248 10 6 3324 20 6 3820 Switch to nine c3.2xlarge instances for Cassandra 20 9 6321 Switch to nine c3.4xlarge instances for Cassandra 20 9 7237 30 9 9120 35 9 10268 Cassandra Performance It was time to see if Cassandra was keeping up. As we scaled up the load we found Cassandra read operation latencies were also increasing. Shouldn&#39;t Cassandra handle more, though? We observed a single Usergrid read by UUID was translating to about 10 read operations to cassandra. Optimization #1: reduce the number of read operations from Cassandra on our most trivial use case. Given what we know, we still decided to test up to a peak 10,000 RPS in the current state. &lt;img src=&quot;https://blogs.apache.org/usergrid/mediaresource/3edc219b-82f4-44fa-9a36-5d4d1a6bdf06&quot; alt=&quot;RPS statistics screen shot/&gt; The cluster was scaled horizontally (more nodes) until we needed to vertically scale (bigger nodes) Cassandra due to high CPU usage. We stopped at 10,268 Requests Per Second with 35 c3.xlarge Usergrid servers and 9 c3.4xlarge Cassandra nodes. By this point numerous opportunities for improvement were identified in the codebase, and we had already executed on some. We fully expect to reach the same throughput with much less infrastructure in the coming weeks. In fact, we&#39;ve already reached ~7,800 RPS with only 15 Usergrid servers since our benchmarking. Deployment/Runtime Architecture Here are the components that we used in our Usergrid performance testing: Tomcat 7.0.62 where the Usergrid WAR file is deployed Cassandra 2.0.15 w/ Astyanax client Elasticsearch 1.4.4 (not utilized in these tests) As part of benchmarking, we wanted to ensure that all configurations and deployment scenarios exactly matched how we would run a production cluster. The main configurations that are recommended for production use of Usergrid are: Usergrid (Application) Tomcat (Container) Cassandra (Database) 1 LOCAL QUORUM read and write consistency set for Cassandra operations Blocking IO connector ( required in Usergrid) 6+ node cluster size 2 Configure separate Keyspace used for Locks vs. Main Usergrid application Use HTTP 1.1 and ensure keepAlive is configured 3 Configure max # of connections used per Cassandra node to be 15 Non-SSL connector (SSL typically handled by a load balancer) Replication Factor = 3 What&#39;s Next? As part of this testing, not only did we identify code optimizations that we can quickly fix for huge performance gains, we also learned more about tuning our infrastructure to handle high concurrency. Having this baseline gives us the motivation to continually improve performance of the Usergrid application, reducing the cost for operating a BaaS platform at huge scale. This post is just the start of our performance series. Stay tuned, as we&rsquo;ll be publishing more results in the future for the following Usergrid scenarios: Query performance - this includes complex graph and geo-location queries Write performance - performance of directly writing entities as well as completing indexing Push Notification performance - this is a combination of query and write performance See you next time!" />
<link rel="canonical" href="http://localhost:4000/usergrid/entry/usergrid_10k_part1" />
<meta property="og:url" content="http://localhost:4000/usergrid/entry/usergrid_10k_part1" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2015-09-16T22:06:37-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Scaling Usergrid to over 10,000 requests/second - Part 1" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2015-09-16T22:06:37-04:00","datePublished":"2015-09-16T22:06:37-04:00","description":"By Michael Russo Based on recent testing at Apigee, the upcoming Apache Usergrid 2 release is set to be the most scalable open-source Backend as a Service available. We were able to drive Usergrid to 10,000 transactions per second and, more importantly, found that Usergrid can scale horizontally. Here&#39;s the story of how we got there. What is Usergrid? Apache Usergrid is a software stack that enables you to run a (Backend-as-a-Service) BaaS that can store, index, and query JSON objects. It also enables you to manage assets and provide authentication, push notifications, and a host of other features useful to developers&mdash;especially those working on mobile apps. The project recently graduated from the Apache Incubator and is now a top-level project of the Apache Software Foundation (ASF). Usergrid is new at Apache, but Apigee has been using it in production for three years now as the foundation for Apigee&#39;s API BaaS product. What&#39;s new in Usergrid 2? Usergrid 2 features the same REST API as Usergrid 1, but under the hood just about everything has changed. Usergrid 2 includes a completely new persistence engine backed by Apache Cassandra and a query/indexing service backed by ElasticSearch. We brought ElasticSearch into Usergrid because the query/index service in Usergrid 1 was not performing well and was complex and difficult to maintain. ElasticSearch does a much better job of query/index than we could have done ourselves. Additionally, separating key-value persistence from index/query allows us to scale each concern separately. As the architecture of Usergrid changed drastically, we needed to have a new baseline performance benchmark to make sure the system scaled as well as, if not better than, it did before. Let&#39;s talk about how we tested. Our testing framework and approach The Usergrid team has invested a lot of time building repeatable test cases using the Gatling load-testing framework. Performance is a high priority for us and we need a way to validate performance metrics for every release candidate. As Usergrid is open source, so are our Usergrid-specific Gatling scenarios, which you can find here: stack/loadtests (on Github). Usergrid application benchmark One of our goals was to prove that we had the ability to scale more requests per second with more hardware, so we started small and worked our way up. As the first in our series of new benchmarking for Usergrid, we wanted to start with a trivial use case to establish a solid baseline for the application. All testing scenarios use the HTTP API and test the concurrency and performance of the requests. We inserted a few million entities that we could later read from the system. The test case itself was simple. Each entity has a UUID (universally unique identifier) property. For all the entities we had inserted, we randomly read them out by their UUID: GET /organization/application/collection/:entityUUID First, we tried scaling the Usergrid application by its configuration. We configured a higher number of connections to use for Cassandra and a higher number of threads for Tomcat to use. This actually yielded higher latencies and system resource usage for marginally the same throughput. We saw better throughput when there was less concurrency allowed. This made sense, but we needed more, and immediately added more Usergrid servers to verify horizontal scalability. What will it take to get to 10,000 RPS? # Usergrid Servers # Cassandra Nodes Peak Requests Per Second 6 4 1420 6 6 2248 10 6 3324 20 6 3820 Switch to nine c3.2xlarge instances for Cassandra 20 9 6321 Switch to nine c3.4xlarge instances for Cassandra 20 9 7237 30 9 9120 35 9 10268 Cassandra Performance It was time to see if Cassandra was keeping up. As we scaled up the load we found Cassandra read operation latencies were also increasing. Shouldn&#39;t Cassandra handle more, though? We observed a single Usergrid read by UUID was translating to about 10 read operations to cassandra. Optimization #1: reduce the number of read operations from Cassandra on our most trivial use case. Given what we know, we still decided to test up to a peak 10,000 RPS in the current state. &lt;img src=&quot;https://blogs.apache.org/usergrid/mediaresource/3edc219b-82f4-44fa-9a36-5d4d1a6bdf06&quot; alt=&quot;RPS statistics screen shot/&gt; The cluster was scaled horizontally (more nodes) until we needed to vertically scale (bigger nodes) Cassandra due to high CPU usage. We stopped at 10,268 Requests Per Second with 35 c3.xlarge Usergrid servers and 9 c3.4xlarge Cassandra nodes. By this point numerous opportunities for improvement were identified in the codebase, and we had already executed on some. We fully expect to reach the same throughput with much less infrastructure in the coming weeks. In fact, we&#39;ve already reached ~7,800 RPS with only 15 Usergrid servers since our benchmarking. Deployment/Runtime Architecture Here are the components that we used in our Usergrid performance testing: Tomcat 7.0.62 where the Usergrid WAR file is deployed Cassandra 2.0.15 w/ Astyanax client Elasticsearch 1.4.4 (not utilized in these tests) As part of benchmarking, we wanted to ensure that all configurations and deployment scenarios exactly matched how we would run a production cluster. The main configurations that are recommended for production use of Usergrid are: Usergrid (Application) Tomcat (Container) Cassandra (Database) 1 LOCAL QUORUM read and write consistency set for Cassandra operations Blocking IO connector ( required in Usergrid) 6+ node cluster size 2 Configure separate Keyspace used for Locks vs. Main Usergrid application Use HTTP 1.1 and ensure keepAlive is configured 3 Configure max # of connections used per Cassandra node to be 15 Non-SSL connector (SSL typically handled by a load balancer) Replication Factor = 3 What&#39;s Next? As part of this testing, not only did we identify code optimizations that we can quickly fix for huge performance gains, we also learned more about tuning our infrastructure to handle high concurrency. Having this baseline gives us the motivation to continually improve performance of the Usergrid application, reducing the cost for operating a BaaS platform at huge scale. This post is just the start of our performance series. Stay tuned, as we&rsquo;ll be publishing more results in the future for the following Usergrid scenarios: Query performance - this includes complex graph and geo-location queries Write performance - performance of directly writing entities as well as completing indexing Push Notification performance - this is a combination of query and write performance See you next time!","headline":"Scaling Usergrid to over 10,000 requests/second - Part 1","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/usergrid/entry/usergrid_10k_part1"},"url":"http://localhost:4000/usergrid/entry/usergrid_10k_part1"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Scaling Usergrid to over 10,000 requests/second - Part 1</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2015-09-16T22:06:37-04:00" itemprop="datePublished">Sep 16, 2015
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Dave Johnson", "login"=>"snoopdave", "email"=>"snoopdave@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>By Michael Russo</p>
<p>Based on recent testing at Apigee, the upcoming Apache Usergrid 2 release is set to be the most scalable open-source Backend as a Service available. We were able to drive Usergrid to 10,000 transactions per second and, more importantly, found that Usergrid can scale horizontally. Here's the story of how we got there.</p>
<h3>What is Usergrid?</h3>
<p>Apache Usergrid is a software stack that enables you to run a (Backend-as-a-Service) BaaS that can store, index, and query JSON objects. It also enables you to manage assets and provide authentication, push notifications, and a host of other features useful to developers&mdash;especially those working on mobile apps. </p>
<p>The project recently graduated from the Apache Incubator and is now a top-level project of the Apache Software Foundation (ASF). Usergrid is new at Apache, but Apigee has been using it in production for three years now as the foundation for Apigee's API BaaS product.</p>
<h3>What's new in Usergrid 2?</h3>
<p>Usergrid 2 features the same REST API as Usergrid 1, but under the hood just about everything has changed. Usergrid 2 includes a completely new persistence engine backed by Apache Cassandra and a query/indexing service backed by ElasticSearch.  We brought ElasticSearch into Usergrid because the query/index service in Usergrid 1 was not performing well and was complex and difficult to maintain. ElasticSearch does a much better job of query/index than we could have done ourselves. Additionally, separating key-value persistence from index/query allows us to scale each concern separately.</p>
<p>As the architecture of Usergrid changed drastically, we needed to have a new baseline performance benchmark to make sure the system scaled as well as, if not better than, it did before. Let's talk about how we tested.</p>
<h3>Our testing framework and approach</h3>
<p>The Usergrid team has invested a lot of time building repeatable test cases using the Gatling load-testing framework. Performance is a high priority for us and we need a way to validate performance metrics for every release candidate. </p>
<p>As Usergrid is open source, so are our Usergrid-specific Gatling scenarios, which you can find here: <a href="https://github.com/apache/usergrid/tree/two-dot-o-dev/stack/loadtests">stack/loadtests</a> (on Github).</p>
<h3>Usergrid application benchmark</h3>
<p>One of our goals was to prove that we had the ability to scale more requests per second with more hardware, so we started small and worked our way up.</p>
<p>As the first in our series of new benchmarking for Usergrid, we wanted to start with a trivial use case to establish a solid baseline for the application. All testing scenarios use the HTTP API and test the concurrency and performance of the requests. We inserted a few million entities that we could later read from the system. The test case itself was simple. Each entity has a UUID (universally unique identifier) property. For all the entities we had inserted, we randomly read them out by their UUID:</p>
<pre>GET /organization/application/collection/:entityUUID</pre>
<p>First, we tried scaling the Usergrid application by its configuration. We configured a higher number of connections to use for Cassandra and a higher number of threads for Tomcat to use.  This actually yielded higher latencies and system resource usage for marginally the same throughput. We saw better throughput when there was less concurrency allowed. This made sense, but we needed more, and immediately added more Usergrid servers to verify horizontal scalability. What will it take to get to 10,000 RPS?</p>
<table width="90%" class="blog-table">
<tr style="background: #eee">
<th># Usergrid Servers</th>
<th># Cassandra Nodes</th>
<th>Peak Requests Per Second</th>
</tr>
<tr>
<td>6</td>
<td>4</td>
<td>1420</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>2248</td>
</tr>
<tr>
<td>10</td>
<td>6</td>
<td>3324</td>
</tr>
<tr>
<td>20</td>
<td>6</td>
<td>3820</td>
</tr>
<tr style="background: #eee">
<td colspan="3">
	Switch to nine c3.2xlarge instances for Cassandra
	</td>
</tr>
<tr>
<td>20</td>
<td>9</td>
<td>6321</td>
</tr>
<tr style="background: #eee">
<td colspan="3">
	Switch to nine c3.4xlarge instances for Cassandra
	</td>
</tr>
<tr>
<td>20</td>
<td>9</td>
<td>7237</td>
</tr>
<tr>
<td>30</td>
<td>9</td>
<td>9120</td>
</tr>
<tr>
<td>35</td>
<td>9</td>
<td>10268</td>
</tr>
</table>
<h3>Cassandra Performance</h3>
<p>It was time to see if Cassandra was keeping up. As we scaled up the load we found Cassandra read operation latencies were also increasing. Shouldn't Cassandra handle more, though? We observed a single Usergrid read by UUID was translating to about 10 read operations to cassandra. Optimization #1: reduce the number of read operations from Cassandra on our most trivial use case. Given what we know, we still decided to test up to a peak 10,000 RPS in the current state.  </p>
<p><img src="https://blogs.apache.org/usergrid/mediaresource/5dea6bbc-461e-4ae2-b0c9-372c733a8c70" alt="RPS screen shot"/></p>
<p><img src="https://blogs.apache.org/usergrid/mediaresource/3edc219b-82f4-44fa-9a36-5d4d1a6bdf06" alt="RPS statistics screen shot/></p>
<p>The cluster was scaled horizontally (more nodes) until we needed to vertically scale (bigger nodes) Cassandra due to high CPU usage.  We stopped at 10,268 Requests Per Second with 35 c3.xlarge Usergrid servers and 9 c3.4xlarge Cassandra nodes. By this point numerous opportunities for improvement were identified in the codebase, and we had already executed on some. We fully expect to reach the same throughput with much less infrastructure in the coming weeks. In fact, we've already reached ~7,800 RPS with only 15 Usergrid servers since our benchmarking.</p>
<h3>Deployment/Runtime Architecture</h3>
<p>Here are the components that we used in our Usergrid performance testing:</p>
<ul>
<li>Tomcat 7.0.62 where the Usergrid WAR file is deployed</li>
<li>Cassandra 2.0.15 w/ Astyanax client</li>
<li>Elasticsearch 1.4.4 (not utilized in these tests)</li>
</ul>
<p>As part of benchmarking, we wanted to ensure that all configurations and deployment scenarios exactly matched how we would run a production cluster.  The main configurations that are recommended for production use of Usergrid are:</p>
<table style="width:90%" class="blog-table">
<tr style="background: #eee">
<th></th>
<th>Usergrid (Application)</th>
<th>Tomcat (Container)</th>
<th>Cassandra (Database)</th>
</tr>
<tr>
<td style="background: #eee">1</td>
<td>LOCAL QUORUM read and write consistency set for Cassandra operations</td>
<td>Blocking IO connector ( required in Usergrid)</td>
<td>6+ node cluster size</td>
</tr>
<tr>
<td style="background: #eee">2</td>
<td>Configure separate Keyspace used for Locks vs. Main Usergrid application</td>
<td>Use HTTP 1.1 and ensure keepAlive is configured</td>
<td></td>
</tr>
<tr>
<td style="background: #eee">3</td>
<td>Configure max # of connections used per Cassandra node to be 15</td>
<td>Non-SSL connector (SSL typically handled by a load balancer)</td>
<td width="20%">Replication Factor = 3</td>
</tr>
</table>
<h3>What's Next?</h3>
<p>As part of this testing, not only did we identify code optimizations that we can quickly fix for huge performance gains, we also learned more about tuning our infrastructure to handle high concurrency. Having this baseline gives us the motivation to continually improve performance of the Usergrid application, reducing the cost for operating a BaaS platform at huge scale.</p>
<p>This post is just the start of our performance series.  Stay tuned, as we&rsquo;ll be publishing more results in the future for the following Usergrid scenarios:</p>
<ul>
<li>Query performance - this includes complex graph and geo-location queries</li>
<li>Write performance - performance of directly writing entities as well as completing indexing</li>
<li>Push Notification performance - this is a combination of query and write performance</li>
</ul>
<p>See you next time!</p>

  </div><a class="u-url" href="/usergrid/entry/usergrid_10k_part1" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
