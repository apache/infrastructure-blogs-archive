---
layout: post
status: PUBLISHED
published: true
title: Apache Hama announces v0.7 Release!
author:
  display_name: Edward J. Yoon
  login: edwardyoon
  email: edwardyoon@apache.org
author_login: edwardyoon
author_email: edwardyoon@apache.org
id: 4dc84550-e986-48e9-9386-6f7516f97eb7
date: '2015-06-15 04:04:35 -0400'
categories:
- News
tags: []
comments: []
permalink: hama/entry/apache_hama_announces_v0_7
---
<p>Apache Hama team is pleased to announce the release of Hama v0.7 with new features and improvements.</p>
<p>Hama is a High-Performance BSP computing engine, which can be used to perform compute-intensive general scientific BSP applications, Google&rsquo;s Pregel-like graph applications, and machine learning algorithms.</p>
<p><b>What are the major changes from the last release?</b></p>
<p>The important new feature of this release is that support the Mesos and Yet Another Resource Negotiator (YARN), so you&rsquo;re able to submit your BSP applications to the existing open source and enterprise clusters e.g., CDH, HDP, and Mesosphere without any installation. In addition, we reinforced machine learning package by adding algorithms such as Max-Flow, K-Core, ANN, ..., etc.</p>
<p>There are also big improvements in the queue and messaging systems. We now use own outgoing/incoming message manager instead of using Java's built-in queues. It stores messages in serialized form in a set of bundles (or a single bundle) to reduce the memory usage and RPC overhead. Unsafe serialization is used to serialize Vertex and its message objects more quickly. Another important improvement is the enhanced graph package. Instead of sending each message individually, we package the messages per vertex and send a packaged message to their assigned destination nodes. With this we achieved significant improvement in the performance of graph applications. The attached benchmarks were done to test scalability and performance of PageRank algorithm for random generated 1 billion edges graph using Apache Hama and Giraph on Amazon EMR 30 nodes cluster. Note that the aggregators was used for detecting the convergence condition in case of Apache Hama.</p>
<table align="center">
<tr>
<td><img src="https://lh5.googleusercontent.com/-iRaQhZbiO3o/VWujxDoSM8I/AAAAAAAAE-Y/Iodd-tc2yrg/w433-h289-no/201505211353771_EM6S04A2%255B1%255D.gif" height="240">
</td>
<td><img src="https://lh3.googleusercontent.com/-KR3TQNELI-A/VWujxPIqfCI/AAAAAAAAE-U/BxWzPhZFuL4/w482-h290-no/201505150920041_LK7CT9SZ%255B1%255D.gif" height="240">
</td>
</tr>
</table>
<p><b>What&rsquo;s Next?</b></p>
<p>After a month of testing and benchmarking this version will bring substantial performance improvements together with important bug fixes which significantly improve the platform stability. We look forward to add more and more and see our community grow. The primary objective of the technical plans are:</p>
<ul>
<li>Add stream input format for listening messages coming from 3rd party applications, and incremental learning algorithms.</li>
<li>Improve reliability of system e.g., fault tolerance, HA, ..., etc.</li>
<li>More machine learning algorithms, such as ensemble classifier, SVM, DNN, ..., etc</li>
</ul>
<p><b>Where I can download it?</b></p>
<p>The release artifacts are published and ready for you to download either from the Apache mirrors or from the Maven repository. We welcome your help, feedback, and suggestions. For more information on how to report problems, and to get involved, visit the Hama project website[1] and wiki[2]. </p>
<p>[1]. Apache Hama Website: <a href="https://hama.apache.org/">https://hama.apache.org/</a><br />
[2]. Apache Hama Wiki: <a href="https://wiki.apache.org/hama/">https://wiki.apache.org/hama/</a></p>
