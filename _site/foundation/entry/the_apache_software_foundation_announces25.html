<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Apache Software Foundation Announces Apache Sqoop as a Top-Level Project | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="The Apache Software Foundation Announces Apache Sqoop as a Top-Level Project" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Open Source big data tool used for efficient bulk transfer between Apache Hadoop and structured datastores. Forest Hill, MD --The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of nearly 150 Open Source projects and initiatives, today announced that Apache Sqoop has graduated from the Apache Incubator to become a Top-Level Project (TLP), signifying that the Project&rsquo;s community and products have been well-governed under the ASF&#39;s meritocratic process and principles. Designed to efficiently transfer bulk data between Apache Hadoop and structured datastores such as relational databases, Apache Sqoop allows the import of data from external datastores and enterprise data warehouses into Hadoop Distributed File System or related systems like Apache Hive and HBase. &quot;The Sqoop Project has demonstrated its maturity by graduating from the Apache Incubator,&quot; explained Arvind Prabhakar, Vice President of Apache Sqoop. &quot;With jobs transferring data on the order of billions of rows, Sqoop is proving its value as a critical component of production environments.&quot; Building on the Hadoop infrastructure, Sqoop parallelizes data transfer for fast performance and best utilization of system and network resources. In addition, Sqoop allows fast copying of data from external systems to Hadoop to make data analysis more efficient and mitigates the risk of excessive load to external systems.&nbsp; &quot;Connectivity to other databases and warehouses is a critical component for the evolution of Hadoop as an enterprise solution, and that&#39;s where Sqoop plays a very important role&quot; said Deepak Reddy, Hadoop Manager at Coupons.com. &quot;We use Sqoop extensively to store and exchange data between Hadoop and other warehouses like Netezza. The power of Sqoop also comes in the ability to write free-form queries against structured databases and pull that data into Hadoop.&quot; &quot;Sqoop has been an integral part of our production data pipeline&quot; said Bohan Chen, Director of the Hadoop Development and Operations team at Apollo Group. &quot;It provides a reliable and scalable way to import data from relational databases and export the aggregation results to relational databases.&quot; Since entering the Apache Incubator in June 2011, Sqoop was quickly embraced as an ideal SQL-to-Hadoop data transfer solution. The Project provides connectors for popular systems such as MySQL, PostgreSQL, Oracle, SQL Server and DB2, and also allows for the development of drop-in connectors that provide high speed connectivity with specialized systems like enterprise data warehouses. Craig Ling, Director of Business Systems at Tsavo Media, said &quot;We adopted the use of Sqoop to transfer data into and out of Hadoop with our other systems over a year ago. It is straight forward and easy to use, which has opened the door to allow team members to start consuming data autonomously, maximizing the analytical value of our data repositories.&quot; Availability and Oversight &lt;/p&gt; Apache Sqoop software is released under the Apache License v2.0, and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. Apache Sqoop source code, documentation, mailing lists, and related resources are available at http://sqoop.apache.org/. A timeline of the project&#39;s history through graduation from the Apache Incubator is also available. About The Apache Software Foundation (ASF) Established in 1999, the all-volunteer Foundation oversees nearly one hundred fifty leading Open Source projects, including Apache HTTP Server &mdash; the world&#39;s most popular Web server software. Through the ASF&#39;s meritocratic process known as &quot;The Apache Way,&quot; more than 350 individual Members and 3,000 Committers successfully collaborate to develop freely available enterprise-grade software, benefiting millions of users worldwide: thousands of software solutions are distributed under the Apache License; and the community actively participates in ASF mailing lists, mentoring initiatives, and ApacheCon, the Foundation&#39;s official user conference, trainings, and expo. The ASF is a US 501(3)(c) not-for-profit charity, funded by individual donations and corporate sponsors including AMD, Basis Technology, Cloudera, Facebook, Google, IBM, HP, Hortonworks, Matt Mullenweg, Microsoft, PSW Group, SpringSource/VMware, and Yahoo!. For more information, visit&nbsp;http://www.apache.org/. &quot;Apache&quot;, &quot;Apache Sqoop&quot;, and &quot;ApacheCon&quot; are trademarks of The Apache Software Foundation. All other brands and trademarks are the property of their respective owners. # &nbsp;# &nbsp;#" />
<meta property="og:description" content="Open Source big data tool used for efficient bulk transfer between Apache Hadoop and structured datastores. Forest Hill, MD --The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of nearly 150 Open Source projects and initiatives, today announced that Apache Sqoop has graduated from the Apache Incubator to become a Top-Level Project (TLP), signifying that the Project&rsquo;s community and products have been well-governed under the ASF&#39;s meritocratic process and principles. Designed to efficiently transfer bulk data between Apache Hadoop and structured datastores such as relational databases, Apache Sqoop allows the import of data from external datastores and enterprise data warehouses into Hadoop Distributed File System or related systems like Apache Hive and HBase. &quot;The Sqoop Project has demonstrated its maturity by graduating from the Apache Incubator,&quot; explained Arvind Prabhakar, Vice President of Apache Sqoop. &quot;With jobs transferring data on the order of billions of rows, Sqoop is proving its value as a critical component of production environments.&quot; Building on the Hadoop infrastructure, Sqoop parallelizes data transfer for fast performance and best utilization of system and network resources. In addition, Sqoop allows fast copying of data from external systems to Hadoop to make data analysis more efficient and mitigates the risk of excessive load to external systems.&nbsp; &quot;Connectivity to other databases and warehouses is a critical component for the evolution of Hadoop as an enterprise solution, and that&#39;s where Sqoop plays a very important role&quot; said Deepak Reddy, Hadoop Manager at Coupons.com. &quot;We use Sqoop extensively to store and exchange data between Hadoop and other warehouses like Netezza. The power of Sqoop also comes in the ability to write free-form queries against structured databases and pull that data into Hadoop.&quot; &quot;Sqoop has been an integral part of our production data pipeline&quot; said Bohan Chen, Director of the Hadoop Development and Operations team at Apollo Group. &quot;It provides a reliable and scalable way to import data from relational databases and export the aggregation results to relational databases.&quot; Since entering the Apache Incubator in June 2011, Sqoop was quickly embraced as an ideal SQL-to-Hadoop data transfer solution. The Project provides connectors for popular systems such as MySQL, PostgreSQL, Oracle, SQL Server and DB2, and also allows for the development of drop-in connectors that provide high speed connectivity with specialized systems like enterprise data warehouses. Craig Ling, Director of Business Systems at Tsavo Media, said &quot;We adopted the use of Sqoop to transfer data into and out of Hadoop with our other systems over a year ago. It is straight forward and easy to use, which has opened the door to allow team members to start consuming data autonomously, maximizing the analytical value of our data repositories.&quot; Availability and Oversight &lt;/p&gt; Apache Sqoop software is released under the Apache License v2.0, and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. Apache Sqoop source code, documentation, mailing lists, and related resources are available at http://sqoop.apache.org/. A timeline of the project&#39;s history through graduation from the Apache Incubator is also available. About The Apache Software Foundation (ASF) Established in 1999, the all-volunteer Foundation oversees nearly one hundred fifty leading Open Source projects, including Apache HTTP Server &mdash; the world&#39;s most popular Web server software. Through the ASF&#39;s meritocratic process known as &quot;The Apache Way,&quot; more than 350 individual Members and 3,000 Committers successfully collaborate to develop freely available enterprise-grade software, benefiting millions of users worldwide: thousands of software solutions are distributed under the Apache License; and the community actively participates in ASF mailing lists, mentoring initiatives, and ApacheCon, the Foundation&#39;s official user conference, trainings, and expo. The ASF is a US 501(3)(c) not-for-profit charity, funded by individual donations and corporate sponsors including AMD, Basis Technology, Cloudera, Facebook, Google, IBM, HP, Hortonworks, Matt Mullenweg, Microsoft, PSW Group, SpringSource/VMware, and Yahoo!. For more information, visit&nbsp;http://www.apache.org/. &quot;Apache&quot;, &quot;Apache Sqoop&quot;, and &quot;ApacheCon&quot; are trademarks of The Apache Software Foundation. All other brands and trademarks are the property of their respective owners. # &nbsp;# &nbsp;#" />
<link rel="canonical" href="http://localhost:4000/foundation/entry/the_apache_software_foundation_announces25" />
<meta property="og:url" content="http://localhost:4000/foundation/entry/the_apache_software_foundation_announces25" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-04-02T19:25:15-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Apache Software Foundation Announces Apache Sqoop as a Top-Level Project" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2012-04-02T19:25:15-04:00","datePublished":"2012-04-02T19:25:15-04:00","description":"Open Source big data tool used for efficient bulk transfer between Apache Hadoop and structured datastores. Forest Hill, MD --The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of nearly 150 Open Source projects and initiatives, today announced that Apache Sqoop has graduated from the Apache Incubator to become a Top-Level Project (TLP), signifying that the Project&rsquo;s community and products have been well-governed under the ASF&#39;s meritocratic process and principles. Designed to efficiently transfer bulk data between Apache Hadoop and structured datastores such as relational databases, Apache Sqoop allows the import of data from external datastores and enterprise data warehouses into Hadoop Distributed File System or related systems like Apache Hive and HBase. &quot;The Sqoop Project has demonstrated its maturity by graduating from the Apache Incubator,&quot; explained Arvind Prabhakar, Vice President of Apache Sqoop. &quot;With jobs transferring data on the order of billions of rows, Sqoop is proving its value as a critical component of production environments.&quot; Building on the Hadoop infrastructure, Sqoop parallelizes data transfer for fast performance and best utilization of system and network resources. In addition, Sqoop allows fast copying of data from external systems to Hadoop to make data analysis more efficient and mitigates the risk of excessive load to external systems.&nbsp; &quot;Connectivity to other databases and warehouses is a critical component for the evolution of Hadoop as an enterprise solution, and that&#39;s where Sqoop plays a very important role&quot; said Deepak Reddy, Hadoop Manager at Coupons.com. &quot;We use Sqoop extensively to store and exchange data between Hadoop and other warehouses like Netezza. The power of Sqoop also comes in the ability to write free-form queries against structured databases and pull that data into Hadoop.&quot; &quot;Sqoop has been an integral part of our production data pipeline&quot; said Bohan Chen, Director of the Hadoop Development and Operations team at Apollo Group. &quot;It provides a reliable and scalable way to import data from relational databases and export the aggregation results to relational databases.&quot; Since entering the Apache Incubator in June 2011, Sqoop was quickly embraced as an ideal SQL-to-Hadoop data transfer solution. The Project provides connectors for popular systems such as MySQL, PostgreSQL, Oracle, SQL Server and DB2, and also allows for the development of drop-in connectors that provide high speed connectivity with specialized systems like enterprise data warehouses. Craig Ling, Director of Business Systems at Tsavo Media, said &quot;We adopted the use of Sqoop to transfer data into and out of Hadoop with our other systems over a year ago. It is straight forward and easy to use, which has opened the door to allow team members to start consuming data autonomously, maximizing the analytical value of our data repositories.&quot; Availability and Oversight &lt;/p&gt; Apache Sqoop software is released under the Apache License v2.0, and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project&#39;s day-to-day operations, including community development and product releases. Apache Sqoop source code, documentation, mailing lists, and related resources are available at http://sqoop.apache.org/. A timeline of the project&#39;s history through graduation from the Apache Incubator is also available. About The Apache Software Foundation (ASF) Established in 1999, the all-volunteer Foundation oversees nearly one hundred fifty leading Open Source projects, including Apache HTTP Server &mdash; the world&#39;s most popular Web server software. Through the ASF&#39;s meritocratic process known as &quot;The Apache Way,&quot; more than 350 individual Members and 3,000 Committers successfully collaborate to develop freely available enterprise-grade software, benefiting millions of users worldwide: thousands of software solutions are distributed under the Apache License; and the community actively participates in ASF mailing lists, mentoring initiatives, and ApacheCon, the Foundation&#39;s official user conference, trainings, and expo. The ASF is a US 501(3)(c) not-for-profit charity, funded by individual donations and corporate sponsors including AMD, Basis Technology, Cloudera, Facebook, Google, IBM, HP, Hortonworks, Matt Mullenweg, Microsoft, PSW Group, SpringSource/VMware, and Yahoo!. For more information, visit&nbsp;http://www.apache.org/. &quot;Apache&quot;, &quot;Apache Sqoop&quot;, and &quot;ApacheCon&quot; are trademarks of The Apache Software Foundation. All other brands and trademarks are the property of their respective owners. # &nbsp;# &nbsp;#","headline":"The Apache Software Foundation Announces Apache Sqoop as a Top-Level Project","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/foundation/entry/the_apache_software_foundation_announces25"},"url":"http://localhost:4000/foundation/entry/the_apache_software_foundation_announces25"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Apache Software Foundation Announces Apache Sqoop as a Top-Level Project</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2012-04-02T19:25:15-04:00" itemprop="datePublished">Apr 2, 2012
      </time>â€¢ <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Sally Khudairi", "login"=>"sk", "email"=>"sk@haloworldwide.com"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div><b><i>Open Source big data tool used for efficient bulk transfer between Apache Hadoop and structured datastores.</i></b></div>
<div></div>
<div><b>Forest Hill, MD --</b>The Apache Software Foundation (ASF), the all-volunteer developers, stewards, and incubators of nearly 150 Open Source projects and initiatives, today announced that Apache Sqoop has graduated from the Apache Incubator to become a Top-Level Project (TLP), signifying that the Project&rsquo;s community and products have been well-governed under the ASF's meritocratic process and principles.</div>
<div></div>
<div>Designed to efficiently transfer bulk data between Apache Hadoop and structured datastores such as relational databases, Apache Sqoop allows the import of data from external datastores and enterprise data warehouses into Hadoop Distributed File System or related systems like Apache Hive and HBase.</div>
<div></div>
<div>"The Sqoop Project has demonstrated its maturity by graduating from the Apache Incubator," explained Arvind Prabhakar, Vice President of Apache Sqoop. "With jobs transferring data on the order of billions of rows, Sqoop is proving its value as a critical component of production environments."</div>
<div></div>
<div>Building on the Hadoop infrastructure, Sqoop parallelizes data transfer for fast performance and best utilization of system and network resources. In addition, Sqoop allows fast copying of data from external systems to Hadoop to make data analysis more efficient and mitigates the risk of excessive load to external systems.&nbsp;</div>
<div></div>
<div>"Connectivity to other databases and warehouses is a critical component for the evolution of Hadoop as an enterprise solution, and that's where Sqoop plays a very important role" said Deepak Reddy, Hadoop Manager at Coupons.com. "We use Sqoop extensively to store and exchange data between Hadoop and other warehouses like Netezza. The power of Sqoop also comes in the ability to write free-form queries against structured databases and pull that data into Hadoop."</div>
<div></div>
<div>"Sqoop has been an integral part of our production data pipeline" said Bohan Chen, Director of the Hadoop Development and Operations team at Apollo Group. "It provides a reliable and scalable way to import data from relational databases and export the aggregation results to relational databases."</div>
<div></div>
<div>Since entering the Apache Incubator in June 2011, Sqoop was quickly embraced as an ideal SQL-to-Hadoop data transfer solution. The Project provides connectors for popular systems such as MySQL, PostgreSQL, Oracle, SQL Server and DB2, and also allows for the development of drop-in connectors that provide high speed connectivity with specialized systems like enterprise data warehouses.</div>
<div></div>
<div>
<p>Craig Ling, Director of Business Systems at Tsavo Media, said "We adopted the use of Sqoop to transfer data into and out of Hadoop with our other systems over a year ago. It is straight forward and easy to use, which has opened the door to allow team members to start consuming data autonomously, maximizing the analytical value of our data repositories."</p>
<p><b>Availability and Oversight</b></p>
</p></div>
<div>Apache Sqoop software is released under the Apache License v2.0, and is overseen by a self-selected team of active contributors to the project. A Project Management Committee (PMC) guides the Project's day-to-day operations, including community development and product releases. Apache Sqoop source code, documentation, mailing lists, and related resources are available at <a href="http://sqoop.apache.org/">http://sqoop.apache.org/</a>. A <a href="https://blogs.apache.org/sqoop/entry/apache_sqoop_graduates_from_incubator">timeline of the project's history</a> through graduation from the Apache Incubator is also available.</div>
<div></div>
<div><b>About The Apache Software Foundation (ASF)</b></div>
<div>Established in 1999, the all-volunteer Foundation oversees nearly one hundred fifty leading Open Source projects, including Apache HTTP Server &mdash; the world's most popular Web server software. Through the ASF's meritocratic process known as "The Apache Way," more than 350 individual Members and 3,000 Committers successfully collaborate to develop freely available enterprise-grade software, benefiting millions of users worldwide: thousands of software solutions are distributed under the Apache License; and the community actively participates in ASF mailing lists, mentoring initiatives, and ApacheCon, the Foundation's official user conference, trainings, and expo. The ASF is a US 501(3)(c) not-for-profit charity, funded by individual donations and corporate sponsors including AMD, Basis Technology, Cloudera, Facebook, Google, IBM, HP, Hortonworks, Matt Mullenweg, Microsoft, PSW Group, SpringSource/VMware, and Yahoo!. For more information, visit&nbsp;<a href="http://www.apache.org/">http://www.apache.org/.</a></div>
<div></div>
<div>"Apache", "Apache Sqoop", and "ApacheCon" are trademarks of The Apache Software Foundation. All other brands and trademarks are the property of their respective owners.</div>
<p># &nbsp;# &nbsp;#</p>

  </div><a class="u-url" href="/foundation/entry/the_apache_software_foundation_announces25" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
