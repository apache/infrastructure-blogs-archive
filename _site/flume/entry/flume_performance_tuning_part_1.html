<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Flume Performance Tuning - part 1 | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Flume Performance Tuning - part 1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is part 1 in a series of articles about tuning the performance of Apache Flume, a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of event data. To kick off this series, I&rsquo;d like to start off discussing some important Flume concepts that come into play when tuning your Flume flows for maximum performance: the channel and the transaction batch size. Setting up a data flow Imagine you want to take a heavy stream of user activity from your application server logs and store that onto your Hadoop cluster for analytics. If you have a large deployment of application servers, you would likely want to build a fan-in architecture, where you are sending data from many nodes to relatively fewer nodes. &lt;/p&gt; If you are sending these user events one at a time, each time waiting for acknowledgment that it was delivered, your throughput may be limited by network latency. Naturally, you would want to batch up the events into larger transactions, so that you amortize the latency of the acknowledgment over a larger number of events and therefore get more throughput. Channels So, what happens if the storage tier goes down momentarily, as in the case of a network partition? What happens to the events if a Flume agent machine crashes? We still want to be able to serve our users on the application tier and retain our data somehow. In order to accomplish this, we need a buffering mechanism on each agent that allows it to store events in the case of downstream failures or slowdowns. In Flume, the channel is what persists events at each hop in the flow. Below is a diagram that illustrates where the channel sits in the architecture of a Flume agent. &lt;/p&gt; Memory Channel vs. File Channel &lt;/strong&gt;An important decision to make when designing your Flume flow is what type of channel you want to use. At the time of this writing, the two recommended channels are the file channel and the memory channel. The file channel is a durable channel, as it persists all events that are stored in it to disk. So, even if the Java virtual machine is killed, or the operating system crashes or reboots, events that were not successfully transferred to the next agent in the pipeline will still be there when the Flume agent is restarted. The memory channel is a volatile channel, as it buffers events in memory only: if the Java process dies, any events stored in the memory channel are lost. Naturally, the memory channel also exhibits very low put/take latencies compared to the file channel, even for a batch size of 1. Since the number of events that can be stored is limited by available RAM, its ability to buffer events in the case of temporary downstream failure is quite limited. The file channel, on the other hand, has far superior buffering capability due to utilizing cheap, abundant hard disk space. Flume event batching As mentioned earlier, Flume can batch events. The batch size is the maximum number of events that a sink or client will attempt to take from a channel in a single transaction. Tuning the batch size trades throughput vs. latency and duplication under failure. With a small batch size, throughput decreases, but the risk of event duplication is reduced if a failure were to occur. With a large batch size, you get much better throughput, but increased latency, and in the case of a transaction failure, the number of possible duplicates increases. Transactions are a critical concept in Flume, because the delivery and durability guarantees made by channels only take effect at the end of each successful transaction. For example, when a source receives or generates an event, in order to store that event into a channel a transaction must first be opened on that channel. Within the transaction, the source puts up to the batch size number of events into the channel, and on success commits the transaction. A sink must go through the same process of operating within a transaction when taking events from a channel. Batch size is configured at the sink level. The larger the batch, the faster the channels operate (but there is a caveat). In the case of the file channel, this speed difference is because all buffers are flushed and then synced to disk when each transaction is committed. A disk sync is a time-consuming operation (it may take several milliseconds), but it is required to ensure the durability of the data. Likewise, with the memory channel, there is a memory synchronization step when each transaction is committed. Of course, memory synchronization is much faster than a disk sync. For more information on the inner workings of the file channel, please see Brock Noland&#39;s article about the Apache Flume File Channel. The downside of using a large batch size is that if there is some type of failure in the middle of a transaction, such as a downstream host or network failure, there is a possibility of duplicates being created. So, for example, if you set your batch size to 1000, and the machine you are writing to goes offline, duplicates may be generated in groups of up to 1000. This may occur in special cases, for example, if the events got written to the downstream machine but then the connection failed before it could acknowledge that it had received them. However, duplicate events will only appear in exceptional circumstances. &lt;/strong&gt; Choosing a batch size To squeeze all the performance possible out of a Flume system, batch sizes should be tuned with care through experimentation. While I will get into this in more detail in the follow-up to this post, here are some rules of thumb for selecting batch sizes. Start off with batch sizes equal to the sum of the batch sizes of the input streams coming into that tier. For example, if you have a downstream Flume agent running an Avro source with 10 upstream agents sending events via Avro sinks using a batch size of 100 each, consider starting that downstream agent with a batch size of 1,000. Tune / experiment from there. If you find yourself setting the batch size very high (say, higher than 10,000) then consider adding another Sink instead, in order to increase the parallelism (each sink typically runs on its own thread). Say you were going to use one HDFS sink with a batch size of 20,000. Experiment with using 2 HDFS sinks with batch sizes of 5,000 or 10,000 to see if that helps more. Prefer the lowest batch size that gives you acceptable performance. Monitor the steady-state channel sizes to get more tuning insight (more on this in the next article). Different batch sizes in different situations Due to the performance / duplication tradeoff of the batch size parameter, I often see varying batch size settings depending on the use case. In the case of using Flume to write to HBase using the HBase Sink, incrementing counters, a smaller batch size on the order of 100 is often used to reduce the impact in case of hiccups in the system. On the other hand, with an HDFS sink, in order to get maximum throughput, I see people running with batch sizes of 1,000 or even 10,000, since typically they can easily run map-reduce jobs to de-duplicate the data at processing time. Note that when writing large events with large batch sizes to HDFS, often other parameters need to be increased as well. One such parameter is hdfs.callTimeout, which may be increased to 60 seconds or more to account for the long tail of occasional higher-latency calls to HDFS. At the other end of the spectrum, in cases where batching events at the application (Flume client) tier is not possible, the memory channel is often used at the collector-tier Flume agent (or a localhost agent on the app servers) to get acceptable performance with a batch size of 1, while using larger batch sizes and file channels in the downstream agents in order to get most of the benefits of durability there. For the best performance, however, all tiers including the client/application tier would perform some level of batching. (Please see above diagram for an illustration of the tiers referenced in this scenario.) Configuration parameters and gotchas The actual parameter used to set the batch size varies between sinks, but for most sinks it&rsquo;s simply called batchSize or batch-size. For the HDFS sink, it&rsquo;s actually called hdfs.batchSize for historical reasons; I recommend setting hdfs.txnEventMax to the same value as hdfs.batchSize for simplicity. Historically, in the HDFS sink, the number of events taken in a single transaction can be different from the number of events written to HDFS before a sync() operation; In practice, there is little reason these should not be set to the same value. One potentially confusing gotcha when tuning the batch size on a sink is that it must be less than or equal to the transactionCapacity set on the corresponding channel. The transactionCapacity should be set to the value of the largest batch size that will be used to store or remove events from that channel. tl;dr: Below is a &ldquo;cheat sheet&rdquo; batch size tuning summary for your convenience. Please note that these are just starting points for tuning. Sink Type Config parameter Typical value Avro batch-size 100 HDFS hdfs.batchSize, hdfs.txnEventMax 1000 HBaseSink batchSize 100 AsyncHBaseSink batchSize 100 That&rsquo;s all I have space for in one blog post. Please leave feedback and questions in the comments. Look for another post in the future with tips on using Flume&rsquo;s monitoring capabilities to take advantage of important information which can aid you in your quest for optimum performance. Mike Percy is a committer and PMC member on the Apache Flume project." />
<meta property="og:description" content="This is part 1 in a series of articles about tuning the performance of Apache Flume, a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of event data. To kick off this series, I&rsquo;d like to start off discussing some important Flume concepts that come into play when tuning your Flume flows for maximum performance: the channel and the transaction batch size. Setting up a data flow Imagine you want to take a heavy stream of user activity from your application server logs and store that onto your Hadoop cluster for analytics. If you have a large deployment of application servers, you would likely want to build a fan-in architecture, where you are sending data from many nodes to relatively fewer nodes. &lt;/p&gt; If you are sending these user events one at a time, each time waiting for acknowledgment that it was delivered, your throughput may be limited by network latency. Naturally, you would want to batch up the events into larger transactions, so that you amortize the latency of the acknowledgment over a larger number of events and therefore get more throughput. Channels So, what happens if the storage tier goes down momentarily, as in the case of a network partition? What happens to the events if a Flume agent machine crashes? We still want to be able to serve our users on the application tier and retain our data somehow. In order to accomplish this, we need a buffering mechanism on each agent that allows it to store events in the case of downstream failures or slowdowns. In Flume, the channel is what persists events at each hop in the flow. Below is a diagram that illustrates where the channel sits in the architecture of a Flume agent. &lt;/p&gt; Memory Channel vs. File Channel &lt;/strong&gt;An important decision to make when designing your Flume flow is what type of channel you want to use. At the time of this writing, the two recommended channels are the file channel and the memory channel. The file channel is a durable channel, as it persists all events that are stored in it to disk. So, even if the Java virtual machine is killed, or the operating system crashes or reboots, events that were not successfully transferred to the next agent in the pipeline will still be there when the Flume agent is restarted. The memory channel is a volatile channel, as it buffers events in memory only: if the Java process dies, any events stored in the memory channel are lost. Naturally, the memory channel also exhibits very low put/take latencies compared to the file channel, even for a batch size of 1. Since the number of events that can be stored is limited by available RAM, its ability to buffer events in the case of temporary downstream failure is quite limited. The file channel, on the other hand, has far superior buffering capability due to utilizing cheap, abundant hard disk space. Flume event batching As mentioned earlier, Flume can batch events. The batch size is the maximum number of events that a sink or client will attempt to take from a channel in a single transaction. Tuning the batch size trades throughput vs. latency and duplication under failure. With a small batch size, throughput decreases, but the risk of event duplication is reduced if a failure were to occur. With a large batch size, you get much better throughput, but increased latency, and in the case of a transaction failure, the number of possible duplicates increases. Transactions are a critical concept in Flume, because the delivery and durability guarantees made by channels only take effect at the end of each successful transaction. For example, when a source receives or generates an event, in order to store that event into a channel a transaction must first be opened on that channel. Within the transaction, the source puts up to the batch size number of events into the channel, and on success commits the transaction. A sink must go through the same process of operating within a transaction when taking events from a channel. Batch size is configured at the sink level. The larger the batch, the faster the channels operate (but there is a caveat). In the case of the file channel, this speed difference is because all buffers are flushed and then synced to disk when each transaction is committed. A disk sync is a time-consuming operation (it may take several milliseconds), but it is required to ensure the durability of the data. Likewise, with the memory channel, there is a memory synchronization step when each transaction is committed. Of course, memory synchronization is much faster than a disk sync. For more information on the inner workings of the file channel, please see Brock Noland&#39;s article about the Apache Flume File Channel. The downside of using a large batch size is that if there is some type of failure in the middle of a transaction, such as a downstream host or network failure, there is a possibility of duplicates being created. So, for example, if you set your batch size to 1000, and the machine you are writing to goes offline, duplicates may be generated in groups of up to 1000. This may occur in special cases, for example, if the events got written to the downstream machine but then the connection failed before it could acknowledge that it had received them. However, duplicate events will only appear in exceptional circumstances. &lt;/strong&gt; Choosing a batch size To squeeze all the performance possible out of a Flume system, batch sizes should be tuned with care through experimentation. While I will get into this in more detail in the follow-up to this post, here are some rules of thumb for selecting batch sizes. Start off with batch sizes equal to the sum of the batch sizes of the input streams coming into that tier. For example, if you have a downstream Flume agent running an Avro source with 10 upstream agents sending events via Avro sinks using a batch size of 100 each, consider starting that downstream agent with a batch size of 1,000. Tune / experiment from there. If you find yourself setting the batch size very high (say, higher than 10,000) then consider adding another Sink instead, in order to increase the parallelism (each sink typically runs on its own thread). Say you were going to use one HDFS sink with a batch size of 20,000. Experiment with using 2 HDFS sinks with batch sizes of 5,000 or 10,000 to see if that helps more. Prefer the lowest batch size that gives you acceptable performance. Monitor the steady-state channel sizes to get more tuning insight (more on this in the next article). Different batch sizes in different situations Due to the performance / duplication tradeoff of the batch size parameter, I often see varying batch size settings depending on the use case. In the case of using Flume to write to HBase using the HBase Sink, incrementing counters, a smaller batch size on the order of 100 is often used to reduce the impact in case of hiccups in the system. On the other hand, with an HDFS sink, in order to get maximum throughput, I see people running with batch sizes of 1,000 or even 10,000, since typically they can easily run map-reduce jobs to de-duplicate the data at processing time. Note that when writing large events with large batch sizes to HDFS, often other parameters need to be increased as well. One such parameter is hdfs.callTimeout, which may be increased to 60 seconds or more to account for the long tail of occasional higher-latency calls to HDFS. At the other end of the spectrum, in cases where batching events at the application (Flume client) tier is not possible, the memory channel is often used at the collector-tier Flume agent (or a localhost agent on the app servers) to get acceptable performance with a batch size of 1, while using larger batch sizes and file channels in the downstream agents in order to get most of the benefits of durability there. For the best performance, however, all tiers including the client/application tier would perform some level of batching. (Please see above diagram for an illustration of the tiers referenced in this scenario.) Configuration parameters and gotchas The actual parameter used to set the batch size varies between sinks, but for most sinks it&rsquo;s simply called batchSize or batch-size. For the HDFS sink, it&rsquo;s actually called hdfs.batchSize for historical reasons; I recommend setting hdfs.txnEventMax to the same value as hdfs.batchSize for simplicity. Historically, in the HDFS sink, the number of events taken in a single transaction can be different from the number of events written to HDFS before a sync() operation; In practice, there is little reason these should not be set to the same value. One potentially confusing gotcha when tuning the batch size on a sink is that it must be less than or equal to the transactionCapacity set on the corresponding channel. The transactionCapacity should be set to the value of the largest batch size that will be used to store or remove events from that channel. tl;dr: Below is a &ldquo;cheat sheet&rdquo; batch size tuning summary for your convenience. Please note that these are just starting points for tuning. Sink Type Config parameter Typical value Avro batch-size 100 HDFS hdfs.batchSize, hdfs.txnEventMax 1000 HBaseSink batchSize 100 AsyncHBaseSink batchSize 100 That&rsquo;s all I have space for in one blog post. Please leave feedback and questions in the comments. Look for another post in the future with tips on using Flume&rsquo;s monitoring capabilities to take advantage of important information which can aid you in your quest for optimum performance. Mike Percy is a committer and PMC member on the Apache Flume project." />
<link rel="canonical" href="http://localhost:4000/flume/entry/flume_performance_tuning_part_1" />
<meta property="og:url" content="http://localhost:4000/flume/entry/flume_performance_tuning_part_1" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2013-01-11T20:05:41-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Flume Performance Tuning - part 1" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2013-01-11T20:05:41-05:00","datePublished":"2013-01-11T20:05:41-05:00","description":"This is part 1 in a series of articles about tuning the performance of Apache Flume, a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of event data. To kick off this series, I&rsquo;d like to start off discussing some important Flume concepts that come into play when tuning your Flume flows for maximum performance: the channel and the transaction batch size. Setting up a data flow Imagine you want to take a heavy stream of user activity from your application server logs and store that onto your Hadoop cluster for analytics. If you have a large deployment of application servers, you would likely want to build a fan-in architecture, where you are sending data from many nodes to relatively fewer nodes. &lt;/p&gt; If you are sending these user events one at a time, each time waiting for acknowledgment that it was delivered, your throughput may be limited by network latency. Naturally, you would want to batch up the events into larger transactions, so that you amortize the latency of the acknowledgment over a larger number of events and therefore get more throughput. Channels So, what happens if the storage tier goes down momentarily, as in the case of a network partition? What happens to the events if a Flume agent machine crashes? We still want to be able to serve our users on the application tier and retain our data somehow. In order to accomplish this, we need a buffering mechanism on each agent that allows it to store events in the case of downstream failures or slowdowns. In Flume, the channel is what persists events at each hop in the flow. Below is a diagram that illustrates where the channel sits in the architecture of a Flume agent. &lt;/p&gt; Memory Channel vs. File Channel &lt;/strong&gt;An important decision to make when designing your Flume flow is what type of channel you want to use. At the time of this writing, the two recommended channels are the file channel and the memory channel. The file channel is a durable channel, as it persists all events that are stored in it to disk. So, even if the Java virtual machine is killed, or the operating system crashes or reboots, events that were not successfully transferred to the next agent in the pipeline will still be there when the Flume agent is restarted. The memory channel is a volatile channel, as it buffers events in memory only: if the Java process dies, any events stored in the memory channel are lost. Naturally, the memory channel also exhibits very low put/take latencies compared to the file channel, even for a batch size of 1. Since the number of events that can be stored is limited by available RAM, its ability to buffer events in the case of temporary downstream failure is quite limited. The file channel, on the other hand, has far superior buffering capability due to utilizing cheap, abundant hard disk space. Flume event batching As mentioned earlier, Flume can batch events. The batch size is the maximum number of events that a sink or client will attempt to take from a channel in a single transaction. Tuning the batch size trades throughput vs. latency and duplication under failure. With a small batch size, throughput decreases, but the risk of event duplication is reduced if a failure were to occur. With a large batch size, you get much better throughput, but increased latency, and in the case of a transaction failure, the number of possible duplicates increases. Transactions are a critical concept in Flume, because the delivery and durability guarantees made by channels only take effect at the end of each successful transaction. For example, when a source receives or generates an event, in order to store that event into a channel a transaction must first be opened on that channel. Within the transaction, the source puts up to the batch size number of events into the channel, and on success commits the transaction. A sink must go through the same process of operating within a transaction when taking events from a channel. Batch size is configured at the sink level. The larger the batch, the faster the channels operate (but there is a caveat). In the case of the file channel, this speed difference is because all buffers are flushed and then synced to disk when each transaction is committed. A disk sync is a time-consuming operation (it may take several milliseconds), but it is required to ensure the durability of the data. Likewise, with the memory channel, there is a memory synchronization step when each transaction is committed. Of course, memory synchronization is much faster than a disk sync. For more information on the inner workings of the file channel, please see Brock Noland&#39;s article about the Apache Flume File Channel. The downside of using a large batch size is that if there is some type of failure in the middle of a transaction, such as a downstream host or network failure, there is a possibility of duplicates being created. So, for example, if you set your batch size to 1000, and the machine you are writing to goes offline, duplicates may be generated in groups of up to 1000. This may occur in special cases, for example, if the events got written to the downstream machine but then the connection failed before it could acknowledge that it had received them. However, duplicate events will only appear in exceptional circumstances. &lt;/strong&gt; Choosing a batch size To squeeze all the performance possible out of a Flume system, batch sizes should be tuned with care through experimentation. While I will get into this in more detail in the follow-up to this post, here are some rules of thumb for selecting batch sizes. Start off with batch sizes equal to the sum of the batch sizes of the input streams coming into that tier. For example, if you have a downstream Flume agent running an Avro source with 10 upstream agents sending events via Avro sinks using a batch size of 100 each, consider starting that downstream agent with a batch size of 1,000. Tune / experiment from there. If you find yourself setting the batch size very high (say, higher than 10,000) then consider adding another Sink instead, in order to increase the parallelism (each sink typically runs on its own thread). Say you were going to use one HDFS sink with a batch size of 20,000. Experiment with using 2 HDFS sinks with batch sizes of 5,000 or 10,000 to see if that helps more. Prefer the lowest batch size that gives you acceptable performance. Monitor the steady-state channel sizes to get more tuning insight (more on this in the next article). Different batch sizes in different situations Due to the performance / duplication tradeoff of the batch size parameter, I often see varying batch size settings depending on the use case. In the case of using Flume to write to HBase using the HBase Sink, incrementing counters, a smaller batch size on the order of 100 is often used to reduce the impact in case of hiccups in the system. On the other hand, with an HDFS sink, in order to get maximum throughput, I see people running with batch sizes of 1,000 or even 10,000, since typically they can easily run map-reduce jobs to de-duplicate the data at processing time. Note that when writing large events with large batch sizes to HDFS, often other parameters need to be increased as well. One such parameter is hdfs.callTimeout, which may be increased to 60 seconds or more to account for the long tail of occasional higher-latency calls to HDFS. At the other end of the spectrum, in cases where batching events at the application (Flume client) tier is not possible, the memory channel is often used at the collector-tier Flume agent (or a localhost agent on the app servers) to get acceptable performance with a batch size of 1, while using larger batch sizes and file channels in the downstream agents in order to get most of the benefits of durability there. For the best performance, however, all tiers including the client/application tier would perform some level of batching. (Please see above diagram for an illustration of the tiers referenced in this scenario.) Configuration parameters and gotchas The actual parameter used to set the batch size varies between sinks, but for most sinks it&rsquo;s simply called batchSize or batch-size. For the HDFS sink, it&rsquo;s actually called hdfs.batchSize for historical reasons; I recommend setting hdfs.txnEventMax to the same value as hdfs.batchSize for simplicity. Historically, in the HDFS sink, the number of events taken in a single transaction can be different from the number of events written to HDFS before a sync() operation; In practice, there is little reason these should not be set to the same value. One potentially confusing gotcha when tuning the batch size on a sink is that it must be less than or equal to the transactionCapacity set on the corresponding channel. The transactionCapacity should be set to the value of the largest batch size that will be used to store or remove events from that channel. tl;dr: Below is a &ldquo;cheat sheet&rdquo; batch size tuning summary for your convenience. Please note that these are just starting points for tuning. Sink Type Config parameter Typical value Avro batch-size 100 HDFS hdfs.batchSize, hdfs.txnEventMax 1000 HBaseSink batchSize 100 AsyncHBaseSink batchSize 100 That&rsquo;s all I have space for in one blog post. Please leave feedback and questions in the comments. Look for another post in the future with tips on using Flume&rsquo;s monitoring capabilities to take advantage of important information which can aid you in your quest for optimum performance. Mike Percy is a committer and PMC member on the Apache Flume project.","headline":"Flume Performance Tuning - part 1","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/flume/entry/flume_performance_tuning_part_1"},"url":"http://localhost:4000/flume/entry/flume_performance_tuning_part_1"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Flume Performance Tuning - part 1</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2013-01-11T20:05:41-05:00" itemprop="datePublished">Jan 11, 2013
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Mike Percy", "login"=>"mpercy", "email"=>"mpercy@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><strong id="internal-source-marker_0.846074462402612" style="font-weight: normal;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">This is part 1 in a series of articles about tuning the performance of </span><a href="http://flume.apache.org/"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">Apache Flume</span></a><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">, a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of event data.</span></strong></p>
<p><strong id="internal-source-marker_0.846074462402612" style="font-weight: normal;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span><strong id="internal-source-marker_0.846074462402612" style="font-weight: normal;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">To kick off this series, I&rsquo;d like to start off discussing some important Flume concepts that come into play when tuning your Flume flows for maximum performance: the </span><span style="background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;">channel</span><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> and the </span><span style="background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;">transaction batch size</span><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">.</span></strong></strong> </p>
<p><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"><b>Setting up a data flow</b></span></p>
<p><strong style="font-weight: normal;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Imagine you want to take a heavy stream of user activity from your application server logs and store that onto your Hadoop cluster for analytics. If you have a large deployment of application servers, you would likely want to build a fan-in architecture, where you are sending data from many nodes to relatively fewer nodes.</span></strong> </p>
<p><strong id="internal-source-marker_0.846074462402612"> </p>
<p style="font-weight: normal;">
<div style="text-align: center;"><strong id="internal-source-marker_0.846074462402612"><img src="https://blogs.apache.org/flume/mediaresource/a800177c-759c-4b7b-a34b-e9d6a7abeb17" alt="A Tiered Flume Topology" border="1" /></strong></div>
<p><span style="font-weight: normal;">If you are sending these user events one at a time, each time waiting for acknowledgment that it was delivered, your throughput may be limited by network latency. Naturally, you would want to batch up the events into larger transactions, so that you amortize the latency of the acknowledgment over a larger number of events and therefore get more throughput. </span> </p>
<p style="font-weight: normal;">
<p style="font-weight: normal;"><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Channels</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">So, what happens if the storage tier goes down momentarily, as in the case of a network partition? What happens to the events if a Flume agent machine crashes? We still want to be able to serve our users on the application tier and retain our data somehow. In order to accomplish this, we need a buffering mechanism on each agent that allows it to store events in the case of downstream failures or slowdowns. In Flume, the </span><span style="font-weight: normal; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;">channel</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> is what persists events at each hop in the flow. Below is a diagram that illustrates where the channel sits in the architecture of a Flume agent.</span><strong id="internal-source-marker_0.846074462402612"> </strong></p>
<p style="display: inline !important;"><strong id="internal-source-marker_0.846074462402612"> </strong></p></p>
<p style="font-weight: normal;">
<p style="text-align: center; font-weight: normal;"><img src="https://blogs.apache.org/flume/mediaresource/8962fbde-7f23-4b43-813a-f150c9afbc0a" alt="Flume agent architecture" /><br /><strong id="internal-source-marker_0.846074462402612" style="font-weight: normal;"> </strong></p>
<p style="font-weight: normal; display: inline !important;"><strong id="internal-source-marker_0.846074462402612" style="font-weight: normal;"> </strong></p>
<p><strong id="internal-source-marker_0.846074462402612"> </p>
<h2 style="font-weight: normal; display: inline !important;"> </h2>
<p><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Memory Channel vs. File Channel</span></p>
<p> </strong><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">An important decision to make when designing your Flume flow is what type of channel you want to use. At the time of this writing, the two recommended channels are the </span><a href="http://flume.apache.org/FlumeUserGuide.html#file-channel" style="font-weight: normal;"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">file channel</span></a><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> and the </span><a href="http://flume.apache.org/FlumeUserGuide.html#memory-channel" style="font-weight: normal;"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">memory channel</span></a><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">. The file channel is a </span><span style="font-weight: normal; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;">durable </span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">channel, as it persists all events that are stored in it to disk. So, even if the Java virtual machine is killed, or the operating system crashes or reboots, events that were not successfully transferred to the next agent in the pipeline will still be there when the Flume agent is restarted. The memory channel is a volatile channel, as it buffers events in memory only: if the Java process dies, any events stored in the memory channel are lost. Naturally, the memory channel also exhibits very low put/take latencies compared to the file channel, even for a batch size of 1. Since the number of events that can be stored is limited by available RAM, its ability to buffer events in the case of temporary downstream failure is quite limited. The file channel, on the other hand, has far superior buffering capability due to utilizing cheap, abundant hard disk space.</span> </p>
<p><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Flume event batching </span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">As mentioned earlier, Flume can batch events. </span><span style="font-weight: bold; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">The batch size is the maximum number of events that a sink or client will attempt to take from a channel in a single transaction</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">. Tuning the batch size trades throughput vs. latency and duplication under failure. With a small batch size, throughput decreases, but the risk of event duplication is reduced if a failure were to occur. With a large batch size, you get much better throughput, but increased latency, and in the case of a transaction failure, the number of possible duplicates increases.</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Transactions are a critical concept in Flume, because the delivery and durability guarantees made by channels only take effect at the end of each successful transaction. For example, when a source receives or generates an event, in order to store that event into a channel a transaction must first be opened on that channel. Within the transaction, the source puts up to the batch size number of events into the channel, and on success </span><span style="font-weight: normal; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;">commits</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> the transaction. A sink must go through the same process of operating within a transaction when taking events from a channel.</span></strong></p>
<p><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span></strong><strong id="internal-source-marker_0.846074462402612"> </strong></p>
<p style="display: inline !important;"><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Batch size is configured at the sink level. The larger the batch, the faster the channels operate (but there is a caveat). In the case of the file channel, this speed difference is because all buffers are flushed and then synced to disk when each transaction is committed. A disk sync is a time-consuming operation (it may take several milliseconds), but it is required to ensure the durability of the data. Likewise, with the memory channel, there is a memory synchronization step when each transaction is committed. Of course, memory synchronization is much faster than a disk sync. For more information on the inner workings of the file channel, please see Brock Noland's </span><a href="https://blogs.apache.org/flume/entry/apache_flume_filechannel" style="font-weight: normal;"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">article about the Apache Flume File Channel</span></a><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">.</span></strong></p>
<p><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"> </strong></strong></strong></strong></p>
<p style="display: inline !important;"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">The downside of using a large batch size is that if there is some type of failure in the middle of a transaction, such as a downstream host or network failure, there is a possibility of duplicates being created. So, for example, if you set your batch size to 1000, and the machine you are writing to goes offline, duplicates may be generated in groups of up to 1000. This may occur in special cases, for example, if the events got written to the downstream machine but then the connection failed before it could acknowledge that it had received them. However, duplicate events will only appear in exceptional circumstances.</span></strong></strong></strong></strong></strong></strong></strong></strong></p>
<p></strong> </p>
<p><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Choosing a batch size</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">To squeeze all the performance possible out of a Flume system, batch sizes should be tuned with care through experimentation. While I will get into this in more detail in the follow-up to this post, here are some rules of thumb for selecting batch sizes.</span> </p>
<p style="font-weight: normal;">
<ol style="font-weight: normal; margin-top: 0pt; margin-bottom: 0pt;">
<li dir="ltr" style="list-style-type: decimal; background-color: transparent; vertical-align: baseline;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Start off with batch sizes equal to the sum of the batch sizes of the input streams coming into that tier. For example, if you have a downstream Flume agent running an Avro source with 10 upstream agents sending events via Avro sinks using a batch size of 100 each, consider starting that downstream agent with a batch size of 1,000. Tune / experiment from there.</span></li>
<li dir="ltr" style="list-style-type: decimal; background-color: transparent; vertical-align: baseline;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">If you find yourself setting the batch size very high (say, higher than 10,000) then consider adding another Sink instead, in order to increase the parallelism (each sink typically runs on its own thread). Say you were going to use one HDFS sink with a batch size of 20,000. Experiment with using 2 HDFS sinks with batch sizes of 5,000 or 10,000 to see if that helps more.</span></li>
<li dir="ltr" style="list-style-type: decimal; background-color: transparent; vertical-align: baseline;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Prefer the lowest batch size that gives you acceptable performance.</span></li>
<li dir="ltr" style="list-style-type: decimal; background-color: transparent; vertical-align: baseline;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Monitor the steady-state channel sizes to get more tuning insight (more on this in the next article).</span></li>
</ol>
<p style="font-weight: normal;">
<p><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Different batch sizes in different situations</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Due to the performance / duplication tradeoff of the batch size parameter, I often see varying batch size settings depending on the use case. In the case of using Flume to write to HBase using the HBase Sink, incrementing counters, a smaller batch size on the order of 100 is often used to reduce the impact in case of hiccups in the system. On the other hand, with an HDFS sink, in order to get maximum throughput, I see people running with batch sizes of 1,000 or even 10,000, since typically they can easily run map-reduce jobs to de-duplicate the data at processing time. Note that when writing large events with large batch sizes to HDFS, often other parameters need to be increased as well. One such parameter is </span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">hdfs.callTimeout</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">, which may be increased to 60 seconds or more to account for the long tail of occasional higher-latency calls to HDFS.</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">At the other end of the spectrum, in cases where batching events at the application (Flume client) tier is not possible, the memory channel is often used at the collector-tier Flume agent (or a localhost agent on the app servers) to get acceptable performance with a batch size of 1, while using larger batch sizes and file channels in the downstream agents in order to get most of the benefits of durability there. For the best performance, however, all tiers including the client/application tier would perform some level of batching. (Please see above diagram for an illustration of the tiers referenced in this scenario.)</span></strong> </p>
<p><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Configuration parameters and gotchas</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">The actual parameter used to set the batch size varies between sinks, but for most sinks it&rsquo;s simply called </span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">batchSize</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> or </span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">batch-size.</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> For the HDFS sink, it&rsquo;s actually called </span><a href="http://flume.apache.org/FlumeUserGuide.html#hdfs-sink" style="font-weight: normal;"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">hdfs.batchSize</span></a><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> for historical reasons; I recommend setting hdfs.txnEventMax to the same value as hdfs.batchSize for simplicity. Historically, in the HDFS sink, the number of events taken in a single transaction can be different from the number of events written to HDFS before a sync() operation; In practice, there is little reason these should not be set to the same value.</span></p>
<p><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span><strong id="internal-source-marker_0.846074462402612"> </strong></p>
<p style="display: inline !important;"><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">One potentially confusing gotcha when tuning the batch size on a sink is that it must be less than or equal to the </span><a href="http://flume.apache.org/FlumeUserGuide.html#memory-channel" style="font-weight: normal;"><span style="background-color: transparent; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;">transactionCapacity</span></a><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> set on the corresponding channel. The </span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">transactionCapacity</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> should be set to the value of the largest batch size that will be used to store or remove events from that channel.</span></strong></p>
<p><strong id="internal-source-marker_0.846074462402612"><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"></span></strong><span style="font-weight: bold; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">tl;dr</span><span style="font-weight: bold; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">:</span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> Below is a &ldquo;cheat sheet&rdquo; batch size tuning summary for your convenience. Please note that these are </span><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"><i>just starting points</i></span><span style="font-weight: normal; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;"> for tuning.</span> </p></p>
<table style="border: none; border-collapse: collapse; width: 624px;">
<colgroup>
<col width="188" />
<col width="228" />
<col width="*" /></colgroup>
<tbody>
<tr style="height: 0px;">
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Sink Type</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Config parameter</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;">Typical value</span></td>
</tr>
<tr style="height: 0px;">
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">Avro</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">batch-size</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">100</span></td>
</tr>
<tr style="height: 0px;">
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">HDFS</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">hdfs.batchSize, hdfs.txnEventMax</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">1000</span></td>
</tr>
<tr style="height: 0px;">
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="vertical-align: baseline; white-space: pre-wrap;">HBaseSink</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">batchSize</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">100</span></td>
</tr>
<tr style="height: 0px;">
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">AsyncHBaseSink</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">batchSize</span></td>
<td style="border: 1px solid #000000; vertical-align: top; padding: 7px;"><span style="background-color: transparent; vertical-align: baseline; white-space: pre-wrap;">100</span> </td>
</tr>
</tbody>
</table>
<p><span style="background-color: transparent; white-space: pre-wrap;">That&rsquo;s all I have space for in one blog post. Please leave feedback and questions in the comments. Look for another post in the future with tips on using Flume&rsquo;s monitoring capabilities to take advantage of important information which can aid you in your quest for optimum performance.</span></p>
<p><i>Mike Percy is a committer and PMC member on the Apache Flume project.</i></p>

  </div><a class="u-url" href="/flume/entry/flume_performance_tuning_part_1" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
