<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Why Does Apache NetBeans Need Its Own Parsers? | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Why Does Apache NetBeans Need Its Own Parsers?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A question was asked on the Apache NetBeans mailing list: &quot;I was just curious about the theoretical aspect of parsing. Isn&#39;t there a unified parsing API, using ANTLR/lex/yacc which can parse any language given a grammar for it? Why do we use a different parsing implementation (like the Graal JS parser in this instance) when a unified approach will help us support lots of languages easily?&quot; Tim Boudreau, involved in NetBeans from its earliest hours, responds, in the thread linked above: First, in an IDE, you are *never* just &quot;parsing&quot;. You are doing *a lot* with the results of the parse. An IDE doesn&#39;t have to just parse one file; it must also understand the context of the project that file lives in; how it relates to other files and those files interdependencies; multiple versions of languages; and the fact that the results of a parse do not map cleanly to a bunch of stuff an IDE would show you that would be useful. For example, say the caret is in a java method, and you want to find all other methods that call the one you&#39;re in and show the user a list of them. The amount of work that has to happen to answer that question is very, very large. To do that quickly enough to be useful, you need to do it ahead of time and have a bunch of indexing and caching software behind the scenes (all of which must be adapted to whatever the parser provides) so you can look it up when you need it. In short, a parser is kind of like a toilet seat by itself. You don&#39;t want to use it without a whole lot of plumbing attached to it. Second, while there are tools like ANTLR (version 4 of which is awesome, by the way), there is still a lot of code you have to write to interact with the results of a parse to do something useful beyond syntax coloring in an IDE. One of my side projects is tooling for NetBeans that *do* let you take an ANTLR grammar and auto generate a lot of the features a language plugin should have. Even with that almost completely declarative, you wind up needing a lot of code. One of the languages I&#39;m testing it with is a simple language called YASL which lets you define javascript-like schemas with validation constraints (e.g., this field is a string, but it must be at least 7 characters and match this pattern; this is an integer number but it must be &gt; 1 and less than 1000 - that sort of thing). All the parsing goodness in the world won&#39;t write hints that notice that, say, the maximum is less than the minimum in an integer constraint and offer to swap them. Someone has to write that by hand. Third, in an IDE with a 20 year history, a lot of parser generating technologies have come and gone - javacc, javacup, ANTLR, and good old hand-written lexers and parsers. Unifying them all would be an enormous amount of work, would break a lot of code that works just fine, and the end result would be - stuff we&#39;ve already got, that already works, just with one-parser-generator-to-rule-them-all underneath. Other than prettiness, I don&#39;t know what problem that solves. So, all of this is to say: We use different parsing implementations because parsing is just a tiny piece of supporting a language, so it wouldn&#39;t make the hard parts easier enough to be worth it. And there will be new cool parser-generating technologies that come along, and it&#39;s good to be able to use them, rather than be married to one-parser-generator-to-rule-them-all and have this conversation again, when they come along. &lt;/b&gt;" />
<meta property="og:description" content="A question was asked on the Apache NetBeans mailing list: &quot;I was just curious about the theoretical aspect of parsing. Isn&#39;t there a unified parsing API, using ANTLR/lex/yacc which can parse any language given a grammar for it? Why do we use a different parsing implementation (like the Graal JS parser in this instance) when a unified approach will help us support lots of languages easily?&quot; Tim Boudreau, involved in NetBeans from its earliest hours, responds, in the thread linked above: First, in an IDE, you are *never* just &quot;parsing&quot;. You are doing *a lot* with the results of the parse. An IDE doesn&#39;t have to just parse one file; it must also understand the context of the project that file lives in; how it relates to other files and those files interdependencies; multiple versions of languages; and the fact that the results of a parse do not map cleanly to a bunch of stuff an IDE would show you that would be useful. For example, say the caret is in a java method, and you want to find all other methods that call the one you&#39;re in and show the user a list of them. The amount of work that has to happen to answer that question is very, very large. To do that quickly enough to be useful, you need to do it ahead of time and have a bunch of indexing and caching software behind the scenes (all of which must be adapted to whatever the parser provides) so you can look it up when you need it. In short, a parser is kind of like a toilet seat by itself. You don&#39;t want to use it without a whole lot of plumbing attached to it. Second, while there are tools like ANTLR (version 4 of which is awesome, by the way), there is still a lot of code you have to write to interact with the results of a parse to do something useful beyond syntax coloring in an IDE. One of my side projects is tooling for NetBeans that *do* let you take an ANTLR grammar and auto generate a lot of the features a language plugin should have. Even with that almost completely declarative, you wind up needing a lot of code. One of the languages I&#39;m testing it with is a simple language called YASL which lets you define javascript-like schemas with validation constraints (e.g., this field is a string, but it must be at least 7 characters and match this pattern; this is an integer number but it must be &gt; 1 and less than 1000 - that sort of thing). All the parsing goodness in the world won&#39;t write hints that notice that, say, the maximum is less than the minimum in an integer constraint and offer to swap them. Someone has to write that by hand. Third, in an IDE with a 20 year history, a lot of parser generating technologies have come and gone - javacc, javacup, ANTLR, and good old hand-written lexers and parsers. Unifying them all would be an enormous amount of work, would break a lot of code that works just fine, and the end result would be - stuff we&#39;ve already got, that already works, just with one-parser-generator-to-rule-them-all underneath. Other than prettiness, I don&#39;t know what problem that solves. So, all of this is to say: We use different parsing implementations because parsing is just a tiny piece of supporting a language, so it wouldn&#39;t make the hard parts easier enough to be worth it. And there will be new cool parser-generating technologies that come along, and it&#39;s good to be able to use them, rather than be married to one-parser-generator-to-rule-them-all and have this conversation again, when they come along. &lt;/b&gt;" />
<link rel="canonical" href="http://localhost:4000/netbeans/entry/why-does-apache-netbeans-need" />
<meta property="og:url" content="http://localhost:4000/netbeans/entry/why-does-apache-netbeans-need" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-06T12:15:42-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Why Does Apache NetBeans Need Its Own Parsers?" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2019-08-06T12:15:42-04:00","datePublished":"2019-08-06T12:15:42-04:00","description":"A question was asked on the Apache NetBeans mailing list: &quot;I was just curious about the theoretical aspect of parsing. Isn&#39;t there a unified parsing API, using ANTLR/lex/yacc which can parse any language given a grammar for it? Why do we use a different parsing implementation (like the Graal JS parser in this instance) when a unified approach will help us support lots of languages easily?&quot; Tim Boudreau, involved in NetBeans from its earliest hours, responds, in the thread linked above: First, in an IDE, you are *never* just &quot;parsing&quot;. You are doing *a lot* with the results of the parse. An IDE doesn&#39;t have to just parse one file; it must also understand the context of the project that file lives in; how it relates to other files and those files interdependencies; multiple versions of languages; and the fact that the results of a parse do not map cleanly to a bunch of stuff an IDE would show you that would be useful. For example, say the caret is in a java method, and you want to find all other methods that call the one you&#39;re in and show the user a list of them. The amount of work that has to happen to answer that question is very, very large. To do that quickly enough to be useful, you need to do it ahead of time and have a bunch of indexing and caching software behind the scenes (all of which must be adapted to whatever the parser provides) so you can look it up when you need it. In short, a parser is kind of like a toilet seat by itself. You don&#39;t want to use it without a whole lot of plumbing attached to it. Second, while there are tools like ANTLR (version 4 of which is awesome, by the way), there is still a lot of code you have to write to interact with the results of a parse to do something useful beyond syntax coloring in an IDE. One of my side projects is tooling for NetBeans that *do* let you take an ANTLR grammar and auto generate a lot of the features a language plugin should have. Even with that almost completely declarative, you wind up needing a lot of code. One of the languages I&#39;m testing it with is a simple language called YASL which lets you define javascript-like schemas with validation constraints (e.g., this field is a string, but it must be at least 7 characters and match this pattern; this is an integer number but it must be &gt; 1 and less than 1000 - that sort of thing). All the parsing goodness in the world won&#39;t write hints that notice that, say, the maximum is less than the minimum in an integer constraint and offer to swap them. Someone has to write that by hand. Third, in an IDE with a 20 year history, a lot of parser generating technologies have come and gone - javacc, javacup, ANTLR, and good old hand-written lexers and parsers. Unifying them all would be an enormous amount of work, would break a lot of code that works just fine, and the end result would be - stuff we&#39;ve already got, that already works, just with one-parser-generator-to-rule-them-all underneath. Other than prettiness, I don&#39;t know what problem that solves. So, all of this is to say: We use different parsing implementations because parsing is just a tiny piece of supporting a language, so it wouldn&#39;t make the hard parts easier enough to be worth it. And there will be new cool parser-generating technologies that come along, and it&#39;s good to be able to use them, rather than be married to one-parser-generator-to-rule-them-all and have this conversation again, when they come along. &lt;/b&gt;","headline":"Why Does Apache NetBeans Need Its Own Parsers?","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/netbeans/entry/why-does-apache-netbeans-need"},"url":"http://localhost:4000/netbeans/entry/why-does-apache-netbeans-need"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Why Does Apache NetBeans Need Its Own Parsers?</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-08-06T12:15:42-04:00" itemprop="datePublished">Aug 6, 2019
      </time>â€¢ <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"GeertjanWielenga", "login"=>"geertjan", "email"=>"geertjan@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>A question was asked on the <a href="https://lists.apache.org/thread.html/ebabfa11e9a88069a762e68a8ade3c70669fb070c891552ea847e4be@%3Cdev.netbeans.apache.org%3E">Apache NetBeans mailing list</a>: "I was just curious about the theoretical aspect of parsing. Isn't there a unified parsing API, using ANTLR/lex/yacc which can parse any language given a grammar for it? Why do we use a different parsing implementation (like the Graal JS parser in this instance) when a unified approach will help us support lots of languages easily?"</p>
<p>Tim Boudreau, involved in NetBeans from its earliest hours, responds, in the thread linked above:</p>
<p><b>
<p>First, in an IDE, you are *never* just "parsing".  You are doing *a lot* with the results of the parse.  An IDE doesn't have to just parse one file;  it must also understand the context of the project that file lives in;  how it relates to other files and those files interdependencies; multiple versions of languages;  and the fact that the results of a parse do not map cleanly to a bunch of stuff an IDE would show you that would be useful.  For example, say the caret is in a java method, and you want to find all other methods that call the one you're in and show the user a list of them.  The amount of work that has to happen to answer that question is very, very large.  To do that quickly enough to be useful, you need to do it ahead of time and have a bunch of indexing and caching software behind the scenes (all of which must be adapted to whatever the parser provides) so you can look it up when you need it.  In short, a parser is kind of like a toilet seat by itself.  You don't want to use it without a whole lot of plumbing attached to it.</p>
<p>Second, while there are tools like ANTLR (version 4 of which is awesome, by the way), there is still a lot of code you have to write to interact with the results of a parse to do something useful beyond syntax coloring in an IDE.  One of my side projects is tooling for NetBeans that *do* let you take an ANTLR grammar and auto generate a lot of the features a language plugin should have.  Even with that almost completely declarative, you wind up needing a lot of code.  One of the languages I'm testing it with is a simple language called YASL which lets you define javascript-like schemas with validation constraints (e.g., this field is a string, but it must be at least 7 characters and match this pattern;  this is an integer number but it must be > 1 and less than 1000 - that sort of thing).  All the parsing goodness in the world won't write hints that notice that, say, the maximum is less than the minimum in an integer constraint and offer to swap them.  Someone has to write that by hand.</p>
<p>Third, in an IDE with a 20 year history, a lot of parser generating technologies have come and gone - javacc, javacup, ANTLR, and good old hand-written lexers and parsers.  Unifying them all would be an enormous amount of work, would break a lot of code that works just fine, and the end result would be - stuff we've already got, that already works, just with one-parser-generator-to-rule-them-all underneath.  Other than prettiness, I don't know what problem that solves.</p>
<p>So, all of this is to say:  We use different parsing implementations because parsing is just a tiny piece of supporting a language, so it wouldn't make the hard parts easier enough to be worth it.  And there will be new cool parser-generating technologies that come along, and it's good to be able to use them, rather than be married to one-parser-generator-to-rule-them-all and have this conversation again, when they come along.</p>
<p></b></p>

  </div><a class="u-url" href="/netbeans/entry/why-does-apache-netbeans-need" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
