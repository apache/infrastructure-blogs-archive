<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Getting Syslog Events to HBase | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Getting Syslog Events to HBase" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Getting Syslog Events to HBase Bryan Bende -&nbsp; bbende@gmail.com -&nbsp; @bbende In the Apache NiFi 0.4.0 release there are several new integration points including processors for interacting with Syslog and HBase. In this post we&#39;ll demonstrate how to use NiFi to receive messages from Syslog over UDP, and store those messages in HBase. The flow described in this post was created using Apache NiFi 0.4.0, rsyslog 5.8.10, and Apache HBase 1.1.2. Setting up Syslog In order for NiFi to receive syslog messages, rsyslog needs to forward messages to a port that NiFi will be listening on. Forwarding of messages can be configured in rsyslog.conf, generally located in /etc on most Linux operating systems. Edit rsyslog.conf and add the following line: &lt;/p&gt; *.* @localhost:7780 &lt;/code&gt; &lt;/div&gt; This tells rsyslog to forward all messages over UDP to localhost port 7780. A double &#39;@@&#39; can be used to forward over TCP. Restart rsyslog for the changes to take effect: &lt;/p&gt; /etc/init.d/rsyslog restart Shutting down system logger: [ OK ] Starting system logger: [ OK ] &lt;/code&gt; &lt;/div&gt; Setting up HBase In order to store the syslog messages, we&#39;ll create an HBase table called &#39;syslog&#39; with one column family called &#39;msg&#39;. From the command line enter the following: &lt;/p&gt; hbase shell create &#39;syslog&#39;, {NAME =&gt; &#39;msg&#39;} &lt;/code&gt; &lt;/div&gt; Configure an HBase Client Service The HBase processors added in Apache NiFi 0.4.0 use a controller service to interact with HBase. This allows the processors to remain unchanged when the HBase client changes, and allows a single NiFi instance to support multiple versions of the HBase client. NiFi&#39;s class-loader isolation provided in NARs, allows a single NiFi instance to interact with HBase instances of different versions at the same time. The HBase Client Service can be configured by providing paths to external configuration files, such as hbase-site.xml, or by providing several properties directly in the processor. For this example we will take the latter approach. From the Controller Services configuration window in NiFi, add an HBase_1_1_2_ClientService with the following configuration (adjusting values appropriately for your system): &lt;/img&gt; After configuring the service, enable it in order for it to be usable by processors: &lt;/img&gt; Building the Dataflow The dataflow we are going build will consist of the following components: ListenSyslog for receiving syslog messages over UDP UpdateAttribute for renaming attributes and creating a row id for HBase AttributesToJSON for creating a JSON document from the syslog attributes PutHBaseJSON for inserting each JSON document as a row in HBase The overall flow looks like the following: &lt;/img&gt; Lets walk through the configuration of each processor... ListenSyslog &lt;/img&gt; Set the Port to the same port that rsyslog is forwarding messages to, in this case 7780. Leave everything else as the default values. With a Max Batch Size of &quot;1&quot; and Parse Messages as &quot;true&quot;, each syslog message will be emitted as a single FlowFile, with the content of the FlowFile being the original message, and the results of parsing the message being stored as FlowFile attributes. The attributes we will be interested in are: syslog.priority syslog.severity syslog.facility syslog.version syslog.timestamp syslog.hostname syslog.sender syslog.body syslog.protocol syslog.port UpdateAttribute &lt;/img&gt; The attributes produced by ListenSyslog all start with &quot;syslog.&quot; which keeps them nicely namespaced in NiFi. However, we are going to use these attribute names as column qualifiers in HBase. We don&#39;t really need this prefix since we will already be with in a syslog table. Add a property for each syslog attribute to remove the prefix, and use the Delete Attributes Expression to remove the original attributes. In addition, create an id attribute of the form &quot;timestamp_uuid&quot; where timestamp is the long representation of the timestamp on the syslog message, and uuid is the uuid of the FlowFile in NiFi. This id attribute will be used as the row id in HBase. The expression language for the id attribute is: &lt;/p&gt; ${syslog.timestamp:toDate(&#39;MMM d HH:mm:ss&#39;):toNumber()}_${uuid} &lt;/code&gt; &lt;/div&gt; AttributesToJSON &lt;/img&gt; Set the Destination to &quot;flowfile-content&quot; so that the JSON document replaces the FlowFile content, and set Include Core Attributes to &quot;false&quot; so that the standard NiFi attributes are not included. PutHBaseJSON &lt;/img&gt; Select the HBase Client Service we configured earlier and set the Table Name and Column Family to &quot;syslog&quot; and &quot;msg&quot; based on the table we created earlier. In addition set the Row Identifier Field Name to &quot;id&quot; to instruct the processor to use the id field from the JSON for the row id. Verifying the Flow From a terminal we can send a test message to syslog using the logger utility: &lt;/p&gt; logger &quot;this is a test syslog message&quot; &lt;/code&gt; &lt;/div&gt; Using the HBase shell we can inspect the contents of the syslog table: &lt;/p&gt; hbase shell hbase(main):002:0&gt; scan &#39;syslog&#39; ROW COLUMN+CELL 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:body, timestamp=1449775215481, value=root: this is a test message 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:hostname, timestamp=1449775215481, value=localhost 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:port, timestamp=1449775215481, value=7780 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:protocol, timestamp=1449775215481, value=UDP 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:sender, timestamp=1449775215481, value=/127.0.0.1 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:timestamp, timestamp=1449775215481, value=Dec 10 19:20:15 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:version, timestamp=1449775215481, value= 1 row(s) in 0.1120 seconds &lt;/code&gt; &lt;/div&gt; Performance Considerations In some cases the volume of syslog messages being pushed to ListenSyslog may be very high. There are several options to help scale the processing depending on the given use-case. Concurrent Tasks ListenSyslog has a background thread reading messages as fast as possible and placing them on a blocking queue to be de-queued and processed by the onTrigger method of the processor. By increasing the number of concurrent tasks for the processor, we can scale up the rate at which messages are processed, ensuring new messages can continue to be queued. Parsing One of the more expensive operations during the processing of a message is parsing the message in order to provide the the attributes. Parsing messages is controlled on the processor through a property and can be turned off in cases where the attributes are not needed, and the original message just needs to be delivered somewhere. Batching In cases where parsing the messages is not necessary, an additional option is batching many messages together during one call to onTrigger. This is controlled through the Batch Size property which defaults to &quot;1&quot;. This would be appropriate in cases where having individual messages is not necessary, such as storing the messages in HDFS where you need them batched into appropriately sized files. ParseSyslog In addition to parsing messages directly in ListenSyslog, there is also a ParseSyslog processor. An alternative to the flow described in the post would be to have ListenSyslog produce batches of 100 messages at a time, followed by SplitText, followed by ParseSyslog. The tradeoff here is that we can scale the different components independently, and take advantage of backpressure between processors. Summary At this point you should be able to get your syslog messages ingested into HBase and can experiment with different configurations. The template for this flow can be found here. We would love to hear any questions, comments, or feedback that you may have! Learn more about Apache NiFi and feel free to leave comments here or e-mail us at dev@nifi.apache.org." />
<meta property="og:description" content="Getting Syslog Events to HBase Bryan Bende -&nbsp; bbende@gmail.com -&nbsp; @bbende In the Apache NiFi 0.4.0 release there are several new integration points including processors for interacting with Syslog and HBase. In this post we&#39;ll demonstrate how to use NiFi to receive messages from Syslog over UDP, and store those messages in HBase. The flow described in this post was created using Apache NiFi 0.4.0, rsyslog 5.8.10, and Apache HBase 1.1.2. Setting up Syslog In order for NiFi to receive syslog messages, rsyslog needs to forward messages to a port that NiFi will be listening on. Forwarding of messages can be configured in rsyslog.conf, generally located in /etc on most Linux operating systems. Edit rsyslog.conf and add the following line: &lt;/p&gt; *.* @localhost:7780 &lt;/code&gt; &lt;/div&gt; This tells rsyslog to forward all messages over UDP to localhost port 7780. A double &#39;@@&#39; can be used to forward over TCP. Restart rsyslog for the changes to take effect: &lt;/p&gt; /etc/init.d/rsyslog restart Shutting down system logger: [ OK ] Starting system logger: [ OK ] &lt;/code&gt; &lt;/div&gt; Setting up HBase In order to store the syslog messages, we&#39;ll create an HBase table called &#39;syslog&#39; with one column family called &#39;msg&#39;. From the command line enter the following: &lt;/p&gt; hbase shell create &#39;syslog&#39;, {NAME =&gt; &#39;msg&#39;} &lt;/code&gt; &lt;/div&gt; Configure an HBase Client Service The HBase processors added in Apache NiFi 0.4.0 use a controller service to interact with HBase. This allows the processors to remain unchanged when the HBase client changes, and allows a single NiFi instance to support multiple versions of the HBase client. NiFi&#39;s class-loader isolation provided in NARs, allows a single NiFi instance to interact with HBase instances of different versions at the same time. The HBase Client Service can be configured by providing paths to external configuration files, such as hbase-site.xml, or by providing several properties directly in the processor. For this example we will take the latter approach. From the Controller Services configuration window in NiFi, add an HBase_1_1_2_ClientService with the following configuration (adjusting values appropriately for your system): &lt;/img&gt; After configuring the service, enable it in order for it to be usable by processors: &lt;/img&gt; Building the Dataflow The dataflow we are going build will consist of the following components: ListenSyslog for receiving syslog messages over UDP UpdateAttribute for renaming attributes and creating a row id for HBase AttributesToJSON for creating a JSON document from the syslog attributes PutHBaseJSON for inserting each JSON document as a row in HBase The overall flow looks like the following: &lt;/img&gt; Lets walk through the configuration of each processor... ListenSyslog &lt;/img&gt; Set the Port to the same port that rsyslog is forwarding messages to, in this case 7780. Leave everything else as the default values. With a Max Batch Size of &quot;1&quot; and Parse Messages as &quot;true&quot;, each syslog message will be emitted as a single FlowFile, with the content of the FlowFile being the original message, and the results of parsing the message being stored as FlowFile attributes. The attributes we will be interested in are: syslog.priority syslog.severity syslog.facility syslog.version syslog.timestamp syslog.hostname syslog.sender syslog.body syslog.protocol syslog.port UpdateAttribute &lt;/img&gt; The attributes produced by ListenSyslog all start with &quot;syslog.&quot; which keeps them nicely namespaced in NiFi. However, we are going to use these attribute names as column qualifiers in HBase. We don&#39;t really need this prefix since we will already be with in a syslog table. Add a property for each syslog attribute to remove the prefix, and use the Delete Attributes Expression to remove the original attributes. In addition, create an id attribute of the form &quot;timestamp_uuid&quot; where timestamp is the long representation of the timestamp on the syslog message, and uuid is the uuid of the FlowFile in NiFi. This id attribute will be used as the row id in HBase. The expression language for the id attribute is: &lt;/p&gt; ${syslog.timestamp:toDate(&#39;MMM d HH:mm:ss&#39;):toNumber()}_${uuid} &lt;/code&gt; &lt;/div&gt; AttributesToJSON &lt;/img&gt; Set the Destination to &quot;flowfile-content&quot; so that the JSON document replaces the FlowFile content, and set Include Core Attributes to &quot;false&quot; so that the standard NiFi attributes are not included. PutHBaseJSON &lt;/img&gt; Select the HBase Client Service we configured earlier and set the Table Name and Column Family to &quot;syslog&quot; and &quot;msg&quot; based on the table we created earlier. In addition set the Row Identifier Field Name to &quot;id&quot; to instruct the processor to use the id field from the JSON for the row id. Verifying the Flow From a terminal we can send a test message to syslog using the logger utility: &lt;/p&gt; logger &quot;this is a test syslog message&quot; &lt;/code&gt; &lt;/div&gt; Using the HBase shell we can inspect the contents of the syslog table: &lt;/p&gt; hbase shell hbase(main):002:0&gt; scan &#39;syslog&#39; ROW COLUMN+CELL 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:body, timestamp=1449775215481, value=root: this is a test message 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:hostname, timestamp=1449775215481, value=localhost 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:port, timestamp=1449775215481, value=7780 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:protocol, timestamp=1449775215481, value=UDP 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:sender, timestamp=1449775215481, value=/127.0.0.1 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:timestamp, timestamp=1449775215481, value=Dec 10 19:20:15 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:version, timestamp=1449775215481, value= 1 row(s) in 0.1120 seconds &lt;/code&gt; &lt;/div&gt; Performance Considerations In some cases the volume of syslog messages being pushed to ListenSyslog may be very high. There are several options to help scale the processing depending on the given use-case. Concurrent Tasks ListenSyslog has a background thread reading messages as fast as possible and placing them on a blocking queue to be de-queued and processed by the onTrigger method of the processor. By increasing the number of concurrent tasks for the processor, we can scale up the rate at which messages are processed, ensuring new messages can continue to be queued. Parsing One of the more expensive operations during the processing of a message is parsing the message in order to provide the the attributes. Parsing messages is controlled on the processor through a property and can be turned off in cases where the attributes are not needed, and the original message just needs to be delivered somewhere. Batching In cases where parsing the messages is not necessary, an additional option is batching many messages together during one call to onTrigger. This is controlled through the Batch Size property which defaults to &quot;1&quot;. This would be appropriate in cases where having individual messages is not necessary, such as storing the messages in HDFS where you need them batched into appropriately sized files. ParseSyslog In addition to parsing messages directly in ListenSyslog, there is also a ParseSyslog processor. An alternative to the flow described in the post would be to have ListenSyslog produce batches of 100 messages at a time, followed by SplitText, followed by ParseSyslog. The tradeoff here is that we can scale the different components independently, and take advantage of backpressure between processors. Summary At this point you should be able to get your syslog messages ingested into HBase and can experiment with different configurations. The template for this flow can be found here. We would love to hear any questions, comments, or feedback that you may have! Learn more about Apache NiFi and feel free to leave comments here or e-mail us at dev@nifi.apache.org." />
<link rel="canonical" href="http://localhost:4000/nifi/entry/storing_syslog_events_in_hbase" />
<meta property="og:url" content="http://localhost:4000/nifi/entry/storing_syslog_events_in_hbase" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2015-12-16T13:39:24-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Getting Syslog Events to HBase" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2015-12-16T13:39:24-05:00","datePublished":"2015-12-16T13:39:24-05:00","description":"Getting Syslog Events to HBase Bryan Bende -&nbsp; bbende@gmail.com -&nbsp; @bbende In the Apache NiFi 0.4.0 release there are several new integration points including processors for interacting with Syslog and HBase. In this post we&#39;ll demonstrate how to use NiFi to receive messages from Syslog over UDP, and store those messages in HBase. The flow described in this post was created using Apache NiFi 0.4.0, rsyslog 5.8.10, and Apache HBase 1.1.2. Setting up Syslog In order for NiFi to receive syslog messages, rsyslog needs to forward messages to a port that NiFi will be listening on. Forwarding of messages can be configured in rsyslog.conf, generally located in /etc on most Linux operating systems. Edit rsyslog.conf and add the following line: &lt;/p&gt; *.* @localhost:7780 &lt;/code&gt; &lt;/div&gt; This tells rsyslog to forward all messages over UDP to localhost port 7780. A double &#39;@@&#39; can be used to forward over TCP. Restart rsyslog for the changes to take effect: &lt;/p&gt; /etc/init.d/rsyslog restart Shutting down system logger: [ OK ] Starting system logger: [ OK ] &lt;/code&gt; &lt;/div&gt; Setting up HBase In order to store the syslog messages, we&#39;ll create an HBase table called &#39;syslog&#39; with one column family called &#39;msg&#39;. From the command line enter the following: &lt;/p&gt; hbase shell create &#39;syslog&#39;, {NAME =&gt; &#39;msg&#39;} &lt;/code&gt; &lt;/div&gt; Configure an HBase Client Service The HBase processors added in Apache NiFi 0.4.0 use a controller service to interact with HBase. This allows the processors to remain unchanged when the HBase client changes, and allows a single NiFi instance to support multiple versions of the HBase client. NiFi&#39;s class-loader isolation provided in NARs, allows a single NiFi instance to interact with HBase instances of different versions at the same time. The HBase Client Service can be configured by providing paths to external configuration files, such as hbase-site.xml, or by providing several properties directly in the processor. For this example we will take the latter approach. From the Controller Services configuration window in NiFi, add an HBase_1_1_2_ClientService with the following configuration (adjusting values appropriately for your system): &lt;/img&gt; After configuring the service, enable it in order for it to be usable by processors: &lt;/img&gt; Building the Dataflow The dataflow we are going build will consist of the following components: ListenSyslog for receiving syslog messages over UDP UpdateAttribute for renaming attributes and creating a row id for HBase AttributesToJSON for creating a JSON document from the syslog attributes PutHBaseJSON for inserting each JSON document as a row in HBase The overall flow looks like the following: &lt;/img&gt; Lets walk through the configuration of each processor... ListenSyslog &lt;/img&gt; Set the Port to the same port that rsyslog is forwarding messages to, in this case 7780. Leave everything else as the default values. With a Max Batch Size of &quot;1&quot; and Parse Messages as &quot;true&quot;, each syslog message will be emitted as a single FlowFile, with the content of the FlowFile being the original message, and the results of parsing the message being stored as FlowFile attributes. The attributes we will be interested in are: syslog.priority syslog.severity syslog.facility syslog.version syslog.timestamp syslog.hostname syslog.sender syslog.body syslog.protocol syslog.port UpdateAttribute &lt;/img&gt; The attributes produced by ListenSyslog all start with &quot;syslog.&quot; which keeps them nicely namespaced in NiFi. However, we are going to use these attribute names as column qualifiers in HBase. We don&#39;t really need this prefix since we will already be with in a syslog table. Add a property for each syslog attribute to remove the prefix, and use the Delete Attributes Expression to remove the original attributes. In addition, create an id attribute of the form &quot;timestamp_uuid&quot; where timestamp is the long representation of the timestamp on the syslog message, and uuid is the uuid of the FlowFile in NiFi. This id attribute will be used as the row id in HBase. The expression language for the id attribute is: &lt;/p&gt; ${syslog.timestamp:toDate(&#39;MMM d HH:mm:ss&#39;):toNumber()}_${uuid} &lt;/code&gt; &lt;/div&gt; AttributesToJSON &lt;/img&gt; Set the Destination to &quot;flowfile-content&quot; so that the JSON document replaces the FlowFile content, and set Include Core Attributes to &quot;false&quot; so that the standard NiFi attributes are not included. PutHBaseJSON &lt;/img&gt; Select the HBase Client Service we configured earlier and set the Table Name and Column Family to &quot;syslog&quot; and &quot;msg&quot; based on the table we created earlier. In addition set the Row Identifier Field Name to &quot;id&quot; to instruct the processor to use the id field from the JSON for the row id. Verifying the Flow From a terminal we can send a test message to syslog using the logger utility: &lt;/p&gt; logger &quot;this is a test syslog message&quot; &lt;/code&gt; &lt;/div&gt; Using the HBase shell we can inspect the contents of the syslog table: &lt;/p&gt; hbase shell hbase(main):002:0&gt; scan &#39;syslog&#39; ROW COLUMN+CELL 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:body, timestamp=1449775215481, value=root: this is a test message 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:hostname, timestamp=1449775215481, value=localhost 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:port, timestamp=1449775215481, value=7780 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:protocol, timestamp=1449775215481, value=UDP 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:sender, timestamp=1449775215481, value=/127.0.0.1 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:timestamp, timestamp=1449775215481, value=Dec 10 19:20:15 29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:version, timestamp=1449775215481, value= 1 row(s) in 0.1120 seconds &lt;/code&gt; &lt;/div&gt; Performance Considerations In some cases the volume of syslog messages being pushed to ListenSyslog may be very high. There are several options to help scale the processing depending on the given use-case. Concurrent Tasks ListenSyslog has a background thread reading messages as fast as possible and placing them on a blocking queue to be de-queued and processed by the onTrigger method of the processor. By increasing the number of concurrent tasks for the processor, we can scale up the rate at which messages are processed, ensuring new messages can continue to be queued. Parsing One of the more expensive operations during the processing of a message is parsing the message in order to provide the the attributes. Parsing messages is controlled on the processor through a property and can be turned off in cases where the attributes are not needed, and the original message just needs to be delivered somewhere. Batching In cases where parsing the messages is not necessary, an additional option is batching many messages together during one call to onTrigger. This is controlled through the Batch Size property which defaults to &quot;1&quot;. This would be appropriate in cases where having individual messages is not necessary, such as storing the messages in HDFS where you need them batched into appropriately sized files. ParseSyslog In addition to parsing messages directly in ListenSyslog, there is also a ParseSyslog processor. An alternative to the flow described in the post would be to have ListenSyslog produce batches of 100 messages at a time, followed by SplitText, followed by ParseSyslog. The tradeoff here is that we can scale the different components independently, and take advantage of backpressure between processors. Summary At this point you should be able to get your syslog messages ingested into HBase and can experiment with different configurations. The template for this flow can be found here. We would love to hear any questions, comments, or feedback that you may have! Learn more about Apache NiFi and feel free to leave comments here or e-mail us at dev@nifi.apache.org.","headline":"Getting Syslog Events to HBase","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/nifi/entry/storing_syslog_events_in_hbase"},"url":"http://localhost:4000/nifi/entry/storing_syslog_events_in_hbase"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Getting Syslog Events to HBase</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2015-12-16T13:39:24-05:00" itemprop="datePublished">Dec 16, 2015
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Bryan Bende", "login"=>"bbende", "email"=>"bbende@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1>Getting Syslog Events to HBase</h1>
<p>
   <span class="author">Bryan Bende -&nbsp;</span><br />
   <span class="author"><a href="mailto:bbende@gmail.com">bbende@gmail.com</a> -&nbsp;</span><br />
   <span class="author"><a href="https://twitter.com/BBende">@bbende</a></span></p>
<hr />
<p>
In the Apache NiFi 0.4.0 release there are several new integration points<br />
including processors for interacting with Syslog and HBase. In this post we'll<br />
demonstrate how to use NiFi to receive messages from Syslog over UDP,<br />
and store those messages in HBase.</p>
<p>
The flow described in this post was created using Apache NiFi 0.4.0,<br />
rsyslog 5.8.10, and Apache HBase 1.1.2.</p>
<h2>Setting up Syslog</h2>
<p>
In order for NiFi to receive syslog messages, rsyslog needs to forward messages<br />
to a port that NiFi will be listening on. Forwarding of messages can be<br />
configured in rsyslog.conf, generally located in /etc on most Linux operating<br />
systems.</p>
<p>
Edit rsyslog.conf and add the following line:</p>
<div>
<code></p>
<pre style="background-color: #f1f1f1">
*.* @localhost:7780
</pre>
<p></code>
</div></p>
<p>
This tells rsyslog to forward all messages over UDP to localhost port 7780.<br />
A double '@@' can be used to forward over TCP.</p>
<p>
Restart rsyslog for the changes to take effect:</p>
<div>
<code></p>
<pre style="background-color: #f1f1f1">
/etc/init.d/rsyslog restart
Shutting down system logger:                               [  OK  ]
Starting system logger:                                    [  OK  ]
</pre>
<p></code>
</div></p>
<h2>Setting up HBase</h2>
<p>
In order to store the syslog messages, we'll create an HBase table called<br />
'syslog' with one column family called 'msg'. From the command line enter the<br />
following:</p>
<div>
<code></p>
<pre style="background-color: #f1f1f1">
hbase shell
create 'syslog', {NAME => 'msg'}
</pre>
<p></code>
</div></p>
<h2>Configure an HBase Client Service</h2>
<p>
  The HBase processors added in Apache NiFi 0.4.0 use a controller service to<br />
  interact with HBase. This allows the processors to remain unchanged when the<br />
  HBase client changes, and allows a single NiFi instance to support multiple<br />
  versions of the HBase client. NiFi's class-loader isolation provided in NARs,<br />
  allows a single NiFi instance to interact with HBase instances of different<br />
  versions at the same time.</p>
<p>
  The HBase Client Service can be configured by providing paths to external<br />
  configuration files, such as hbase-site.xml, or by providing several<br />
  properties directly in the processor. For this example we will take the<br />
  latter approach. From the Controller Services configuration window in NiFi,<br />
  add an HBase_1_1_2_ClientService with the following configuration (adjusting<br />
  values appropriately for your system):</p>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/d3ea48a8-e8db-46c0-9f2b-0896ef37f493"><img src="https://blogs.apache.org/nifi/mediaresource/d3ea48a8-e8db-46c0-9f2b-0896ef37f493?" alt="client-service-config.jpg"></img></a></p>
<p>
  After configuring the service, enable it in order for it to be usable by<br />
  processors:</p>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/eddbfa7e-0032-48d9-bad7-21e37b7736fc"><img src="https://blogs.apache.org/nifi/mediaresource/eddbfa7e-0032-48d9-bad7-21e37b7736fc?" alt="client-service-enabled.jpg"></img></a></p>
<h2>Building the Dataflow</h2>
<p>
  The dataflow we are going build will consist of the following components:</p>
<ul>
<li><b>ListenSyslog</b> for receiving syslog messages over UDP</li>
<li><b>UpdateAttribute</b> for renaming attributes and creating a row id for HBase</li>
<li><b>AttributesToJSON</b> for creating a JSON document from the syslog attributes</li>
<li><b>PutHBaseJSON</b> for inserting each JSON document as a row in HBase</li>
</ul>
<p>
The overall flow looks like the following:</p>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/d4136c36-cea4-4e36-b072-f72944edbff3"><img src="https://blogs.apache.org/nifi/mediaresource/d4136c36-cea4-4e36-b072-f72944edbff3?" alt="syslog-hbase-flow.jpg"></img></a><br/><br />
Lets walk through the configuration of each processor...</p>
<h3>ListenSyslog</h3>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/e9f4b991-8c41-4c26-8b60-e8a7e6d4c7dc"><img src="https://blogs.apache.org/nifi/mediaresource/e9f4b991-8c41-4c26-8b60-e8a7e6d4c7dc?" alt="config-listensyslog.jpg"></img></a></p>
<p>
  Set the <i>Port</i> to the same port that rsyslog is forwarding messages to,<br />
  in this case 7780. Leave everything else as the default values.</p>
<p>
   With a <i>Max Batch Size</i> of "1" and <i>Parse Messages</i> as "true", each syslog<br />
   message will be emitted as a single FlowFile, with the content of the<br />
   FlowFile being the original message, and the results of parsing the message<br />
   being stored as FlowFile attributes.</p>
<p>
  The attributes we will be interested in are:</p>
<ul>
<li>syslog.priority</li>
<li>syslog.severity</li>
<li>syslog.facility</li>
<li>syslog.version</li>
<li>syslog.timestamp</li>
<li>syslog.hostname</li>
<li>syslog.sender</li>
<li>syslog.body</li>
<li>syslog.protocol</li>
<li>syslog.port</li>
</ul>
<h3>UpdateAttribute</h3>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/c04e59e3-a444-4fd5-9ad3-7518a9438a4f"><img src="https://blogs.apache.org/nifi/mediaresource/c04e59e3-a444-4fd5-9ad3-7518a9438a4f?" alt="config-updateattr.jpg"></img></a></p>
<p>
  The attributes produced by ListenSyslog all start with "syslog." which keeps<br />
  them nicely namespaced in NiFi. However, we are going to use these attribute<br />
  names as column qualifiers in HBase. We don't really need this prefix since<br />
  we will already be with in a syslog table.</p>
<p>
  Add a property for each syslog attribute to remove the prefix, and use the<br />
  <i>Delete Attributes Expression</i> to remove the original attributes. In addition,<br />
  create an <i>id</i> attribute of the form "timestamp_uuid" where timestamp is the<br />
  long representation of the timestamp on the syslog message, and uuid is the<br />
  uuid of the FlowFile in NiFi. This id attribute will be used as the row id in<br />
  HBase.</p>
<p>
  The expression language for the id attribute is:</p>
<div>
  <code></p>
<pre style="background-color: #f1f1f1">
${syslog.timestamp:toDate('MMM d HH:mm:ss'):toNumber()}_${uuid}
  </pre>
<p>  </code>
  </div></p>
<h3>AttributesToJSON</h3>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/e710ebb7-0289-4cb1-bc03-3a07121c2daf"><img src="https://blogs.apache.org/nifi/mediaresource/e710ebb7-0289-4cb1-bc03-3a07121c2daf" alt="config-attrstojson.jpg"></img></a></p>
<p>
  Set the <i>Destination</i> to "flowfile-content" so that the JSON document<br />
  replaces the FlowFile content, and set <i>Include Core Attributes</i> to<br />
  "false" so that the standard NiFi attributes are not included.</p>
<h3>PutHBaseJSON</h3>
<p>
<a href="https://blogs.apache.org/nifi/mediaresource/efcfdfcf-e4f1-4894-ad79-b1deed8c42f3"><img src="https://blogs.apache.org/nifi/mediaresource/efcfdfcf-e4f1-4894-ad79-b1deed8c42f3" alt="config-puthbasejson.jpg"></img></a></p>
<p>
  Select the <i>HBase Client Service</i> we configured earlier and set the<br />
  <i>Table Name</i> and <i>Column Family</i> to "syslog" and "msg" based on the<br />
  table we created earlier. In addition set the <i>Row Identifier Field Name</i><br />
  to "id" to instruct the processor to use the id field from the JSON for the<br />
  row id.</p>
<h2>Verifying the Flow</h2>
<p>
From a terminal we can send a test message to syslog using the logger utility:</p>
<div>
<code></p>
<pre style="background-color: #f1f1f1">
logger "this is a test syslog message"
</pre>
<p></code>
</div></p>
<p>
Using the HBase shell we can inspect the contents of the syslog table:</p>
<div>
<code></p>
<pre style="background-color: #f1f1f1">
hbase shell
hbase(main):002:0> scan 'syslog'
ROW                                          COLUMN+CELL
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:body, timestamp=1449775215481,
  value=root: this is a test message
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:hostname, timestamp=1449775215481,
  value=localhost
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:port, timestamp=1449775215481,
  value=7780
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:protocol, timestamp=1449775215481,
  value=UDP
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:sender, timestamp=1449775215481,
  value=/127.0.0.1
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:timestamp, timestamp=1449775215481,
  value=Dec 10 19:20:15
29704815000_84f91b21-d35f-4a24-8e0e-aaed4a521c13 column=msg:version, timestamp=1449775215481,
  value=
1 row(s) in 0.1120 seconds
</pre>
<p></code>
</div></p>
<h2>Performance Considerations</h2>
<p>
  In some cases the volume of syslog messages being pushed to ListenSyslog may<br />
  be very high. There are several options to help scale the processing<br />
  depending on the given use-case.</p>
<h4>Concurrent Tasks</h4>
<p>
  ListenSyslog has a background thread reading messages as fast<br />
  as possible and placing them on a blocking queue to be de-queued and processed<br />
  by the onTrigger method of the processor. By increasing the number of<br />
  concurrent tasks for the processor, we can scale up the rate at which messages<br />
  are processed, ensuring new messages can continue to be queued.</p>
<h4>Parsing</h4>
<p>
  One of the more expensive operations during the processing of a message is<br />
  parsing the message in order to provide the the attributes. Parsing messages<br />
  is controlled on the processor through a property and can be turned off in<br />
  cases where the attributes are not needed, and the original message just<br />
  needs to be delivered somewhere.</p>
<h4>Batching</h4>
<p>
  In cases where parsing the messages is not necessary, an additional option is<br />
  batching many messages together during one call to onTrigger. This is<br />
  controlled through the <i>Batch Size</i> property which defaults to "1". This<br />
  would be appropriate in cases where having individual  messages is not<br />
  necessary, such as storing the messages in HDFS where you need them batched<br />
  into appropriately sized files.</p>
<h4>ParseSyslog</h4>
<p>
  In addition to parsing messages directly in ListenSyslog, there is also a<br />
  ParseSyslog processor. An alternative to the flow described in the post<br />
  would be to have ListenSyslog produce batches of 100 messages at a time,<br />
  followed by SplitText, followed by ParseSyslog. The tradeoff here is that<br />
  we can scale the different components independently, and take advantage of<br />
  backpressure between processors.</p>
<h2>Summary</h2>
<p>
  At this point you should be able to get your syslog messages ingested into<br />
  HBase and can experiment with different configurations. The template for this flow can be found<br />
<a href="https://cwiki.apache.org/confluence/download/attachments/57904847/Syslog_HBase.xml?version=1&modificationDate=1449776959701&api=v2">here</a>.</p>
<p>
  We would love to hear any questions, comments, or feedback that you may have!</p>
<p>
  <a href="http://nifi.apache.org">Learn more about Apache NiFi</a> and feel<br />
  free to leave comments here or e-mail us at dev@nifi.apache.org.</p>

  </div><a class="u-url" href="/nifi/entry/storing_syslog_events_in_hbase" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
