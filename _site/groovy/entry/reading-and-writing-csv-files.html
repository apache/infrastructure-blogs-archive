<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Reading and Writing CSV files with Groovy | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Reading and Writing CSV files with Groovy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post, we&#39;ll look at reading and writing CSV files using Groovy. Aren&#39;t CSV files just text files? For simple cases, we can treat CSV files no differently than we would other text files. Suppose we have the following data that we would like to write to a CSV file: def data = [ [&#39;place&#39;, &#39;firstname&#39;, &#39;lastname&#39;, &#39;team&#39;], [&#39;1&#39;, &#39;Lorena&#39;, &#39;Wiebes&#39;, &#39;Team DSM&#39;], [&#39;2&#39;, &#39;Marianne&#39;, &#39;Vos&#39;, &#39;Team Jumbo Visma&#39;], [&#39;3&#39;, &#39;Lotte&#39;, &#39;Kopecky&#39;, &#39;Team SD Worx&#39;]] Groovy uses File or Path objects similar to Java. We&#39;ll use a File object here and, for our purposes, we&#39;ll just use a temporary file since we are just going to read it back in and check it against our data. Here is how to create a temporary file: def file = File.createTempFile(&#39;FemmesStage1Podium&#39;, &#39;.csv&#39;) Writing our CSV (in this simple example) is as simple as joining the data with commas and the lines with line separator character(s): file.text = data*.join(&#39;,&#39;).join(System.lineSeparator()) Here we &quot;wrote&quot; the entire file contents in one go but there are options for writing a line or character or byte at a time. Reading the data in is just as simple. We read the lines and split on commas: assert file.readLines()*.split(&#39;,&#39;) == data In general, we might want to further process the data. Groovy provides nice options for this too. Suppose we have the following existing CSV file: We can read in the file and select various columns of interest with code like below: def file = new File(&#39;HommesStageWinners.csv&#39;)def rows = file.readLines().tail()*.split(&#39;,&#39;)int total = rows.size()Set names = rows.collect { it[1] + &#39; &#39; + it[2] }Set teams = rows*.getAt(3)Set countries = rows*.getAt(4)String result = &quot;Across $total stages, ${names.size()} riders from &quot; + &quot;${teams.size()} teams and ${countries.size()} countries won stages.&quot;assert result == &#39;Across 21 stages, 15 riders from 10 teams and 9 countries won stages.&#39; Here, the tail()&nbsp;method skips over the header line. Column 0 contains the stage number which we ignore. Column 1 contains the first name, column 2 the last name, column 3 the team, and column 4 the country of the rider. We store away the full names, teams and countries in sets to remove duplicates. We then create an overall result message using the size of those sets. While for this simple example, the coding was fairly simple, it isn&#39;t recommended to hand process CSV files in this fashion. The details for CSV can quickly get messy. What if the values themselves contain commas or newlines? Perhaps we can surround in double quotes but then what if the value contains a double quote? And so forth. For this reason, CSV libraries are recommended. We&#39;ll look at three shortly, but first let&#39;s summarise some of the highlights of the tour by looking at multiple winners. Here is some code which summarises our CSV data: def byValueDesc = { -it.value }def bySize = { k, v -&gt; [k, v.size()] }def isMultiple = { it.value &gt; 1 }def multipleWins = { Closure select -&gt; rows .groupBy(select) .collectEntries(bySize) .findAll(isMultiple) .sort(byValueDesc) .entrySet() .join(&#39;, &#39;)}println &#39;Multiple wins by country:\n&#39; + multipleWins{ it[4] }println &#39;Multiple wins by rider:\n&#39; + multipleWins{ it[1] + &#39; &#39; + it[2] }println &#39;Multiple wins by team:\n&#39; + multipleWins{ it[3] } This summary has nothing in particular to do with CSV files but is summarised in honour of the great riding during the tour! Here&#39;s the output: Okay, now let&#39;s look at our three CSV libraries. Commons CSV The Apache Commons CSV library makes writing and parsing CSV files easier. Here is the code for writing our CSV which makes use of the CSVPrinter class: file.withWriter { w -&gt; new CSVPrinter(w, CSVFormat.DEFAULT).printRecords(data)} And here is the code for reading it back in which uses the RFC4180 parser factory singleton: file.withReader { r -&gt; assert RFC4180.parse(r).records*.toList() == data} There are other singleton factories for tab-separated values and other common formats and builders to let you set a whole variety of options like escape characters, quote options, whether to use an enum to define header names, and whether to ignore empty lines or nulls. For our more elaborate example, we have a tiny bit more work to do. We&#39;ll use the builder to tell the parser to skip the header row. We could have chosen to use the tail() trick we used earlier but we decided to use the parser features instead. The code would look like this: file.withReader { r -&gt; def rows = RFC4180.builder() .setHeader() .setSkipHeaderRecord(true) .build() .parse(r) .records assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have used column names rather than column numbers during our processing. Using column names is another advantage of using the CSV library; it would be quite a lot of work to do that aspect by hand. Also note that, for simplicity, we didn&#39;t create the entire&nbsp;result&nbsp;message as in the earlier example. Instead, we just checked the size of all of the relevant sets that we calculated previously. OpenCSV The OpenCSV library handles the messy CSV details when needed but doesn&#39;t get in the way for simple cases. For our first example, the CSVReader and CSVWriter classes will be suitable. Here is the code for writing our CSV file in the same way as earlier: file.withWriter { w -&gt; new CSVWriter(w).writeAll(data.collect{ it as String[] })} And here is the code for reading data: file.withReader { r -&gt; assert new CSVReader(r).readAll() == data} If we look at the produced file, it is already a little fancier than earlier with double quotes around all data: If we want to do more elaborate processing, the CSVReaderHeaderAware class is aware of the initial header row and its column names. Here is our more elaborate example which processed some of the data further: file.withReader { r -&gt; def rows = [] def reader = new CSVReaderHeaderAware(r) while ((next = reader.readMap())) rows &lt;&lt; next assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have again used column names rather than column numbers during our processing. For simplicity, we followed the same style as in the Commons CSV example and just checked the size of all of the relevant sets that we calculated previously. OpenCSV also supports transforming CSV files into JavaBean instances. First, we define our target class (or annotate an existing domain class): class Cyclist { @CsvBindByName(column = &#39;firstname&#39;) String first @CsvBindByName(column = &#39;lastname&#39;) String last @CsvBindByName String team @CsvBindByName String country} For two of the columns, we&#39;ve indicated that the column name in the CSV file doesn&#39;t match our class property. The annotation attribute caters for that scenario. Then, we can use this code to convert our CSV file into a list of domain objects: file.withReader { r -&gt; List rows = new CsvToBeanBuilder(r).withType(Cyclist).build().parse() assert rows.size() == 21 assert rows.collect { it.first + &#39; &#39; + it.last }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9}&lt;/pre&gt; OpenCSV has many options we didn&#39;t show. When writing files you can specify the separator and quote characters, when reading CSV you can specify column positions, types, and validate data. Jackson Databind CSV The Jackson Databind library supports the&nbsp;CSV format (as well as many others). Writing CSV files from existing data is simple as shown here for running example: file.withWriter { w -&gt; new CsvMapper().writeValue(w, data)} This writes the data into our temporary file as we saw with previous examples. One minor difference is that by default, just the values containing spaces will be double quoted but like the other libraries, there are many configuration options to tweak such settings. Reading the data can be achieved using the following code: def mapper = new CsvMapper().readerForListOf(String).with(CsvParser.Feature.WRAP_AS_ARRAY)file.withReader { r -&gt; assert mapper.readValues(r).readAll() == data} Our more elaborate example is done in a similar way: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerForMapOf(String).with(schema)file.withReader { r -&gt; def rows = mapper.readValues(r).readAll() assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} Here, we tell the library to make use of our header row and store each row of data in a map. Jackson Databind also supports writing to classes including JavaBeans as well as records. Let&#39;s create a record to hold our cyclist information: @JsonCreatorrecord Cyclist( @JsonProperty(&#39;stage&#39;) int stage, @JsonProperty(&#39;firstname&#39;) String first, @JsonProperty(&#39;lastname&#39;) String last, @JsonProperty(&#39;team&#39;) String team, @JsonProperty(&#39;country&#39;) String country) { String full() { &quot;$first $last&quot; }} Note that again we can indicate where our record component names may not match the names used in the CSV file, we simply supply the alternate name when specifying the property. There are other options like indicating that a field is required or giving its column position but we don&#39;t need those options for our example. We&#39;ve also added a full() helper method to return the full name of the cyclist. Groovy will use native records on platforms that support it (JDK16+) or emulated records on earlier platforms. Now we can write our code for record deserialization: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerFor(Cyclist).with(schema)file.withReader { r -&gt; List records = mapper.readValues(r).readAll() assert records.size() == 21 assert records*.full().toSet().size() == 15 assert records*.team.toSet().size() == 10 assert records*.country.toSet().size() == 9}&lt;/pre&gt; Conclusion We have looked at writing and reading CSV files to Strings and domain classes and records. We had a look at handling simple cases by hand and also looked at the OpenCSV, Commons CSV and Jackson Databind CSV libraries. Code for these examples:https://github.com/paulk-asert/CsvGroovy Code for other examples of using Groovy for Data Science:https://github.com/paulk-asert/groovy-data-science" />
<meta property="og:description" content="In this post, we&#39;ll look at reading and writing CSV files using Groovy. Aren&#39;t CSV files just text files? For simple cases, we can treat CSV files no differently than we would other text files. Suppose we have the following data that we would like to write to a CSV file: def data = [ [&#39;place&#39;, &#39;firstname&#39;, &#39;lastname&#39;, &#39;team&#39;], [&#39;1&#39;, &#39;Lorena&#39;, &#39;Wiebes&#39;, &#39;Team DSM&#39;], [&#39;2&#39;, &#39;Marianne&#39;, &#39;Vos&#39;, &#39;Team Jumbo Visma&#39;], [&#39;3&#39;, &#39;Lotte&#39;, &#39;Kopecky&#39;, &#39;Team SD Worx&#39;]] Groovy uses File or Path objects similar to Java. We&#39;ll use a File object here and, for our purposes, we&#39;ll just use a temporary file since we are just going to read it back in and check it against our data. Here is how to create a temporary file: def file = File.createTempFile(&#39;FemmesStage1Podium&#39;, &#39;.csv&#39;) Writing our CSV (in this simple example) is as simple as joining the data with commas and the lines with line separator character(s): file.text = data*.join(&#39;,&#39;).join(System.lineSeparator()) Here we &quot;wrote&quot; the entire file contents in one go but there are options for writing a line or character or byte at a time. Reading the data in is just as simple. We read the lines and split on commas: assert file.readLines()*.split(&#39;,&#39;) == data In general, we might want to further process the data. Groovy provides nice options for this too. Suppose we have the following existing CSV file: We can read in the file and select various columns of interest with code like below: def file = new File(&#39;HommesStageWinners.csv&#39;)def rows = file.readLines().tail()*.split(&#39;,&#39;)int total = rows.size()Set names = rows.collect { it[1] + &#39; &#39; + it[2] }Set teams = rows*.getAt(3)Set countries = rows*.getAt(4)String result = &quot;Across $total stages, ${names.size()} riders from &quot; + &quot;${teams.size()} teams and ${countries.size()} countries won stages.&quot;assert result == &#39;Across 21 stages, 15 riders from 10 teams and 9 countries won stages.&#39; Here, the tail()&nbsp;method skips over the header line. Column 0 contains the stage number which we ignore. Column 1 contains the first name, column 2 the last name, column 3 the team, and column 4 the country of the rider. We store away the full names, teams and countries in sets to remove duplicates. We then create an overall result message using the size of those sets. While for this simple example, the coding was fairly simple, it isn&#39;t recommended to hand process CSV files in this fashion. The details for CSV can quickly get messy. What if the values themselves contain commas or newlines? Perhaps we can surround in double quotes but then what if the value contains a double quote? And so forth. For this reason, CSV libraries are recommended. We&#39;ll look at three shortly, but first let&#39;s summarise some of the highlights of the tour by looking at multiple winners. Here is some code which summarises our CSV data: def byValueDesc = { -it.value }def bySize = { k, v -&gt; [k, v.size()] }def isMultiple = { it.value &gt; 1 }def multipleWins = { Closure select -&gt; rows .groupBy(select) .collectEntries(bySize) .findAll(isMultiple) .sort(byValueDesc) .entrySet() .join(&#39;, &#39;)}println &#39;Multiple wins by country:\n&#39; + multipleWins{ it[4] }println &#39;Multiple wins by rider:\n&#39; + multipleWins{ it[1] + &#39; &#39; + it[2] }println &#39;Multiple wins by team:\n&#39; + multipleWins{ it[3] } This summary has nothing in particular to do with CSV files but is summarised in honour of the great riding during the tour! Here&#39;s the output: Okay, now let&#39;s look at our three CSV libraries. Commons CSV The Apache Commons CSV library makes writing and parsing CSV files easier. Here is the code for writing our CSV which makes use of the CSVPrinter class: file.withWriter { w -&gt; new CSVPrinter(w, CSVFormat.DEFAULT).printRecords(data)} And here is the code for reading it back in which uses the RFC4180 parser factory singleton: file.withReader { r -&gt; assert RFC4180.parse(r).records*.toList() == data} There are other singleton factories for tab-separated values and other common formats and builders to let you set a whole variety of options like escape characters, quote options, whether to use an enum to define header names, and whether to ignore empty lines or nulls. For our more elaborate example, we have a tiny bit more work to do. We&#39;ll use the builder to tell the parser to skip the header row. We could have chosen to use the tail() trick we used earlier but we decided to use the parser features instead. The code would look like this: file.withReader { r -&gt; def rows = RFC4180.builder() .setHeader() .setSkipHeaderRecord(true) .build() .parse(r) .records assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have used column names rather than column numbers during our processing. Using column names is another advantage of using the CSV library; it would be quite a lot of work to do that aspect by hand. Also note that, for simplicity, we didn&#39;t create the entire&nbsp;result&nbsp;message as in the earlier example. Instead, we just checked the size of all of the relevant sets that we calculated previously. OpenCSV The OpenCSV library handles the messy CSV details when needed but doesn&#39;t get in the way for simple cases. For our first example, the CSVReader and CSVWriter classes will be suitable. Here is the code for writing our CSV file in the same way as earlier: file.withWriter { w -&gt; new CSVWriter(w).writeAll(data.collect{ it as String[] })} And here is the code for reading data: file.withReader { r -&gt; assert new CSVReader(r).readAll() == data} If we look at the produced file, it is already a little fancier than earlier with double quotes around all data: If we want to do more elaborate processing, the CSVReaderHeaderAware class is aware of the initial header row and its column names. Here is our more elaborate example which processed some of the data further: file.withReader { r -&gt; def rows = [] def reader = new CSVReaderHeaderAware(r) while ((next = reader.readMap())) rows &lt;&lt; next assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have again used column names rather than column numbers during our processing. For simplicity, we followed the same style as in the Commons CSV example and just checked the size of all of the relevant sets that we calculated previously. OpenCSV also supports transforming CSV files into JavaBean instances. First, we define our target class (or annotate an existing domain class): class Cyclist { @CsvBindByName(column = &#39;firstname&#39;) String first @CsvBindByName(column = &#39;lastname&#39;) String last @CsvBindByName String team @CsvBindByName String country} For two of the columns, we&#39;ve indicated that the column name in the CSV file doesn&#39;t match our class property. The annotation attribute caters for that scenario. Then, we can use this code to convert our CSV file into a list of domain objects: file.withReader { r -&gt; List rows = new CsvToBeanBuilder(r).withType(Cyclist).build().parse() assert rows.size() == 21 assert rows.collect { it.first + &#39; &#39; + it.last }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9}&lt;/pre&gt; OpenCSV has many options we didn&#39;t show. When writing files you can specify the separator and quote characters, when reading CSV you can specify column positions, types, and validate data. Jackson Databind CSV The Jackson Databind library supports the&nbsp;CSV format (as well as many others). Writing CSV files from existing data is simple as shown here for running example: file.withWriter { w -&gt; new CsvMapper().writeValue(w, data)} This writes the data into our temporary file as we saw with previous examples. One minor difference is that by default, just the values containing spaces will be double quoted but like the other libraries, there are many configuration options to tweak such settings. Reading the data can be achieved using the following code: def mapper = new CsvMapper().readerForListOf(String).with(CsvParser.Feature.WRAP_AS_ARRAY)file.withReader { r -&gt; assert mapper.readValues(r).readAll() == data} Our more elaborate example is done in a similar way: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerForMapOf(String).with(schema)file.withReader { r -&gt; def rows = mapper.readValues(r).readAll() assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} Here, we tell the library to make use of our header row and store each row of data in a map. Jackson Databind also supports writing to classes including JavaBeans as well as records. Let&#39;s create a record to hold our cyclist information: @JsonCreatorrecord Cyclist( @JsonProperty(&#39;stage&#39;) int stage, @JsonProperty(&#39;firstname&#39;) String first, @JsonProperty(&#39;lastname&#39;) String last, @JsonProperty(&#39;team&#39;) String team, @JsonProperty(&#39;country&#39;) String country) { String full() { &quot;$first $last&quot; }} Note that again we can indicate where our record component names may not match the names used in the CSV file, we simply supply the alternate name when specifying the property. There are other options like indicating that a field is required or giving its column position but we don&#39;t need those options for our example. We&#39;ve also added a full() helper method to return the full name of the cyclist. Groovy will use native records on platforms that support it (JDK16+) or emulated records on earlier platforms. Now we can write our code for record deserialization: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerFor(Cyclist).with(schema)file.withReader { r -&gt; List records = mapper.readValues(r).readAll() assert records.size() == 21 assert records*.full().toSet().size() == 15 assert records*.team.toSet().size() == 10 assert records*.country.toSet().size() == 9}&lt;/pre&gt; Conclusion We have looked at writing and reading CSV files to Strings and domain classes and records. We had a look at handling simple cases by hand and also looked at the OpenCSV, Commons CSV and Jackson Databind CSV libraries. Code for these examples:https://github.com/paulk-asert/CsvGroovy Code for other examples of using Groovy for Data Science:https://github.com/paulk-asert/groovy-data-science" />
<link rel="canonical" href="http://localhost:4000/groovy/entry/reading-and-writing-csv-files" />
<meta property="og:url" content="http://localhost:4000/groovy/entry/reading-and-writing-csv-files" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-25T23:14:24-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reading and Writing CSV files with Groovy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-07-25T23:14:24-04:00","datePublished":"2022-07-25T23:14:24-04:00","description":"In this post, we&#39;ll look at reading and writing CSV files using Groovy. Aren&#39;t CSV files just text files? For simple cases, we can treat CSV files no differently than we would other text files. Suppose we have the following data that we would like to write to a CSV file: def data = [ [&#39;place&#39;, &#39;firstname&#39;, &#39;lastname&#39;, &#39;team&#39;], [&#39;1&#39;, &#39;Lorena&#39;, &#39;Wiebes&#39;, &#39;Team DSM&#39;], [&#39;2&#39;, &#39;Marianne&#39;, &#39;Vos&#39;, &#39;Team Jumbo Visma&#39;], [&#39;3&#39;, &#39;Lotte&#39;, &#39;Kopecky&#39;, &#39;Team SD Worx&#39;]] Groovy uses File or Path objects similar to Java. We&#39;ll use a File object here and, for our purposes, we&#39;ll just use a temporary file since we are just going to read it back in and check it against our data. Here is how to create a temporary file: def file = File.createTempFile(&#39;FemmesStage1Podium&#39;, &#39;.csv&#39;) Writing our CSV (in this simple example) is as simple as joining the data with commas and the lines with line separator character(s): file.text = data*.join(&#39;,&#39;).join(System.lineSeparator()) Here we &quot;wrote&quot; the entire file contents in one go but there are options for writing a line or character or byte at a time. Reading the data in is just as simple. We read the lines and split on commas: assert file.readLines()*.split(&#39;,&#39;) == data In general, we might want to further process the data. Groovy provides nice options for this too. Suppose we have the following existing CSV file: We can read in the file and select various columns of interest with code like below: def file = new File(&#39;HommesStageWinners.csv&#39;)def rows = file.readLines().tail()*.split(&#39;,&#39;)int total = rows.size()Set names = rows.collect { it[1] + &#39; &#39; + it[2] }Set teams = rows*.getAt(3)Set countries = rows*.getAt(4)String result = &quot;Across $total stages, ${names.size()} riders from &quot; + &quot;${teams.size()} teams and ${countries.size()} countries won stages.&quot;assert result == &#39;Across 21 stages, 15 riders from 10 teams and 9 countries won stages.&#39; Here, the tail()&nbsp;method skips over the header line. Column 0 contains the stage number which we ignore. Column 1 contains the first name, column 2 the last name, column 3 the team, and column 4 the country of the rider. We store away the full names, teams and countries in sets to remove duplicates. We then create an overall result message using the size of those sets. While for this simple example, the coding was fairly simple, it isn&#39;t recommended to hand process CSV files in this fashion. The details for CSV can quickly get messy. What if the values themselves contain commas or newlines? Perhaps we can surround in double quotes but then what if the value contains a double quote? And so forth. For this reason, CSV libraries are recommended. We&#39;ll look at three shortly, but first let&#39;s summarise some of the highlights of the tour by looking at multiple winners. Here is some code which summarises our CSV data: def byValueDesc = { -it.value }def bySize = { k, v -&gt; [k, v.size()] }def isMultiple = { it.value &gt; 1 }def multipleWins = { Closure select -&gt; rows .groupBy(select) .collectEntries(bySize) .findAll(isMultiple) .sort(byValueDesc) .entrySet() .join(&#39;, &#39;)}println &#39;Multiple wins by country:\\n&#39; + multipleWins{ it[4] }println &#39;Multiple wins by rider:\\n&#39; + multipleWins{ it[1] + &#39; &#39; + it[2] }println &#39;Multiple wins by team:\\n&#39; + multipleWins{ it[3] } This summary has nothing in particular to do with CSV files but is summarised in honour of the great riding during the tour! Here&#39;s the output: Okay, now let&#39;s look at our three CSV libraries. Commons CSV The Apache Commons CSV library makes writing and parsing CSV files easier. Here is the code for writing our CSV which makes use of the CSVPrinter class: file.withWriter { w -&gt; new CSVPrinter(w, CSVFormat.DEFAULT).printRecords(data)} And here is the code for reading it back in which uses the RFC4180 parser factory singleton: file.withReader { r -&gt; assert RFC4180.parse(r).records*.toList() == data} There are other singleton factories for tab-separated values and other common formats and builders to let you set a whole variety of options like escape characters, quote options, whether to use an enum to define header names, and whether to ignore empty lines or nulls. For our more elaborate example, we have a tiny bit more work to do. We&#39;ll use the builder to tell the parser to skip the header row. We could have chosen to use the tail() trick we used earlier but we decided to use the parser features instead. The code would look like this: file.withReader { r -&gt; def rows = RFC4180.builder() .setHeader() .setSkipHeaderRecord(true) .build() .parse(r) .records assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have used column names rather than column numbers during our processing. Using column names is another advantage of using the CSV library; it would be quite a lot of work to do that aspect by hand. Also note that, for simplicity, we didn&#39;t create the entire&nbsp;result&nbsp;message as in the earlier example. Instead, we just checked the size of all of the relevant sets that we calculated previously. OpenCSV The OpenCSV library handles the messy CSV details when needed but doesn&#39;t get in the way for simple cases. For our first example, the CSVReader and CSVWriter classes will be suitable. Here is the code for writing our CSV file in the same way as earlier: file.withWriter { w -&gt; new CSVWriter(w).writeAll(data.collect{ it as String[] })} And here is the code for reading data: file.withReader { r -&gt; assert new CSVReader(r).readAll() == data} If we look at the produced file, it is already a little fancier than earlier with double quotes around all data: If we want to do more elaborate processing, the CSVReaderHeaderAware class is aware of the initial header row and its column names. Here is our more elaborate example which processed some of the data further: file.withReader { r -&gt; def rows = [] def reader = new CSVReaderHeaderAware(r) while ((next = reader.readMap())) rows &lt;&lt; next assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} You can see here that we have again used column names rather than column numbers during our processing. For simplicity, we followed the same style as in the Commons CSV example and just checked the size of all of the relevant sets that we calculated previously. OpenCSV also supports transforming CSV files into JavaBean instances. First, we define our target class (or annotate an existing domain class): class Cyclist { @CsvBindByName(column = &#39;firstname&#39;) String first @CsvBindByName(column = &#39;lastname&#39;) String last @CsvBindByName String team @CsvBindByName String country} For two of the columns, we&#39;ve indicated that the column name in the CSV file doesn&#39;t match our class property. The annotation attribute caters for that scenario. Then, we can use this code to convert our CSV file into a list of domain objects: file.withReader { r -&gt; List rows = new CsvToBeanBuilder(r).withType(Cyclist).build().parse() assert rows.size() == 21 assert rows.collect { it.first + &#39; &#39; + it.last }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9}&lt;/pre&gt; OpenCSV has many options we didn&#39;t show. When writing files you can specify the separator and quote characters, when reading CSV you can specify column positions, types, and validate data. Jackson Databind CSV The Jackson Databind library supports the&nbsp;CSV format (as well as many others). Writing CSV files from existing data is simple as shown here for running example: file.withWriter { w -&gt; new CsvMapper().writeValue(w, data)} This writes the data into our temporary file as we saw with previous examples. One minor difference is that by default, just the values containing spaces will be double quoted but like the other libraries, there are many configuration options to tweak such settings. Reading the data can be achieved using the following code: def mapper = new CsvMapper().readerForListOf(String).with(CsvParser.Feature.WRAP_AS_ARRAY)file.withReader { r -&gt; assert mapper.readValues(r).readAll() == data} Our more elaborate example is done in a similar way: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerForMapOf(String).with(schema)file.withReader { r -&gt; def rows = mapper.readValues(r).readAll() assert rows.size() == 21 assert rows.collect { it.firstname + &#39; &#39; + it.lastname }.toSet().size() == 15 assert rows*.team.toSet().size() == 10 assert rows*.country.toSet().size() == 9} Here, we tell the library to make use of our header row and store each row of data in a map. Jackson Databind also supports writing to classes including JavaBeans as well as records. Let&#39;s create a record to hold our cyclist information: @JsonCreatorrecord Cyclist( @JsonProperty(&#39;stage&#39;) int stage, @JsonProperty(&#39;firstname&#39;) String first, @JsonProperty(&#39;lastname&#39;) String last, @JsonProperty(&#39;team&#39;) String team, @JsonProperty(&#39;country&#39;) String country) { String full() { &quot;$first $last&quot; }} Note that again we can indicate where our record component names may not match the names used in the CSV file, we simply supply the alternate name when specifying the property. There are other options like indicating that a field is required or giving its column position but we don&#39;t need those options for our example. We&#39;ve also added a full() helper method to return the full name of the cyclist. Groovy will use native records on platforms that support it (JDK16+) or emulated records on earlier platforms. Now we can write our code for record deserialization: def schema = CsvSchema.emptySchema().withHeader()def mapper = new CsvMapper().readerFor(Cyclist).with(schema)file.withReader { r -&gt; List records = mapper.readValues(r).readAll() assert records.size() == 21 assert records*.full().toSet().size() == 15 assert records*.team.toSet().size() == 10 assert records*.country.toSet().size() == 9}&lt;/pre&gt; Conclusion We have looked at writing and reading CSV files to Strings and domain classes and records. We had a look at handling simple cases by hand and also looked at the OpenCSV, Commons CSV and Jackson Databind CSV libraries. Code for these examples:https://github.com/paulk-asert/CsvGroovy Code for other examples of using Groovy for Data Science:https://github.com/paulk-asert/groovy-data-science","headline":"Reading and Writing CSV files with Groovy","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/groovy/entry/reading-and-writing-csv-files"},"url":"http://localhost:4000/groovy/entry/reading-and-writing-csv-files"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Reading and Writing CSV files with Groovy</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-07-25T23:14:24-04:00" itemprop="datePublished">Jul 25, 2022
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"Paul King", "login"=>"paulk", "email"=>"paulk@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In this post, we'll look at reading and writing CSV files using Groovy.</p>
<h3>Aren't CSV files just text files?</h3>
<p>For simple cases, we can treat CSV files no differently than we would other text files. Suppose we have the following data that we would like to write to a CSV file:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>data = [<br>        [<span style="color:#6a8759;">'place'</span>, <span style="color:#6a8759;">'firstname'</span>, <span style="color:#6a8759;">'lastname'</span>, <span style="color:#6a8759;">'team'</span>],<br>        [<span style="color:#6a8759;">'1'</span>, <span style="color:#6a8759;">'Lorena'</span>, <span style="color:#6a8759;">'Wiebes'</span>, <span style="color:#6a8759;">'Team DSM'</span>],<br>        [<span style="color:#6a8759;">'2'</span>, <span style="color:#6a8759;">'Marianne'</span>, <span style="color:#6a8759;">'Vos'</span>, <span style="color:#6a8759;">'Team Jumbo Visma'</span>],<br>        [<span style="color:#6a8759;">'3'</span>, <span style="color:#6a8759;">'Lotte'</span>, <span style="color:#6a8759;">'Kopecky'</span>, <span style="color:#6a8759;">'Team SD Worx'</span>]<br>]<br></pre>
<p>Groovy uses <code>File</code> or <code>Path</code> objects similar to Java. We'll use a <code>File</code> object here and, for our purposes, we'll just use a temporary file since we are just going to read it back in and check it against our data. Here is how to create a temporary file:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>file = File.<span style="color:#9876aa;font-style:italic;">createTempFile</span>(<span style="color:#6a8759;">'FemmesStage1Podium'</span>, <span style="color:#6a8759;">'.csv'</span>)</pre>
<p>Writing our CSV (in this simple example) is as simple as joining the data with commas and the lines with line separator character(s):</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.<span style="color:#9876aa;">text </span>= data*.join(<span style="color:#6a8759;">','</span>).join(System.<span style="color:#9876aa;font-style:italic;">lineSeparator</span>())</pre>
<p>Here we "wrote" the entire file contents in one go but there are options for writing a line or character or byte at a time.</p>
<p>Reading the data in is just as simple. We read the lines and split on commas:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">assert </span>file.readLines()*.split(<span style="color:#6a8759;">'</span><span style="color:#6a8759;background-color:#364135;">,</span><span style="color:#6a8759;">'</span>) == data</pre>
<p>In general, we might want to further process the data. Groovy provides nice options for this too. Suppose we have the following existing CSV file:<br><br />
<img src="https://blogs.apache.org/groovy/mediaresource/0128cd28-23e8-42ca-b408-c2eaf1c82d1c" style="border:1px solid grey; width:60%;" alt="HommesOverall.png"><br>We can read in the file and select various columns of interest with code like below:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>file = <span style="color:#cc7832;">new </span>File(<span style="color:#6a8759;">'HommesStageWinners.csv'</span>)<br><span style="color:#cc7832;">def </span>rows = file.readLines().tail()*.split(<span style="color:#6a8759;">'</span><span style="color:#6a8759;background-color:#364135;">,</span><span style="color:#6a8759;">'</span>)<br><span style="color:#cc7832;">int </span>total = rows.size()<br>Set names = rows.collect <span style="font-weight:bold;">{ </span>it[<span style="color:#6897bb;">1</span>] + <span style="color:#6a8759;">' ' </span>+ it[<span style="color:#6897bb;">2</span>] <span style="font-weight:bold;">}<br></span>Set teams = rows*.getAt(<span style="color:#6897bb;">3</span>)<br>Set countries = rows*.getAt(<span style="color:#6897bb;">4</span>)<br>String result = <span style="color:#6a8759;">"Across </span>$total<span style="color:#6a8759;"> stages, </span>$<span style="font-weight:bold;">{</span>names.size()<span style="font-weight:bold;">}</span><span style="color:#6a8759;"> riders from " </span>+<br>        <span style="color:#6a8759;">"</span>$<span style="font-weight:bold;">{</span>teams.size()<span style="font-weight:bold;">}</span><span style="color:#6a8759;"> teams and </span>$<span style="font-weight:bold;">{</span>countries.size()<span style="font-weight:bold;">}</span><span style="color:#6a8759;"> countries won stages."<br></span><span style="color:#cc7832;">assert </span>result == <span style="color:#6a8759;">'Across 21 stages, 15 riders from 10 teams and 9 countries won stages.'<br></span></pre>
<p>Here, the <code>tail()</code>&nbsp;method skips over the header line. Column 0 contains the stage number which we ignore. Column 1 contains the first name, column 2 the last name, column 3 the team, and column 4 the country of the rider. We store away the full names, teams and countries in sets to remove duplicates. We then create an overall result message using the size of those sets.</p>
<p>While for this simple example, the coding was fairly simple, it isn't recommended to hand process CSV files in this fashion. The details for CSV can quickly get messy. What if the values themselves contain commas or newlines? Perhaps we can surround in double quotes but then what if the value contains a double quote? And so forth. For this reason, CSV libraries are recommended.</p>
<p>We'll look at three shortly, but first let's summarise some of the highlights of the tour by looking at multiple winners. Here is some code which summarises our CSV data:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>byValueDesc = <span style="font-weight:bold;">{ </span>-it.value <span style="font-weight:bold;">}<br></span><span style="color:#cc7832;">def </span>bySize = <span style="font-weight:bold;">{ </span>k, v <span style="font-weight:bold;">-> </span>[k, v.size()] <span style="font-weight:bold;">}<br></span><span style="color:#cc7832;">def </span>isMultiple = <span style="font-weight:bold;">{ </span>it.value > <span style="color:#6897bb;">1 </span><span style="font-weight:bold;">}<br></span><span style="color:#cc7832;">def </span>multipleWins = <span style="font-weight:bold;">{ </span>Closure select <span style="font-weight:bold;">-> </span>rows<br>    .groupBy(select)<br>    .collectEntries(bySize)<br>    .findAll(isMultiple)<br>    .sort(byValueDesc)<br>    .entrySet()<br>    .join(<span style="color:#6a8759;">', '</span>)<br><span style="font-weight:bold;">}<br></span>println <span style="color:#6a8759;">'Multiple wins by country:</span><span style="color:#cc7832;">\n</span><span style="color:#6a8759;">' </span>+ multipleWins<span style="font-weight:bold;">{ </span>it[<span style="color:#6897bb;">4</span>] <span style="font-weight:bold;">}<br></span>println <span style="color:#6a8759;">'Multiple wins by rider:</span><span style="color:#cc7832;">\n</span><span style="color:#6a8759;">' </span>+ multipleWins<span style="font-weight:bold;">{ </span>it[<span style="color:#6897bb;">1</span>] + <span style="color:#6a8759;">' ' </span>+ it[<span style="color:#6897bb;">2</span>] <span style="font-weight:bold;">}<br></span>println <span style="color:#6a8759;">'Multiple wins by team:</span><span style="color:#cc7832;">\n</span><span style="color:#6a8759;">' </span>+ multipleWins<span style="font-weight:bold;">{ </span>it[<span style="color:#6897bb;">3</span>] <span style="font-weight:bold;">}<br></span></pre>
<p>This summary has nothing in particular to do with CSV files but is summarised in honour of the great riding during the tour! Here's the output:</p>
<p><img src="https://blogs.apache.org/groovy/mediaresource/878dc821-991f-468c-823d-7672ddeccb98" style="width:80%;" alt="MultipleWins.png"><br></p>
<p>Okay, now let's look at our three CSV libraries.</p>
<h3>Commons CSV</h3>
<p>The <a href="https://commons.apache.org/proper/commons-csv/" target="_blank">Apache Commons CSV</a> library makes writing and parsing CSV files easier. Here is the code for writing our CSV which makes use of the <code>CSVPrinter</code> class:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withWriter <span style="font-weight:bold;">{ </span>w <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">new </span>CSVPrinter(w, CSVFormat.<span style="color:#9876aa;font-style:italic;">DEFAULT</span>).printRecords(data)<br><span style="font-weight:bold;">}<br></span></pre>
<p>And here is the code for reading it back in which uses the <code>RFC4180</code> parser factory singleton:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">assert </span><span style="color:#9876aa;font-style:italic;">RFC4180</span>.parse(r).<span style="color:#9876aa;">records</span>*.toList() == data<br><span style="font-weight:bold;">}<br></span></pre>
<p>There are other singleton factories for tab-separated values and other common formats and builders to let you set a whole variety of options like escape characters, quote options, whether to use an enum to define header names, and whether to ignore empty lines or nulls.</p>
<p>For our more elaborate example, we have a tiny bit more work to do. We'll use the builder to tell the parser to skip the header row. We could have chosen to use the <code>tail()</code> trick we used earlier but we decided to use the parser features instead. The code would look like this:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">def </span>rows = <span style="color:#9876aa;font-style:italic;">RFC4180</span>.builder()<br>            .setHeader()<br>            .setSkipHeaderRecord(<span style="color:#cc7832;">true</span>)<br>            .build()<br>            .parse(r)<br>            .<span style="color:#9876aa;">records<br></span><span style="color:#9876aa;">    </span><span style="color:#cc7832;">assert </span>rows.size() == <span style="color:#6897bb;">21<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows.collect <span style="font-weight:bold;">{ </span>it.firstname + <span style="color:#6a8759;">' ' </span>+ it.lastname <span style="font-weight:bold;">}</span>.toSet().size() == <span style="color:#6897bb;">15<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.team.toSet().size() == <span style="color:#6897bb;">10<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.country.toSet().size() == <span style="color:#6897bb;">9<br></span><span style="font-weight:bold;">}<br></span></pre>
<p>You can see here that we have used column names rather than column numbers during our processing. Using column names is another advantage of using the CSV library; it would be quite a lot of work to do that aspect by hand. Also note that, for simplicity, we didn't create the entire&nbsp;<i>result</i>&nbsp;message as in the earlier example. Instead, we just checked the size of all of the relevant sets that we calculated previously.<br></p>
<h3>OpenCSV</h3>
<p>The <a href="http://opencsv.sourceforge.net/" target="_blank">OpenCSV</a> library handles the messy CSV details when needed but doesn't get in the way for simple cases. For our first example, the <code>CSVReader</code> and <code>CSVWriter</code> classes will be suitable. Here is the code for writing our CSV file in the same way as earlier:<br></p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withWriter <span style="font-weight:bold;">{ </span>w <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">new </span>CSVWriter(w).writeAll(data.collect<span style="font-weight:bold;">{ </span>it <span style="color:#cc7832;">as </span>String[] <span style="font-weight:bold;">}</span>)<br><span style="font-weight:bold;">}<br></span></pre>
<p>And here is the code for reading data:<br></p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">assert new </span>CSVReader(r).readAll() == data<br><span style="font-weight:bold;">}<br></span></pre>
<p>If we look at the produced file, it is already a little fancier than earlier with double quotes around all data:</p>
<p><img src="https://blogs.apache.org/groovy/mediaresource/f226d423-3408-4aaa-ba3e-d835e6c894aa" style="width:40%;" alt="FemmesPodiumStage1.png"><br></p>
<p>If we want to do more elaborate processing, the <code>CSVReaderHeaderAware</code> class is aware of the initial header row and its column names. Here is our more elaborate example which processed some of the data further:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">def </span>rows = []<br>    <span style="color:#cc7832;">def </span>reader = <span style="color:#cc7832;">new </span>CSVReaderHeaderAware(r)<br>    <span style="color:#cc7832;">while </span>((next = reader.readMap())) rows << next<br>    <span style="color:#cc7832;">assert </span>rows.size() == <span style="color:#6897bb;">21<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows.collect <span style="font-weight:bold;">{ </span>it.firstname + <span style="color:#6a8759;">' ' </span>+ it.lastname <span style="font-weight:bold;">}</span>.toSet().size() == <span style="color:#6897bb;">15<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.team.toSet().size() == <span style="color:#6897bb;">10<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.country.toSet().size() == <span style="color:#6897bb;">9<br></span><span style="font-weight:bold;">}<br></span></pre>
<p>You can see here that we have again used column names rather than column numbers during our processing. For simplicity, we followed the same style as in the Commons CSV example and just checked the size of all of the relevant sets that we calculated previously.</p>
<p>OpenCSV also supports transforming CSV files into JavaBean instances. First, we define our target class (or annotate an existing domain class):<br></p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">class </span>Cyclist {<br>    <span style="color:#bbb529;">@CsvBindByName</span>(column = <span style="color:#6a8759;">'firstname'</span>)<br>    String <span style="color:#9876aa;">first<br></span><span style="color:#9876aa;">    </span><span style="color:#bbb529;">@CsvBindByName</span>(column = <span style="color:#6a8759;">'lastname'</span>)<br>    String <span style="color:#9876aa;">last<br></span><span style="color:#9876aa;">    </span><span style="color:#bbb529;">@CsvBindByName<br></span><span style="color:#bbb529;">    </span>String <span style="color:#9876aa;">team<br></span><span style="color:#9876aa;">    </span><span style="color:#bbb529;">@CsvBindByName<br></span><span style="color:#bbb529;">    </span>String <span style="color:#9876aa;">country<br></span>}<br></pre>
<p>For two of the columns, we've indicated that the column name in the CSV file doesn't match our class property. The annotation attribute caters for that scenario.</p>
<p>Then, we can use this code to convert our CSV file into a list of domain objects:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span>List<Cyclist> rows = <span style="color:#cc7832;">new </span>CsvToBeanBuilder(r).withType(Cyclist).build().parse()<br>    <span style="color:#cc7832;">assert </span>rows.size() == <span style="color:#6897bb;">21<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows.collect <span style="font-weight:bold;">{ </span>it.first + <span style="color:#6a8759;">' ' </span>+ it.last <span style="font-weight:bold;">}</span>.toSet().size() == <span style="color:#6897bb;">15<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.team.toSet().size() == <span style="color:#6897bb;">10<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.country.toSet().size() == <span style="color:#6897bb;">9<br></span><span style="font-weight:bold;">}<br></span></pre>
<p>OpenCSV has many options we didn't show. When writing files you can specify the separator and quote characters, when reading CSV you can specify column positions, types, and validate data.</p>
<h3>Jackson Databind CSV</h3>
<p>The <a href="https://github.com/FasterXML/jackson-databind" target="_blank">Jackson Databind</a> library supports the&nbsp;<a href="https://github.com/FasterXML/jackson-dataformats-text/tree/master/csv" target="_blank">CSV</a> format (as well as many others).</p>
<p>Writing CSV files from existing data is simple as shown here for running example:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;">file.withWriter <span style="font-weight:bold;">{ </span>w <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">new </span>CsvMapper().writeValue(w, data)<br><span style="font-weight:bold;">}<br></span></pre>
<p>This writes the data into our temporary file as we saw with previous examples. One minor difference is that by default, just the values containing spaces will be double quoted but like the other libraries, there are many configuration options to tweak such settings.</p>
<p>Reading the data can be achieved using the following code:<br></p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>mapper = <span style="color:#cc7832;">new </span>CsvMapper().readerForListOf(String).with(CsvParser.Feature.<span style="color:#9876aa;font-style:italic;">WRAP_AS_ARRAY</span>)<br>file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">assert </span>mapper.readValues(r).readAll() == data<br><span style="font-weight:bold;">}<br></span></pre>
<p>Our more elaborate example is done in a similar way:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>schema = CsvSchema.<span style="color:#9876aa;font-style:italic;">emptySchema</span>().withHeader()<br><span style="color:#cc7832;">def </span>mapper = <span style="color:#cc7832;">new </span>CsvMapper().readerForMapOf(String).with(schema)<br>file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span><span style="color:#cc7832;">def </span>rows = mapper.readValues(r).readAll()<br>    <span style="color:#cc7832;">assert </span>rows.size() == <span style="color:#6897bb;">21<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows.collect <span style="font-weight:bold;">{ </span>it.firstname + <span style="color:#6a8759;">' ' </span>+ it.lastname <span style="font-weight:bold;">}</span>.toSet().size() == <span style="color:#6897bb;">15<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.team.toSet().size() == <span style="color:#6897bb;">10<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>rows*.country.toSet().size() == <span style="color:#6897bb;">9<br></span><span style="font-weight:bold;">}<br></span></pre>
<p>Here, we tell the library to make use of our header row and store each row of data in a map.</p>
<p>Jackson Databind also supports writing to classes including JavaBeans as well as records. Let's create a record to hold our cyclist information:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#bbb529;">@JsonCreator<br></span><span style="color:#cc7832;">record </span>Cyclist(<br>        <span style="color:#bbb529;">@JsonProperty</span>(<span style="color:#6a8759;">'stage'</span>) <span style="color:#cc7832;">int </span>stage,<br>        <span style="color:#bbb529;">@JsonProperty</span>(<span style="color:#6a8759;">'firstname'</span>) String first,<br>        <span style="color:#bbb529;">@JsonProperty</span>(<span style="color:#6a8759;">'lastname'</span>) String last,<br>        <span style="color:#bbb529;">@JsonProperty</span>(<span style="color:#6a8759;">'team'</span>) String team,<br>        <span style="color:#bbb529;">@JsonProperty</span>(<span style="color:#6a8759;">'country'</span>) String country) {<br>    String full() { <span style="color:#6a8759;">"</span>$<span style="color:#9876aa;">first </span>$<span style="color:#9876aa;">last</span><span style="color:#6a8759;">" </span>}<br>}<br></pre>
<p>Note that again we can indicate where our record component names may not match the names used in the CSV file, we simply supply the alternate name when specifying the property. There are other options like indicating that a field is required or giving its column position but we don't need those options for our example. We've also added a <code>full()</code> helper method to return the full name of the cyclist.</p>
<p>Groovy will use native records on platforms that support it (JDK16+) or emulated records on earlier platforms.</p>
<p>Now we can write our code for record deserialization:</p>
<pre style="background-color:#2b2b2b;color:#a9b7c6;font-family:'JetBrains Mono',monospace;font-size:9.6pt;"><span style="color:#cc7832;">def </span>schema = CsvSchema.<span style="color:#9876aa;font-style:italic;">emptySchema</span>().withHeader()<br><span style="color:#cc7832;">def </span>mapper = <span style="color:#cc7832;">new </span>CsvMapper().readerFor(Cyclist).with(schema)<br>file.withReader <span style="font-weight:bold;">{ </span>r <span style="font-weight:bold;">-><br></span><span style="font-weight:bold;">    </span>List<Cyclist> records = mapper.readValues(r).readAll()<br>    <span style="color:#cc7832;">assert </span>records.size() == <span style="color:#6897bb;">21<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>records*.full().toSet().size() == <span style="color:#6897bb;">15<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>records*.<span style="color:#9876aa;">team</span>.toSet().size() == <span style="color:#6897bb;">10<br></span><span style="color:#6897bb;">    </span><span style="color:#cc7832;">assert </span>records*.<span style="color:#9876aa;">country</span>.toSet().size() == <span style="color:#6897bb;">9<br></span><span style="font-weight:bold;">}<br></span></pre>
<h3>Conclusion</h3>
<p>We have looked at writing and reading CSV files to Strings and domain classes and records. We had a look at handling simple cases by hand and also looked at the OpenCSV, Commons CSV and Jackson Databind CSV libraries.</p>
<p>Code for these examples:<br><a href="https://github.com/paulk-asert/CsvGroovy" target="_blank">https://github.com/paulk-asert/CsvGroovy</a><br></p>
<p>Code for other examples of using Groovy for Data Science:<br><a href="https://github.com/paulk-asert/groovy-data-science" target="_blank">https://github.com/paulk-asert/groovy-data-science</a><br></p>
<p><br></p>
<p><br></p>

  </div><a class="u-url" href="/groovy/entry/reading-and-writing-csv-files" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
