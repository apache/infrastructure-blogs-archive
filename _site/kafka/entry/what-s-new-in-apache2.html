<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>What’s New in Apache Kafka 2.5.0 | Blogs Archive</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="What’s New in Apache Kafka 2.5.0" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="On behalf of the Apache Kafka&reg; community, it is my pleasure to announce the release of Apache Kafka 2.5.0. The community has created another exciting release. We are making progress on KIP-500 and have added new metrics and security features, among other improvements. This blog post goes into detail on some of the added functionality, but to get a full list of what&rsquo;s new in this release, please see the release notes. Kafka broker, producer, and consumer KIP-500 update In Apache Kafka 2.5, some preparatory work has been done towards the removal of Apache ZooKeeper&amp;#x2122; (ZK). KIP-555: details about the ZooKeeper deprecation process in admin tools KIP-543: dynamic configs will not require ZooKeeper access Exactly once semantics (EOS) &ndash; Foundational improvements KIP-447: Producer scalability for exactly once semantics This KIP simplifies the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build EOS applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release. See KIP-447 for more details. KIP-360: Improve reliability of idempotent/transactional producer This KIP addresses a problem with producer state retention on the broker, which is what makes the idempotence guarantee possible. Previously, when the log was truncated to enforce retention or truncated from a call to delete records, the broker dropped producer state, which led to UnknownProducerId errors. With this improvement, the broker instead retains producer state until expiration. This KIP also gives the producer a powerful way to recover from unexpected errors. See KIP-360 for more details. Metrics and operational improvements KIP-515: Enable ZK client to use the new TLS supported authentication (ZK 3.5.7) Apache Kafka 2.5 now ships ZooKeeper 3.5.7. One feature of note is the newly added ZooKeeper TLS support in ZooKeeper 3.5. When deploying a secure Kafka cluster, it&rsquo;s critical to use TLS to encrypt communication in transit. Apache Kafka 2.4 already ships with ZooKeeper 3.5, which adds TLS support between the broker and ZooKeeper. However, configuration information has to be passed via system properties as -D command line options on the Java invocation of the broker or CLI tool (e.g., zookeeper-security-migration), which is not secure. KIP-515 introduces the necessary changes to enable the use of secure configuration values for using TLS with ZooKeeper. ZooKeeper 3.5.7 supports both mutual TLS authentication via its ssl.clientAuth=required configuration value and TLS encryption without client certificate authentication via ssl.clientAuth=none. See KIP-515 for more details. KIP-511: Collect and Expose Client&#8217;s Name and Version in the Brokers Previously, operators of Apache Kafka could only identify incoming clients using the clientId field set on the consumer and producer. As this field is typically used to identify different applications, it leaves a gap in operational insight regarding client software libraries and versions. KIP-511 introduces two new fields to the ApiVersionsRequest RPC: ClientSoftwareName and ClientSoftwareVersion. These fields are captured by the broker and reported through a new set of metrics. The metric MBean pattern is: kafka.server:clientSoftwareName=(client-software-name),clientSoftwareVersion=(client-software-version),listener=(listener),networkProcessor=(processor-index),type=(type) For example, the Apache Kafka 2.4 Java client produces the following MBean on the broker: kafka.server:clientSoftwareName=apache-kafka-java,clientSoftwareVersion=2.4.0,listener=PLAINTEXT,networkProcessor=1,type=socket-server-metrics See KIP-511 for more details. KIP-559: Make the Kafka Protocol Friendlier with L7 Proxies This KIP identifies and improves several parts of our protocol, which were not fully self-describing. Some of our APIs have generic bytes fields, which have implicit encoding. Additional context is needed to properly decode these fields. This KIP addresses this problem by adding the necessary context to the API so L7 proxies can fully decode our protocols. See KIP-559 for more details. &lt;h4 id=”kip-541””&gt;KIP-541: Create a fetch.max.bytes configuration for the broker&lt;/h4&gt; Kafka consumers can choose the maximum number of bytes to fetch by setting the client-side configuration fetch.max.bytes. Too high of a value may degrade performance on the broker for other consumers. If the value is extremely high, the client request may time out. KIP-541 centralizes this configuration with a broker setting that puts an upper limit on the maximum number of bytes that the client can choose to fetch. See KIP-541 for more details. Kafka Connect KIP-558: Track a connector&rsquo;s active topics During runtime, it&rsquo;s not easy to know the topics a sink connector reads records from when a regex is used for topic selection. It&#8217;s also not possible to know which topics a source connector writes to. KIP-558 enables developers, operators, and applications to easily identify topics used by source and sink connectors. $ curl -s &#39;http://localhost:8083/connector/a-source-connector/topics&#39; {&quot;a-source-connector&quot;:{&quot;topics&quot;:[&quot;foo&quot;,&quot;bar&quot;,&quot;baz&quot;]}} The topic tracking is enabled by default but can also be disabled with topic.tracking.enable=false. See KIP-558 for more details. Kafka Streams KIP-150: Add Cogroup to the DSL In the past, aggregating multiple streams into one could be complicated and error prone. It generally requires you to group and aggregate all of the streams into tables, then make multiple outer join calls. The new co-group operator cleans up the syntax of your programs, reduces the number of state store invocations, and overall increases performance. KTable&lt;K, CG&gt; cogrouped = grouped1 .cogroup(aggregator1) .cogroup(grouped2, aggregator2) .cogroup(grouped3, aggregator3) .aggregate(initializer1, materialized1); See KIP-150 for more details. KIP-523: Add toTable() to the DSL A powerful way to interpret a stream of events is as a changelog and to materialize a table over it. KIP-523 as a toTable() function can be applied to a stream and materializes the latest value per key. It&rsquo;s important to note that any null values will be interpreted as deletes for a given key (tombstones). See KIP-523 for more details. KIP-535: Allow state stores to serve stale reads during rebalance Previously, interactive queries (IQs) against state stores would fail during the time period when there is a rebalance in progress. This degraded the uptime of applications that depend on the ability to query Kafka Streams&rsquo; tables of state. KIP-535 gives applications the ability to query any replica of a state store and observe how far each replica is lagging behind the primary. See KIP-535 and this blog post for more details. Deprecations We have dropped support for Scala 2.11 in Apache Kafka 2.5. Scala 2.12 and 2.13 are now the only supported versions. TLS 1.2 is now the default SSL protocol. TLS 1.0 and 1.1 are still supported. Conclusion To learn more about what&rsquo;s new in Apache Kafka 2.5 and to see all the KIPs included in this release, be sure to check out the release notes and highlights video." />
<meta property="og:description" content="On behalf of the Apache Kafka&reg; community, it is my pleasure to announce the release of Apache Kafka 2.5.0. The community has created another exciting release. We are making progress on KIP-500 and have added new metrics and security features, among other improvements. This blog post goes into detail on some of the added functionality, but to get a full list of what&rsquo;s new in this release, please see the release notes. Kafka broker, producer, and consumer KIP-500 update In Apache Kafka 2.5, some preparatory work has been done towards the removal of Apache ZooKeeper&amp;#x2122; (ZK). KIP-555: details about the ZooKeeper deprecation process in admin tools KIP-543: dynamic configs will not require ZooKeeper access Exactly once semantics (EOS) &ndash; Foundational improvements KIP-447: Producer scalability for exactly once semantics This KIP simplifies the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build EOS applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release. See KIP-447 for more details. KIP-360: Improve reliability of idempotent/transactional producer This KIP addresses a problem with producer state retention on the broker, which is what makes the idempotence guarantee possible. Previously, when the log was truncated to enforce retention or truncated from a call to delete records, the broker dropped producer state, which led to UnknownProducerId errors. With this improvement, the broker instead retains producer state until expiration. This KIP also gives the producer a powerful way to recover from unexpected errors. See KIP-360 for more details. Metrics and operational improvements KIP-515: Enable ZK client to use the new TLS supported authentication (ZK 3.5.7) Apache Kafka 2.5 now ships ZooKeeper 3.5.7. One feature of note is the newly added ZooKeeper TLS support in ZooKeeper 3.5. When deploying a secure Kafka cluster, it&rsquo;s critical to use TLS to encrypt communication in transit. Apache Kafka 2.4 already ships with ZooKeeper 3.5, which adds TLS support between the broker and ZooKeeper. However, configuration information has to be passed via system properties as -D command line options on the Java invocation of the broker or CLI tool (e.g., zookeeper-security-migration), which is not secure. KIP-515 introduces the necessary changes to enable the use of secure configuration values for using TLS with ZooKeeper. ZooKeeper 3.5.7 supports both mutual TLS authentication via its ssl.clientAuth=required configuration value and TLS encryption without client certificate authentication via ssl.clientAuth=none. See KIP-515 for more details. KIP-511: Collect and Expose Client&#8217;s Name and Version in the Brokers Previously, operators of Apache Kafka could only identify incoming clients using the clientId field set on the consumer and producer. As this field is typically used to identify different applications, it leaves a gap in operational insight regarding client software libraries and versions. KIP-511 introduces two new fields to the ApiVersionsRequest RPC: ClientSoftwareName and ClientSoftwareVersion. These fields are captured by the broker and reported through a new set of metrics. The metric MBean pattern is: kafka.server:clientSoftwareName=(client-software-name),clientSoftwareVersion=(client-software-version),listener=(listener),networkProcessor=(processor-index),type=(type) For example, the Apache Kafka 2.4 Java client produces the following MBean on the broker: kafka.server:clientSoftwareName=apache-kafka-java,clientSoftwareVersion=2.4.0,listener=PLAINTEXT,networkProcessor=1,type=socket-server-metrics See KIP-511 for more details. KIP-559: Make the Kafka Protocol Friendlier with L7 Proxies This KIP identifies and improves several parts of our protocol, which were not fully self-describing. Some of our APIs have generic bytes fields, which have implicit encoding. Additional context is needed to properly decode these fields. This KIP addresses this problem by adding the necessary context to the API so L7 proxies can fully decode our protocols. See KIP-559 for more details. &lt;h4 id=”kip-541””&gt;KIP-541: Create a fetch.max.bytes configuration for the broker&lt;/h4&gt; Kafka consumers can choose the maximum number of bytes to fetch by setting the client-side configuration fetch.max.bytes. Too high of a value may degrade performance on the broker for other consumers. If the value is extremely high, the client request may time out. KIP-541 centralizes this configuration with a broker setting that puts an upper limit on the maximum number of bytes that the client can choose to fetch. See KIP-541 for more details. Kafka Connect KIP-558: Track a connector&rsquo;s active topics During runtime, it&rsquo;s not easy to know the topics a sink connector reads records from when a regex is used for topic selection. It&#8217;s also not possible to know which topics a source connector writes to. KIP-558 enables developers, operators, and applications to easily identify topics used by source and sink connectors. $ curl -s &#39;http://localhost:8083/connector/a-source-connector/topics&#39; {&quot;a-source-connector&quot;:{&quot;topics&quot;:[&quot;foo&quot;,&quot;bar&quot;,&quot;baz&quot;]}} The topic tracking is enabled by default but can also be disabled with topic.tracking.enable=false. See KIP-558 for more details. Kafka Streams KIP-150: Add Cogroup to the DSL In the past, aggregating multiple streams into one could be complicated and error prone. It generally requires you to group and aggregate all of the streams into tables, then make multiple outer join calls. The new co-group operator cleans up the syntax of your programs, reduces the number of state store invocations, and overall increases performance. KTable&lt;K, CG&gt; cogrouped = grouped1 .cogroup(aggregator1) .cogroup(grouped2, aggregator2) .cogroup(grouped3, aggregator3) .aggregate(initializer1, materialized1); See KIP-150 for more details. KIP-523: Add toTable() to the DSL A powerful way to interpret a stream of events is as a changelog and to materialize a table over it. KIP-523 as a toTable() function can be applied to a stream and materializes the latest value per key. It&rsquo;s important to note that any null values will be interpreted as deletes for a given key (tombstones). See KIP-523 for more details. KIP-535: Allow state stores to serve stale reads during rebalance Previously, interactive queries (IQs) against state stores would fail during the time period when there is a rebalance in progress. This degraded the uptime of applications that depend on the ability to query Kafka Streams&rsquo; tables of state. KIP-535 gives applications the ability to query any replica of a state store and observe how far each replica is lagging behind the primary. See KIP-535 and this blog post for more details. Deprecations We have dropped support for Scala 2.11 in Apache Kafka 2.5. Scala 2.12 and 2.13 are now the only supported versions. TLS 1.2 is now the default SSL protocol. TLS 1.0 and 1.1 are still supported. Conclusion To learn more about what&rsquo;s new in Apache Kafka 2.5 and to see all the KIPs included in this release, be sure to check out the release notes and highlights video." />
<link rel="canonical" href="http://localhost:4000/kafka/entry/what-s-new-in-apache2" />
<meta property="og:url" content="http://localhost:4000/kafka/entry/what-s-new-in-apache2" />
<meta property="og:site_name" content="Blogs Archive" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-18T17:26:28-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="What’s New in Apache Kafka 2.5.0" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-05-18T17:26:28-04:00","datePublished":"2020-05-18T17:26:28-04:00","description":"On behalf of the Apache Kafka&reg; community, it is my pleasure to announce the release of Apache Kafka 2.5.0. The community has created another exciting release. We are making progress on KIP-500 and have added new metrics and security features, among other improvements. This blog post goes into detail on some of the added functionality, but to get a full list of what&rsquo;s new in this release, please see the release notes. Kafka broker, producer, and consumer KIP-500 update In Apache Kafka 2.5, some preparatory work has been done towards the removal of Apache ZooKeeper&amp;#x2122; (ZK). KIP-555: details about the ZooKeeper deprecation process in admin tools KIP-543: dynamic configs will not require ZooKeeper access Exactly once semantics (EOS) &ndash; Foundational improvements KIP-447: Producer scalability for exactly once semantics This KIP simplifies the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build EOS applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release. See KIP-447 for more details. KIP-360: Improve reliability of idempotent/transactional producer This KIP addresses a problem with producer state retention on the broker, which is what makes the idempotence guarantee possible. Previously, when the log was truncated to enforce retention or truncated from a call to delete records, the broker dropped producer state, which led to UnknownProducerId errors. With this improvement, the broker instead retains producer state until expiration. This KIP also gives the producer a powerful way to recover from unexpected errors. See KIP-360 for more details. Metrics and operational improvements KIP-515: Enable ZK client to use the new TLS supported authentication (ZK 3.5.7) Apache Kafka 2.5 now ships ZooKeeper 3.5.7. One feature of note is the newly added ZooKeeper TLS support in ZooKeeper 3.5. When deploying a secure Kafka cluster, it&rsquo;s critical to use TLS to encrypt communication in transit. Apache Kafka 2.4 already ships with ZooKeeper 3.5, which adds TLS support between the broker and ZooKeeper. However, configuration information has to be passed via system properties as -D command line options on the Java invocation of the broker or CLI tool (e.g., zookeeper-security-migration), which is not secure. KIP-515 introduces the necessary changes to enable the use of secure configuration values for using TLS with ZooKeeper. ZooKeeper 3.5.7 supports both mutual TLS authentication via its ssl.clientAuth=required configuration value and TLS encryption without client certificate authentication via ssl.clientAuth=none. See KIP-515 for more details. KIP-511: Collect and Expose Client&#8217;s Name and Version in the Brokers Previously, operators of Apache Kafka could only identify incoming clients using the clientId field set on the consumer and producer. As this field is typically used to identify different applications, it leaves a gap in operational insight regarding client software libraries and versions. KIP-511 introduces two new fields to the ApiVersionsRequest RPC: ClientSoftwareName and ClientSoftwareVersion. These fields are captured by the broker and reported through a new set of metrics. The metric MBean pattern is: kafka.server:clientSoftwareName=(client-software-name),clientSoftwareVersion=(client-software-version),listener=(listener),networkProcessor=(processor-index),type=(type) For example, the Apache Kafka 2.4 Java client produces the following MBean on the broker: kafka.server:clientSoftwareName=apache-kafka-java,clientSoftwareVersion=2.4.0,listener=PLAINTEXT,networkProcessor=1,type=socket-server-metrics See KIP-511 for more details. KIP-559: Make the Kafka Protocol Friendlier with L7 Proxies This KIP identifies and improves several parts of our protocol, which were not fully self-describing. Some of our APIs have generic bytes fields, which have implicit encoding. Additional context is needed to properly decode these fields. This KIP addresses this problem by adding the necessary context to the API so L7 proxies can fully decode our protocols. See KIP-559 for more details. &lt;h4 id=”kip-541””&gt;KIP-541: Create a fetch.max.bytes configuration for the broker&lt;/h4&gt; Kafka consumers can choose the maximum number of bytes to fetch by setting the client-side configuration fetch.max.bytes. Too high of a value may degrade performance on the broker for other consumers. If the value is extremely high, the client request may time out. KIP-541 centralizes this configuration with a broker setting that puts an upper limit on the maximum number of bytes that the client can choose to fetch. See KIP-541 for more details. Kafka Connect KIP-558: Track a connector&rsquo;s active topics During runtime, it&rsquo;s not easy to know the topics a sink connector reads records from when a regex is used for topic selection. It&#8217;s also not possible to know which topics a source connector writes to. KIP-558 enables developers, operators, and applications to easily identify topics used by source and sink connectors. $ curl -s &#39;http://localhost:8083/connector/a-source-connector/topics&#39; {&quot;a-source-connector&quot;:{&quot;topics&quot;:[&quot;foo&quot;,&quot;bar&quot;,&quot;baz&quot;]}} The topic tracking is enabled by default but can also be disabled with topic.tracking.enable=false. See KIP-558 for more details. Kafka Streams KIP-150: Add Cogroup to the DSL In the past, aggregating multiple streams into one could be complicated and error prone. It generally requires you to group and aggregate all of the streams into tables, then make multiple outer join calls. The new co-group operator cleans up the syntax of your programs, reduces the number of state store invocations, and overall increases performance. KTable&lt;K, CG&gt; cogrouped = grouped1 .cogroup(aggregator1) .cogroup(grouped2, aggregator2) .cogroup(grouped3, aggregator3) .aggregate(initializer1, materialized1); See KIP-150 for more details. KIP-523: Add toTable() to the DSL A powerful way to interpret a stream of events is as a changelog and to materialize a table over it. KIP-523 as a toTable() function can be applied to a stream and materializes the latest value per key. It&rsquo;s important to note that any null values will be interpreted as deletes for a given key (tombstones). See KIP-523 for more details. KIP-535: Allow state stores to serve stale reads during rebalance Previously, interactive queries (IQs) against state stores would fail during the time period when there is a rebalance in progress. This degraded the uptime of applications that depend on the ability to query Kafka Streams&rsquo; tables of state. KIP-535 gives applications the ability to query any replica of a state store and observe how far each replica is lagging behind the primary. See KIP-535 and this blog post for more details. Deprecations We have dropped support for Scala 2.11 in Apache Kafka 2.5. Scala 2.12 and 2.13 are now the only supported versions. TLS 1.2 is now the default SSL protocol. TLS 1.0 and 1.1 are still supported. Conclusion To learn more about what&rsquo;s new in Apache Kafka 2.5 and to see all the KIPs included in this release, be sure to check out the release notes and highlights video.","headline":"What’s New in Apache Kafka 2.5.0","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/kafka/entry/what-s-new-in-apache2"},"url":"http://localhost:4000/kafka/entry/what-s-new-in-apache2"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blogs Archive" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blogs Archive</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">What&#39;s New in Apache Kafka 2.5.0</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-05-18T17:26:28-04:00" itemprop="datePublished">May 18, 2020
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"display_name"=>"David Arthur", "login"=>"davidarthur", "email"=>"davidarthur@apache.org"}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>On behalf of the Apache Kafka<sup>&reg;</sup> community, it is my pleasure to announce the release of Apache Kafka 2.5.0. The community has created another exciting release.</p>
<p>We are making progress on KIP-500 and have added new metrics and security features, among other improvements. This blog post goes into detail on some of the added functionality, but to get a full list of what&rsquo;s new in this release, please see the <a href="https://dist.apache.org/repos/dist/release/kafka/2.5.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a>.</p>
<h2 id="broker-producer-consumer"><a id="broker-producer-consumer"></a>Kafka broker, producer, and consumer</h2>
<h4 id="kip-500"><a id="kip-500"></a>KIP-500 update</h4>
<p>In Apache Kafka 2.5, some preparatory work has been done towards the removal of Apache ZooKeeper&#x2122; (ZK).</p>
<ul>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-555%3A+Deprecate+Direct+Zookeeper+access+in+Kafka+Administrative+Tools" target="_blank" rel="noopener noreferrer">KIP-555</a>: details about the ZooKeeper deprecation process in admin tools</li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-543%3A+Expand+ConfigCommand%27s+non-ZK+functionality" target="_blank" rel="noopener noreferrer">KIP-543</a>: dynamic configs will not require ZooKeeper access</li>
</ul>
<h3 id="eos"><a id="eos"></a>Exactly once semantics (EOS) &ndash; Foundational improvements</h3>
<h4 id="kip-447"><a id="kip-447"></a>KIP-447: Producer scalability for exactly once semantics</h4>
<p>This KIP simplifies the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build EOS applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics" target="_blank" rel="noopener noreferrer">KIP-447</a> for more details.</em></p>
<h4 id="kip-360"><a id="kip-360"></a>KIP-360: Improve reliability of idempotent/transactional producer</h4>
<p>This KIP addresses a problem with producer state retention on the broker, which is what makes the idempotence guarantee possible. Previously, when the log was truncated to enforce retention or truncated from a call to delete records, the broker dropped producer state, which led to <code>UnknownProducerId</code> errors. With this improvement, the broker instead retains producer state until expiration. This KIP also gives the producer a powerful way to recover from unexpected errors.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=89068820" target="_blank" rel="noopener noreferrer">KIP-360</a> for more details.</em></p>
<h3 id="metrics-operational-improvements"><a id="metrics-operational-improvements"></a>Metrics and operational improvements</h3>
<h4 id="kip-515"><a id="kip-515"></a>KIP-515: Enable ZK client to use the new TLS supported authentication (ZK 3.5.7)</h4>
<p>Apache Kafka 2.5 now ships ZooKeeper 3.5.7. One feature of note is the newly added ZooKeeper TLS support in ZooKeeper 3.5. When deploying a secure Kafka cluster, it&rsquo;s critical to use TLS to encrypt communication in transit. Apache Kafka 2.4 already ships with ZooKeeper 3.5, which adds TLS support between the broker and ZooKeeper. However, configuration information has to be passed via system properties as <code>-D</code> command line options on the Java invocation of the broker or CLI tool (e.g., <code>zookeeper-security-migration</code>), which is not secure. KIP-515 introduces the necessary changes to enable the use of secure configuration values for using TLS with ZooKeeper.</p>
<p>ZooKeeper 3.5.7 supports both mutual TLS authentication via its <code>ssl.clientAuth=required</code> configuration value and TLS encryption without client certificate authentication via <code>ssl.clientAuth=none</code>.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-515%3A+Enable+ZK+client+to+use+the+new+TLS+supported+authentication" target="_blank" rel="noopener noreferrer">KIP-515</a> for more details.</em></p>
<h4 id="kip-511"><a id="kip-511"></a>KIP-511: Collect and Expose Client&#8217;s Name and Version in the Brokers</h4>
<p>Previously, operators of Apache Kafka could only identify incoming clients using the <code>clientId</code> field set on the consumer and producer. As this field is typically used to identify different applications, it leaves a gap in operational insight regarding client software libraries and versions. KIP-511 introduces two new fields to the <code>ApiVersionsRequest</code> RPC: <code>ClientSoftwareName</code> and <code>ClientSoftwareVersion</code>.</p>
<p>These fields are captured by the broker and reported through a new set of metrics. The metric MBean pattern is:</p>
<pre>kafka.server:clientSoftwareName=(client-software-name),clientSoftwareVersion=(client-software-version),listener=(listener),networkProcessor=(processor-index),type=(type)
</pre>
<p>For example, the Apache Kafka 2.4 Java client produces the following MBean on the broker:</p>
<pre>kafka.server:clientSoftwareName=apache-kafka-java,clientSoftwareVersion=2.4.0,listener=PLAINTEXT,networkProcessor=1,type=socket-server-metrics
</pre>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-511%3A+Collect+and+Expose+Client%27s+Name+and+Version+in+the+Brokers" target="_blank" rel="noopener noreferrer">KIP-511</a> for more details.</em></p>
<h4 id="kip-559"><a id="kip-559"></a>KIP-559: Make the Kafka Protocol Friendlier with L7 Proxies</h4>
<p>This KIP identifies and improves several parts of our protocol, which were not fully self-describing. Some of our APIs have generic <code>bytes</code> fields, which have implicit encoding. Additional context is needed to properly decode these fields. This KIP addresses this problem by adding the necessary context to the API so L7 proxies can fully decode our protocols.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-559%3A+Make+the+Kafka+Protocol+Friendlier+with+L7+Proxies" target="_blank" rel="noopener noreferrer">KIP-559</a> for more details.</em></p>
<h4 id="kip-541""><a id="kip-541"></a>KIP-541: Create a fetch.max.bytes configuration for the broker</h4>
<p>Kafka consumers can choose the maximum number of bytes to fetch by setting the client-side configuration <code>fetch.max.bytes</code>. Too high of a value may degrade performance on the broker for other consumers. If the value is extremely high, the client request may time out. KIP-541 centralizes this configuration with a broker setting that puts an upper limit on the maximum number of bytes that the client can choose to fetch.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-541%3A+Create+a+fetch.max.bytes+configuration+for+the+broker" target="_blank" rel="noopener noreferrer">KIP-541</a> for more details.</em></p>
<h2 id="kafka-connect"><a id="kafka-connect"></a>Kafka Connect</h2>
<h4 id="kip-558"><a id="kip-558"></a>KIP-558: Track a connector&rsquo;s active topics</h4>
<p>During runtime, it&rsquo;s not easy to know the topics a sink connector reads records from when a regex is used for topic selection. It&#8217;s also not possible to know which topics a source connector writes to. KIP-558 enables developers, operators, and applications to easily identify topics used by source and sink connectors.</p>
<pre>$ curl -s 'http://localhost:8083/connector/a-source-connector/topics'
{"a-source-connector":{"topics":["foo","bar","baz"]}}
</pre>
<p>The topic tracking is enabled by default but can also be disabled with <code>topic.tracking.enable=false</code>.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-558%3A+Track+the+set+of+actively+used+topics+by+connectors+in+Kafka+Connect" target="_blank" rel="noopener noreferrer">KIP-558</a> for more details.</em></p>
<h2 id="kafka-streams"><a id="kafka-streams"></a>Kafka Streams</h2>
<h4 id="kip-150"><a id="kip-150"></a>KIP-150: Add Cogroup to the DSL</h4>
<p>In the past, aggregating multiple streams into one could be complicated and error prone. It generally requires you to group and aggregate all of the streams into tables, then make multiple outer join calls. The new co-group operator cleans up the syntax of your programs, reduces the number of state store invocations, and overall increases performance.</p>
<pre>KTable<K, CG> cogrouped =
  grouped1
    .cogroup(aggregator1)
    .cogroup(grouped2, aggregator2)
    .cogroup(grouped3, aggregator3)
    .aggregate(initializer1, materialized1);
</pre>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-150+-+Kafka-Streams+Cogroup" target="_blank" rel="noopener noreferrer">KIP-150</a> for more details.</em></p>
<h4 id="kip-523"><a id="kip-523"></a>KIP-523: Add toTable() to the DSL</h4>
<p>A powerful way to interpret a stream of events is as a changelog and to materialize a table over it. KIP-523 as a <code>toTable()</code> function can be applied to a stream and materializes the latest value per key. It&rsquo;s important to note that any null values will be interpreted as deletes for a given key (tombstones).</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-523%3A+Add+KStream%23toTable+to+the+Streams+DSL" target="_blank" rel="noopener noreferrer">KIP-523</a> for more details.</em></p>
<h4 id="kip-535"><a id="kip-535"></a>KIP-535: Allow state stores to serve stale reads during rebalance</h4>
<p>Previously, interactive queries (IQs) against state stores would fail during the time period when there is a rebalance in progress. This degraded the uptime of applications that depend on the ability to query Kafka Streams&rsquo; tables of state. KIP-535 gives applications the ability to query any replica of a state store and observe how far each replica is lagging behind the primary.</p>
<p><em>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-535%3A+Allow+state+stores+to+serve+stale+reads+during+rebalance" target="_blank" rel="noopener noreferrer">KIP-535</a> and this <a target="_blank" href="https://www.confluent.io/blog/kafka-streams-ksqldb-interactive-queries-go-prime-time/">blog post</a> for more details.</em></p>
<h2 id="deprecations"><a id="deprecations"></a>Deprecations</h2>
<p>We have dropped support for Scala 2.11 in Apache Kafka 2.5. Scala 2.12 and 2.13 are now the only supported versions.</p>
<p>TLS 1.2 is now the default SSL protocol. TLS 1.0 and 1.1 are still supported.</p>
<h2 id="conclusion"><a id="conclusion"></a>Conclusion</h2>
<p>To learn more about what&rsquo;s new in Apache Kafka 2.5 and to see all the KIPs included in this release, be sure to check out the <a href="https://dist.apache.org/repos/dist/release/kafka/2.5.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a> and <a href="https://www.youtube.com/watch?v=svIOIlV2jRE" target="_blank" rel="noopener noreferrer">highlights video</a>.</p>

  </div><a class="u-url" href="/kafka/entry/what-s-new-in-apache2" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Blogs Archive</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blogs Archive</li><li><a class="u-email" href="mailto:issues@infra.apache.org">issues@infra.apache.org</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is an archive of the Roller blogs that were previously hosted on blogs.apache.org</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
